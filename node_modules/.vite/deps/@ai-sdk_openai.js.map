{
  "version": 3,
  "sources": ["../../@ai-sdk/openai/src/openai-provider.ts", "../../@ai-sdk/openai/src/chat/openai-chat-language-model.ts", "../../@ai-sdk/openai/src/openai-error.ts", "../../@ai-sdk/openai/src/chat/convert-to-openai-chat-messages.ts", "../../@ai-sdk/openai/src/chat/get-response-metadata.ts", "../../@ai-sdk/openai/src/chat/map-openai-finish-reason.ts", "../../@ai-sdk/openai/src/chat/openai-chat-options.ts", "../../@ai-sdk/openai/src/chat/openai-chat-prepare-tools.ts", "../../@ai-sdk/openai/src/completion/openai-completion-language-model.ts", "../../@ai-sdk/openai/src/completion/convert-to-openai-completion-prompt.ts", "../../@ai-sdk/openai/src/completion/get-response-metadata.ts", "../../@ai-sdk/openai/src/completion/map-openai-finish-reason.ts", "../../@ai-sdk/openai/src/completion/openai-completion-options.ts", "../../@ai-sdk/openai/src/embedding/openai-embedding-model.ts", "../../@ai-sdk/openai/src/embedding/openai-embedding-options.ts", "../../@ai-sdk/openai/src/image/openai-image-model.ts", "../../@ai-sdk/openai/src/image/openai-image-options.ts", "../../@ai-sdk/openai/src/tool/code-interpreter.ts", "../../@ai-sdk/openai/src/tool/file-search.ts", "../../@ai-sdk/openai/src/tool/image-generation.ts", "../../@ai-sdk/openai/src/tool/web-search.ts", "../../@ai-sdk/openai/src/tool/web-search-preview.ts", "../../@ai-sdk/openai/src/openai-tools.ts", "../../@ai-sdk/openai/src/responses/openai-responses-language-model.ts", "../../@ai-sdk/openai/src/responses/convert-to-openai-responses-input.ts", "../../@ai-sdk/openai/src/responses/map-openai-responses-finish-reason.ts", "../../@ai-sdk/openai/src/responses/openai-responses-prepare-tools.ts", "../../@ai-sdk/openai/src/speech/openai-speech-model.ts", "../../@ai-sdk/openai/src/transcription/openai-transcription-model.ts", "../../@ai-sdk/openai/src/transcription/openai-transcription-options.ts", "../../@ai-sdk/openai/src/version.ts"],
  "sourcesContent": ["import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  ProviderV2,\n  SpeechModelV2,\n  TranscriptionModelV2,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIChatLanguageModel } from './chat/openai-chat-language-model';\nimport { OpenAIChatModelId } from './chat/openai-chat-options';\nimport { OpenAICompletionLanguageModel } from './completion/openai-completion-language-model';\nimport { OpenAICompletionModelId } from './completion/openai-completion-options';\nimport { OpenAIEmbeddingModel } from './embedding/openai-embedding-model';\nimport { OpenAIEmbeddingModelId } from './embedding/openai-embedding-options';\nimport { OpenAIImageModel } from './image/openai-image-model';\nimport { OpenAIImageModelId } from './image/openai-image-options';\nimport { openaiTools } from './openai-tools';\nimport { OpenAIResponsesLanguageModel } from './responses/openai-responses-language-model';\nimport { OpenAIResponsesModelId } from './responses/openai-responses-settings';\nimport { OpenAISpeechModel } from './speech/openai-speech-model';\nimport { OpenAISpeechModelId } from './speech/openai-speech-options';\nimport { OpenAITranscriptionModel } from './transcription/openai-transcription-model';\nimport { OpenAITranscriptionModelId } from './transcription/openai-transcription-options';\nimport { VERSION } from './version';\n\nexport interface OpenAIProvider extends ProviderV2 {\n  (modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI model for text generation.\n   */\n  languageModel(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI chat model for text generation.\n   */\n  chat(modelId: OpenAIChatModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI responses API model for text generation.\n   */\n  responses(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI completion model for text generation.\n   */\n  completion(modelId: OpenAICompletionModelId): LanguageModelV2;\n\n  /**\nCreates a model for text embeddings.\n   */\n  embedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbeddingModel(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for image generation.\n   */\n  image(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for image generation.\n   */\n  imageModel(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for transcription.\n   */\n  transcription(modelId: OpenAITranscriptionModelId): TranscriptionModelV2;\n\n  /**\nCreates a model for speech generation.\n   */\n  speech(modelId: OpenAISpeechModelId): SpeechModelV2;\n\n  /**\nOpenAI-specific tools.\n   */\n  tools: typeof openaiTools;\n}\n\nexport interface OpenAIProviderSettings {\n  /**\nBase URL for the OpenAI API calls.\n     */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests.\n     */\n  apiKey?: string;\n\n  /**\nOpenAI Organization.\n     */\n  organization?: string;\n\n  /**\nOpenAI project.\n     */\n  project?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nProvider name. Overrides the `openai` default name for 3rd party providers.\n   */\n  name?: string;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate an OpenAI provider instance.\n */\nexport function createOpenAI(\n  options: OpenAIProviderSettings = {},\n): OpenAIProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ?? 'https://api.openai.com/v1';\n\n  const providerName = options.name ?? 'openai';\n\n  const getHeaders = () =>\n    withUserAgentSuffix(\n      {\n        Authorization: `Bearer ${loadApiKey({\n          apiKey: options.apiKey,\n          environmentVariableName: 'OPENAI_API_KEY',\n          description: 'OpenAI',\n        })}`,\n        'OpenAI-Organization': options.organization,\n        'OpenAI-Project': options.project,\n        ...options.headers,\n      },\n      `ai-sdk/openai/${VERSION}`,\n    );\n\n  const createChatModel = (modelId: OpenAIChatModelId) =>\n    new OpenAIChatLanguageModel(modelId, {\n      provider: `${providerName}.chat`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createCompletionModel = (modelId: OpenAICompletionModelId) =>\n    new OpenAICompletionLanguageModel(modelId, {\n      provider: `${providerName}.completion`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: OpenAIEmbeddingModelId) =>\n    new OpenAIEmbeddingModel(modelId, {\n      provider: `${providerName}.embedding`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (modelId: OpenAIImageModelId) =>\n    new OpenAIImageModel(modelId, {\n      provider: `${providerName}.image`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createTranscriptionModel = (modelId: OpenAITranscriptionModelId) =>\n    new OpenAITranscriptionModel(modelId, {\n      provider: `${providerName}.transcription`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createSpeechModel = (modelId: OpenAISpeechModelId) =>\n    new OpenAISpeechModel(modelId, {\n      provider: `${providerName}.speech`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createLanguageModel = (modelId: OpenAIResponsesModelId) => {\n    if (new.target) {\n      throw new Error(\n        'The OpenAI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createResponsesModel(modelId);\n  };\n\n  const createResponsesModel = (modelId: OpenAIResponsesModelId) => {\n    return new OpenAIResponsesLanguageModel(modelId, {\n      provider: `${providerName}.responses`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n      fileIdPrefixes: ['file-'],\n    });\n  };\n\n  const provider = function (modelId: OpenAIResponsesModelId) {\n    return createLanguageModel(modelId);\n  };\n\n  provider.languageModel = createLanguageModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.responses = createResponsesModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n\n  provider.transcription = createTranscriptionModel;\n  provider.transcriptionModel = createTranscriptionModel;\n\n  provider.speech = createSpeechModel;\n  provider.speechModel = createSpeechModel;\n\n  provider.tools = openaiTools;\n\n  return provider as OpenAIProvider;\n}\n\n/**\nDefault OpenAI provider instance.\n */\nexport const openai = createOpenAI();\n", "import {\n  InvalidResponseDataError,\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  isParsableJson,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  openaiErrorDataSchema,\n  openaiFailedResponseHandler,\n} from '../openai-error';\nimport { convertToOpenAIChatMessages } from './convert-to-openai-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAIChatModelId,\n  openaiChatLanguageModelOptions,\n} from './openai-chat-options';\nimport { prepareChatTools } from './openai-chat-prepare-tools';\n\ntype OpenAIChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAIChatLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIChatModelId;\n\n  readonly supportedUrls = {\n    'image/*': [/^https?:\\/\\/.*$/],\n  };\n\n  private readonly config: OpenAIChatConfig;\n\n  constructor(modelId: OpenAIChatModelId, config: OpenAIChatConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: LanguageModelV2CallOptions) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiChatLanguageModelOptions,\n      })) ?? {};\n\n    const structuredOutputs = openaiOptions.structuredOutputs ?? true;\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (\n      responseFormat?.type === 'json' &&\n      responseFormat.schema != null &&\n      !structuredOutputs\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details:\n          'JSON response format schema is only supported with structuredOutputs',\n      });\n    }\n\n    const { messages, warnings: messageWarnings } = convertToOpenAIChatMessages(\n      {\n        prompt,\n        systemMessageMode: getSystemMessageMode(this.modelId),\n      },\n    );\n\n    warnings.push(...messageWarnings);\n\n    const strictJsonSchema = openaiOptions.strictJsonSchema ?? false;\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      logit_bias: openaiOptions.logitBias,\n      logprobs:\n        openaiOptions.logprobs === true ||\n        typeof openaiOptions.logprobs === 'number'\n          ? true\n          : undefined,\n      top_logprobs:\n        typeof openaiOptions.logprobs === 'number'\n          ? openaiOptions.logprobs\n          : typeof openaiOptions.logprobs === 'boolean'\n            ? openaiOptions.logprobs\n              ? 0\n              : undefined\n            : undefined,\n      user: openaiOptions.user,\n      parallel_tool_calls: openaiOptions.parallelToolCalls,\n\n      // standardized settings:\n      max_tokens: maxOutputTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? structuredOutputs && responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  strict: strictJsonSchema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n      stop: stopSequences,\n      seed,\n      verbosity: openaiOptions.textVerbosity,\n\n      // openai specific settings:\n      // TODO AI SDK 6: remove, we auto-map maxOutputTokens now\n      max_completion_tokens: openaiOptions.maxCompletionTokens,\n      store: openaiOptions.store,\n      metadata: openaiOptions.metadata,\n      prediction: openaiOptions.prediction,\n      reasoning_effort: openaiOptions.reasoningEffort,\n      service_tier: openaiOptions.serviceTier,\n      prompt_cache_key: openaiOptions.promptCacheKey,\n      safety_identifier: openaiOptions.safetyIdentifier,\n\n      // messages:\n      messages,\n    };\n\n    if (isReasoningModel(this.modelId)) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.frequency_penalty != null) {\n        baseArgs.frequency_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'frequencyPenalty',\n          details: 'frequencyPenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.presence_penalty != null) {\n        baseArgs.presence_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'presencePenalty',\n          details: 'presencePenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logit_bias != null) {\n        baseArgs.logit_bias = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logitBias is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logprobs != null) {\n        baseArgs.logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logprobs is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_logprobs != null) {\n        baseArgs.top_logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'topLogprobs is not supported for reasoning models',\n        });\n      }\n\n      // reasoning models use max_completion_tokens instead of max_tokens:\n      if (baseArgs.max_tokens != null) {\n        if (baseArgs.max_completion_tokens == null) {\n          baseArgs.max_completion_tokens = baseArgs.max_tokens;\n        }\n        baseArgs.max_tokens = undefined;\n      }\n    } else if (\n      this.modelId.startsWith('gpt-4o-search-preview') ||\n      this.modelId.startsWith('gpt-4o-mini-search-preview')\n    ) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details:\n            'temperature is not supported for the search preview models and has been removed.',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions.serviceTier === 'flex' &&\n      !supportsFlexProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions.serviceTier === 'priority' &&\n      !supportsPriorityProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareChatTools({\n      tools,\n      toolChoice,\n      structuredOutputs,\n      strictJsonSchema,\n    });\n\n    return {\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args: body, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n    const content: Array<LanguageModelV2Content> = [];\n\n    // text content:\n    const text = choice.message.content;\n    if (text != null && text.length > 0) {\n      content.push({ type: 'text', text });\n    }\n\n    // tool calls:\n    for (const toolCall of choice.message.tool_calls ?? []) {\n      content.push({\n        type: 'tool-call' as const,\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        input: toolCall.function.arguments!,\n      });\n    }\n\n    // annotations/citations:\n    for (const annotation of choice.message.annotations ?? []) {\n      content.push({\n        type: 'source',\n        sourceType: 'url',\n        id: generateId(),\n        url: annotation.url,\n        title: annotation.title,\n      });\n    }\n\n    // provider metadata:\n    const completionTokenDetails = response.usage?.completion_tokens_details;\n    const promptTokenDetails = response.usage?.prompt_tokens_details;\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    if (completionTokenDetails?.accepted_prediction_tokens != null) {\n      providerMetadata.openai.acceptedPredictionTokens =\n        completionTokenDetails?.accepted_prediction_tokens;\n    }\n    if (completionTokenDetails?.rejected_prediction_tokens != null) {\n      providerMetadata.openai.rejectedPredictionTokens =\n        completionTokenDetails?.rejected_prediction_tokens;\n    }\n    if (choice.logprobs?.content != null) {\n      providerMetadata.openai.logprobs = choice.logprobs.content;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      usage: {\n        inputTokens: response.usage?.prompt_tokens ?? undefined,\n        outputTokens: response.usage?.completion_tokens ?? undefined,\n        totalTokens: response.usage?.total_tokens ?? undefined,\n        reasoningTokens: completionTokenDetails?.reasoning_tokens ?? undefined,\n        cachedInputTokens: promptTokenDetails?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      warnings,\n      providerMetadata,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiChatChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n    let isActiveText = false;\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiChatChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens ?? undefined;\n              usage.outputTokens = value.usage.completion_tokens ?? undefined;\n              usage.totalTokens = value.usage.total_tokens ?? undefined;\n              usage.reasoningTokens =\n                value.usage.completion_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.usage.prompt_tokens_details?.cached_tokens ?? undefined;\n\n              if (\n                value.usage.completion_tokens_details\n                  ?.accepted_prediction_tokens != null\n              ) {\n                providerMetadata.openai.acceptedPredictionTokens =\n                  value.usage.completion_tokens_details?.accepted_prediction_tokens;\n              }\n              if (\n                value.usage.completion_tokens_details\n                  ?.rejected_prediction_tokens != null\n              ) {\n                providerMetadata.openai.rejectedPredictionTokens =\n                  value.usage.completion_tokens_details?.rejected_prediction_tokens;\n              }\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs?.content != null) {\n              providerMetadata.openai.logprobs = choice.logprobs.content;\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            if (delta.content != null) {\n              if (!isActiveText) {\n                controller.enqueue({ type: 'text-start', id: '0' });\n                isActiveText = true;\n              }\n\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                // Tool call start. OpenAI returns all information except the arguments in the first chunk.\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCallDelta.id,\n                    toolName: toolCallDelta.function.name,\n                  });\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-input-delta',\n                        id: toolCall.id,\n                        delta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-input-end',\n                        id: toolCall.id,\n                      });\n\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        input: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.id,\n                  delta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.id,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    input: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n\n            // annotations/citations:\n            if (delta.annotations != null) {\n              for (const annotation of delta.annotations) {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              }\n            }\n          },\n\n          flush(controller) {\n            if (isActiveText) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              ...(providerMetadata != null ? { providerMetadata } : {}),\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst openaiTokenUsageSchema = z\n  .object({\n    prompt_tokens: z.number().nullish(),\n    completion_tokens: z.number().nullish(),\n    total_tokens: z.number().nullish(),\n    prompt_tokens_details: z\n      .object({\n        cached_tokens: z.number().nullish(),\n      })\n      .nullish(),\n    completion_tokens_details: z\n      .object({\n        reasoning_tokens: z.number().nullish(),\n        accepted_prediction_tokens: z.number().nullish(),\n        rejected_prediction_tokens: z.number().nullish(),\n      })\n      .nullish(),\n  })\n  .nullish();\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      message: z.object({\n        role: z.literal('assistant').nullish(),\n        content: z.string().nullish(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string().nullish(),\n              type: z.literal('function'),\n              function: z.object({\n                name: z.string(),\n                arguments: z.string(),\n              }),\n            }),\n          )\n          .nullish(),\n        annotations: z\n          .array(\n            z.object({\n              type: z.literal('url_citation'),\n              start_index: z.number(),\n              end_index: z.number(),\n              url: z.string(),\n              title: z.string(),\n            }),\n          )\n          .nullish(),\n      }),\n      index: z.number(),\n      logprobs: z\n        .object({\n          content: z\n            .array(\n              z.object({\n                token: z.string(),\n                logprob: z.number(),\n                top_logprobs: z.array(\n                  z.object({\n                    token: z.string(),\n                    logprob: z.number(),\n                  }),\n                ),\n              }),\n            )\n            .nullish(),\n        })\n        .nullish(),\n      finish_reason: z.string().nullish(),\n    }),\n  ),\n  usage: openaiTokenUsageSchema,\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatChunkSchema = z.union([\n  z.object({\n    id: z.string().nullish(),\n    created: z.number().nullish(),\n    model: z.string().nullish(),\n    choices: z.array(\n      z.object({\n        delta: z\n          .object({\n            role: z.enum(['assistant']).nullish(),\n            content: z.string().nullish(),\n            tool_calls: z\n              .array(\n                z.object({\n                  index: z.number(),\n                  id: z.string().nullish(),\n                  type: z.literal('function').nullish(),\n                  function: z.object({\n                    name: z.string().nullish(),\n                    arguments: z.string().nullish(),\n                  }),\n                }),\n              )\n              .nullish(),\n            annotations: z\n              .array(\n                z.object({\n                  type: z.literal('url_citation'),\n                  start_index: z.number(),\n                  end_index: z.number(),\n                  url: z.string(),\n                  title: z.string(),\n                }),\n              )\n              .nullish(),\n          })\n          .nullish(),\n        logprobs: z\n          .object({\n            content: z\n              .array(\n                z.object({\n                  token: z.string(),\n                  logprob: z.number(),\n                  top_logprobs: z.array(\n                    z.object({\n                      token: z.string(),\n                      logprob: z.number(),\n                    }),\n                  ),\n                }),\n              )\n              .nullish(),\n          })\n          .nullish(),\n        finish_reason: z.string().nullish(),\n        index: z.number(),\n      }),\n    ),\n    usage: openaiTokenUsageSchema,\n  }),\n  openaiErrorDataSchema,\n]);\n\nfunction isReasoningModel(modelId: string) {\n  return (\n    (modelId.startsWith('o') || modelId.startsWith('gpt-5')) &&\n    !modelId.startsWith('gpt-5-chat')\n  );\n}\n\nfunction supportsFlexProcessing(modelId: string) {\n  return (\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'))\n  );\n}\n\nfunction supportsPriorityProcessing(modelId: string) {\n  return (\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini')\n  );\n}\n\nfunction getSystemMessageMode(modelId: string) {\n  if (!isReasoningModel(modelId)) {\n    return 'system';\n  }\n\n  return (\n    reasoningModels[modelId as keyof typeof reasoningModels]\n      ?.systemMessageMode ?? 'developer'\n  );\n}\n\nconst reasoningModels = {\n  'o1-mini': {\n    systemMessageMode: 'remove',\n  },\n  'o1-mini-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  o3: {\n    systemMessageMode: 'developer',\n  },\n  'o3-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini-2025-01-31': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n} as const;\n", "import { z } from 'zod/v4';\nimport { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\n\nexport const openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAIErrorData = z.infer<typeof openaiErrorDataSchema>;\n\nexport const openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n", "import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { OpenAIChatPrompt } from './openai-chat-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToOpenAIChatMessages({\n  prompt,\n  systemMessageMode = 'system',\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode?: 'system' | 'developer' | 'remove';\n}): {\n  messages: OpenAIChatPrompt;\n  warnings: Array<LanguageModelV2CallWarning>;\n} {\n  const messages: OpenAIChatPrompt = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            messages.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            messages.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({ role: 'user', content: content[0].text });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'image_url',\n                    image_url: {\n                      url:\n                        part.data instanceof URL\n                          ? part.data.toString()\n                          : `data:${mediaType};base64,${convertToBase64(part.data)}`,\n\n                      // OpenAI specific extension: image detail\n                      detail: part.providerOptions?.openai?.imageDetail,\n                    },\n                  };\n                } else if (part.mediaType.startsWith('audio/')) {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'audio file parts with URLs',\n                    });\n                  }\n\n                  switch (part.mediaType) {\n                    case 'audio/wav': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'wav',\n                        },\n                      };\n                    }\n                    case 'audio/mp3':\n                    case 'audio/mpeg': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'mp3',\n                        },\n                      };\n                    }\n\n                    default: {\n                      throw new UnsupportedFunctionalityError({\n                        functionality: `audio content parts with media type ${part.mediaType}`,\n                      });\n                    }\n                  }\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'PDF file parts with URLs',\n                    });\n                  }\n\n                  return {\n                    type: 'file',\n                    file:\n                      typeof part.data === 'string' &&\n                      part.data.startsWith('file-')\n                        ? { file_id: part.data }\n                        : {\n                            filename: part.filename ?? `part-${index}.pdf`,\n                            file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                          },\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.input),\n                },\n              });\n              break;\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          const output = toolResponse.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: contentValue,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { messages, warnings };\n}\n", "export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n", "import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n", "import { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAIChatModelId =\n  | 'o1'\n  | 'o1-2024-12-17'\n  | 'o3-mini'\n  | 'o3-mini-2025-01-31'\n  | 'o3'\n  | 'o3-2025-04-16'\n  | 'gpt-4.1'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4'\n  | 'gpt-4-0613'\n  | 'gpt-4.5-preview'\n  | 'gpt-4.5-preview-2025-02-27'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-1106'\n  | 'chatgpt-4o-latest'\n  | 'gpt-5'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | (string & {});\n\nexport const openaiChatLanguageModelOptions = z.object({\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in\n   * the GPT tokenizer) to an associated bias value from -100 to 100.\n   */\n  logitBias: z.record(z.coerce.number<string>(), z.number()).optional(),\n\n  /**\n   * Return the log probabilities of the tokens.\n   *\n   * Setting to true will return the log probabilities of the tokens that\n   * were generated.\n   *\n   * Setting to a number will return the log probabilities of the top n\n   * tokens that were generated.\n   */\n  logprobs: z.union([z.boolean(), z.number()]).optional(),\n\n  /**\n   * Whether to enable parallel function calling during tool use. Default to true.\n   */\n  parallelToolCalls: z.boolean().optional(),\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to\n   * monitor and detect abuse.\n   */\n  user: z.string().optional(),\n\n  /**\n   * Reasoning effort for reasoning models. Defaults to `medium`.\n   */\n  reasoningEffort: z.enum(['minimal', 'low', 'medium', 'high']).optional(),\n\n  /**\n   * Maximum number of completion tokens to generate. Useful for reasoning models.\n   */\n  maxCompletionTokens: z.number().optional(),\n\n  /**\n   * Whether to enable persistence in responses API.\n   */\n  store: z.boolean().optional(),\n\n  /**\n   * Metadata to associate with the request.\n   */\n  metadata: z.record(z.string().max(64), z.string().max(512)).optional(),\n\n  /**\n   * Parameters for prediction mode.\n   */\n  prediction: z.record(z.string(), z.any()).optional(),\n\n  /**\n   * Whether to use structured outputs.\n   *\n   * @default true\n   */\n  structuredOutputs: z.boolean().optional(),\n\n  /**\n   * Service tier for the request.\n   * - 'auto': Default service tier\n   * - 'flex': 50% cheaper processing at the cost of increased latency. Only available for o3 and o4-mini models.\n   * - 'priority': Higher-speed processing with predictably low latency at premium cost. Available for Enterprise customers.\n   *\n   * @default 'auto'\n   */\n  serviceTier: z.enum(['auto', 'flex', 'priority']).optional(),\n\n  /**\n   * Whether to use strict JSON schema validation.\n   *\n   * @default false\n   */\n  strictJsonSchema: z.boolean().optional(),\n\n  /**\n   * Controls the verbosity of the model's responses.\n   * Lower values will result in more concise responses, while higher values will result in more verbose responses.\n   */\n  textVerbosity: z.enum(['low', 'medium', 'high']).optional(),\n\n  /**\n   * A cache key for prompt caching. Allows manual control over prompt caching behavior.\n   * Useful for improving cache hit rates and working around automatic caching issues.\n   */\n  promptCacheKey: z.string().optional(),\n\n  /**\n   * A stable identifier used to help detect users of your application\n   * that may be violating OpenAI's usage policies. The IDs should be a\n   * string that uniquely identifies each user. We recommend hashing their\n   * username or email address, in order to avoid sending us any identifying\n   * information.\n   */\n  safetyIdentifier: z.string().optional(),\n});\n\nexport type OpenAIChatLanguageModelOptions = z.infer<\n  typeof openaiChatLanguageModelOptions\n>;\n", "import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  OpenAIChatToolChoice,\n  OpenAIChatFunctionTool,\n} from './openai-chat-types';\n\nexport function prepareChatTools({\n  tools,\n  toolChoice,\n  structuredOutputs,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  structuredOutputs: boolean;\n  strictJsonSchema: boolean;\n}): {\n  tools?: OpenAIChatFunctionTool[];\n  toolChoice?: OpenAIChatToolChoice;\n  toolWarnings: Array<LanguageModelV2CallWarning>;\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: OpenAIChatFunctionTool[] = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          function: {\n            name: tool.name,\n            description: tool.description,\n            parameters: tool.inputSchema,\n            strict: structuredOutputs ? strictJsonSchema : undefined,\n          },\n        });\n        break;\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n", "import {\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  openaiErrorDataSchema,\n  openaiFailedResponseHandler,\n} from '../openai-error';\nimport { convertToOpenAICompletionPrompt } from './convert-to-openai-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAICompletionModelId,\n  openaiCompletionProviderOptions,\n} from './openai-completion-options';\n\ntype OpenAICompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAICompletionLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAICompletionModelId;\n\n  private readonly config: OpenAICompletionConfig;\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  constructor(\n    modelId: OpenAICompletionModelId,\n    config: OpenAICompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    // No URLs are supported for completion models.\n  };\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    tools,\n    toolChoice,\n    seed,\n    providerOptions,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions = {\n      ...(await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n      ...(await parseProviderOptions({\n        provider: this.providerOptionsName,\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n    };\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (tools?.length) {\n      warnings.push({ type: 'unsupported-setting', setting: 'tools' });\n    }\n\n    if (toolChoice != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'toolChoice' });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompletionPrompt({ prompt });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    return {\n      args: {\n        // model id:\n        model: this.modelId,\n\n        // model specific settings:\n        echo: openaiOptions.echo,\n        logit_bias: openaiOptions.logitBias,\n        logprobs:\n          openaiOptions?.logprobs === true\n            ? 0\n            : openaiOptions?.logprobs === false\n              ? undefined\n              : openaiOptions?.logprobs,\n        suffix: openaiOptions.suffix,\n        user: openaiOptions.user,\n\n        // standardized settings:\n        max_tokens: maxOutputTokens,\n        temperature,\n        top_p: topP,\n        frequency_penalty: frequencyPenalty,\n        presence_penalty: presencePenalty,\n        seed,\n\n        // prompt:\n        prompt: completionPrompt,\n\n        // stop sequences:\n        stop: stop.length > 0 ? stop : undefined,\n      },\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    if (choice.logprobs != null) {\n      providerMetadata.openai.logprobs = choice.logprobs;\n    }\n\n    return {\n      content: [{ type: 'text', text: choice.text }],\n      usage: {\n        inputTokens: response.usage?.prompt_tokens,\n        outputTokens: response.usage?.completion_tokens,\n        totalTokens: response.usage?.total_tokens,\n      },\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      request: { body: args },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiCompletionChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiCompletionChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n\n              controller.enqueue({ type: 'text-start', id: '0' });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens;\n              usage.outputTokens = value.usage.completion_tokens;\n              usage.totalTokens = value.usage.total_tokens;\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs != null) {\n              providerMetadata.openai.logprobs = choice.logprobs;\n            }\n\n            if (choice?.text != null && choice.text.length > 0) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            if (!isFirstChunk) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              providerMetadata,\n              usage,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst usageSchema = z.object({\n  prompt_tokens: z.number(),\n  completion_tokens: z.number(),\n  total_tokens: z.number(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      text: z.string(),\n      finish_reason: z.string(),\n      logprobs: z\n        .object({\n          tokens: z.array(z.string()),\n          token_logprobs: z.array(z.number()),\n          top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n  usage: usageSchema.nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionChunkSchema = z.union([\n  z.object({\n    id: z.string().nullish(),\n    created: z.number().nullish(),\n    model: z.string().nullish(),\n    choices: z.array(\n      z.object({\n        text: z.string(),\n        finish_reason: z.string().nullish(),\n        index: z.number(),\n        logprobs: z\n          .object({\n            tokens: z.array(z.string()),\n            token_logprobs: z.array(z.number()),\n            top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n          })\n          .nullish(),\n      }),\n    ),\n    usage: usageSchema.nullish(),\n  }),\n  openaiErrorDataSchema,\n]);\n", "import {\n  InvalidPromptError,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompletionPrompt({\n  prompt,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV2Prompt;\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n            }\n          })\n          .filter(Boolean)\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n", "export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n", "import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n", "import { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAICompletionModelId = 'gpt-3.5-turbo-instruct' | (string & {});\n\nexport const openaiCompletionProviderOptions = z.object({\n  /**\nEcho back the prompt in addition to the completion.\n   */\n  echo: z.boolean().optional(),\n\n  /**\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in\nthe GPT tokenizer) to an associated bias value from -100 to 100. You\ncan use this tokenizer tool to convert text to token IDs. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|>\ntoken from being generated.\n */\n  logitBias: z.record(z.string(), z.number()).optional(),\n\n  /**\nThe suffix that comes after a completion of inserted text.\n */\n  suffix: z.string().optional(),\n\n  /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n */\n  user: z.string().optional(),\n\n  /**\nReturn the log probabilities of the tokens. Including logprobs will increase\nthe response size and can slow down response times. However, it can\nbe useful to better understand how the model is behaving.\nSetting to true will return the log probabilities of the tokens that\nwere generated.\nSetting to a number will return the log probabilities of the top n\ntokens that were generated.\n   */\n  logprobs: z.union([z.boolean(), z.number()]).optional(),\n});\n\nexport type OpenAICompletionProviderOptions = z.infer<\n  typeof openaiCompletionProviderOptions\n>;\n", "import {\n  EmbeddingModelV2,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIEmbeddingModelId,\n  openaiEmbeddingProviderOptions,\n} from './openai-embedding-options';\n\nexport class OpenAIEmbeddingModel implements EmbeddingModelV2<string> {\n  readonly specificationVersion = 'v2';\n  readonly modelId: OpenAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: OpenAIConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(modelId: OpenAIEmbeddingModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiEmbeddingProviderOptions,\n      })) ?? {};\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: openaiOptions.dimensions,\n        user: openaiOptions.user,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n", "import { z } from 'zod/v4';\n\nexport type OpenAIEmbeddingModelId =\n  | 'text-embedding-3-small'\n  | 'text-embedding-3-large'\n  | 'text-embedding-ada-002'\n  | (string & {});\n\nexport const openaiEmbeddingProviderOptions = z.object({\n  /**\nThe number of dimensions the resulting output embeddings should have.\nOnly supported in text-embedding-3 and later models.\n   */\n  dimensions: z.number().optional(),\n\n  /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n*/\n  user: z.string().optional(),\n});\n\nexport type OpenAIEmbeddingProviderOptions = z.infer<\n  typeof openaiEmbeddingProviderOptions\n>;\n", "import { ImageModelV2, ImageModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIImageModelId,\n  hasDefaultResponseFormat,\n  modelMaxImagesPerCall,\n} from './openai-image-options';\n\ninterface OpenAIImageModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAIImageModel implements ImageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get maxImagesPerCall(): number {\n    return modelMaxImagesPerCall[this.modelId] ?? 1;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAIImageModelId,\n    private readonly config: OpenAIImageModelConfig,\n  ) {}\n\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV2['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV2['doGenerate']>>\n  > {\n    const warnings: Array<ImageModelV2CallWarning> = [];\n\n    if (aspectRatio != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'aspectRatio',\n        details:\n          'This model does not support aspect ratio. Use `size` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { value: response, responseHeaders } = await postJsonToApi({\n      url: this.config.url({\n        path: '/images/generations',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(providerOptions.openai ?? {}),\n        ...(!hasDefaultResponseFormat.has(this.modelId)\n          ? { response_format: 'b64_json' }\n          : {}),\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      images: response.data.map(item => item.b64_json),\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n      providerMetadata: {\n        openai: {\n          images: response.data.map(item =>\n            item.revised_prompt\n              ? {\n                  revisedPrompt: item.revised_prompt,\n                }\n              : null,\n          ),\n        },\n      },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiImageResponseSchema = z.object({\n  data: z.array(\n    z.object({ b64_json: z.string(), revised_prompt: z.string().optional() }),\n  ),\n});\n", "export type OpenAIImageModelId =\n  | 'gpt-image-1'\n  | 'dall-e-3'\n  | 'dall-e-2'\n  | (string & {});\n\n// https://platform.openai.com/docs/guides/images\nexport const modelMaxImagesPerCall: Record<OpenAIImageModelId, number> = {\n  'dall-e-3': 1,\n  'dall-e-2': 10,\n  'gpt-image-1': 10,\n};\n\nexport const hasDefaultResponseFormat = new Set(['gpt-image-1']);\n", "import { createProviderDefinedToolFactoryWithOutputSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const codeInterpreterInputSchema = z.object({\n  code: z.string().nullish(),\n  containerId: z.string(),\n});\n\nexport const codeInterpreterOutputSchema = z.object({\n  outputs: z\n    .array(\n      z.discriminatedUnion('type', [\n        z.object({ type: z.literal('logs'), logs: z.string() }),\n        z.object({ type: z.literal('image'), url: z.string() }),\n      ]),\n    )\n    .nullish(),\n});\n\nexport const codeInterpreterArgsSchema = z.object({\n  container: z\n    .union([\n      z.string(),\n      z.object({\n        fileIds: z.array(z.string()).optional(),\n      }),\n    ])\n    .optional(),\n});\n\ntype CodeInterpreterArgs = {\n  /**\n   * The code interpreter container.\n   * Can be a container ID\n   * or an object that specifies uploaded file IDs to make available to your code.\n   */\n  container?: string | { fileIds?: string[] };\n};\n\nexport const codeInterpreterToolFactory =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {\n      /**\n       * The code to run, or null if not available.\n       */\n      code?: string | null;\n\n      /**\n       * The ID of the container used to run the code.\n       */\n      containerId: string;\n    },\n    {\n      /**\n       * The outputs generated by the code interpreter, such as logs or images.\n       * Can be null if no outputs are available.\n       */\n      outputs?: Array<\n        | {\n            type: 'logs';\n\n            /**\n             * The logs output from the code interpreter.\n             */\n            logs: string;\n          }\n        | {\n            type: 'image';\n\n            /**\n             * The URL of the image output from the code interpreter.\n             */\n            url: string;\n          }\n      > | null;\n    },\n    CodeInterpreterArgs\n  >({\n    id: 'openai.code_interpreter',\n    name: 'code_interpreter',\n    inputSchema: codeInterpreterInputSchema,\n    outputSchema: codeInterpreterOutputSchema,\n  });\n\nexport const codeInterpreter = (\n  args: CodeInterpreterArgs = {}, // default\n) => {\n  return codeInterpreterToolFactory(args);\n};\n", "import { createProviderDefinedToolFactoryWithOutputSchema } from '@ai-sdk/provider-utils';\nimport {\n  OpenAIResponsesFileSearchToolComparisonFilter,\n  OpenAIResponsesFileSearchToolCompoundFilter,\n} from '../responses/openai-responses-api-types';\nimport { z } from 'zod/v4';\n\nconst comparisonFilterSchema = z.object({\n  key: z.string(),\n  type: z.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']),\n  value: z.union([z.string(), z.number(), z.boolean()]),\n});\n\nconst compoundFilterSchema: z.ZodType<any> = z.object({\n  type: z.enum(['and', 'or']),\n  filters: z.array(\n    z.union([comparisonFilterSchema, z.lazy(() => compoundFilterSchema)]),\n  ),\n});\n\nexport const fileSearchArgsSchema = z.object({\n  vectorStoreIds: z.array(z.string()),\n  maxNumResults: z.number().optional(),\n  ranking: z\n    .object({\n      ranker: z.string().optional(),\n      scoreThreshold: z.number().optional(),\n    })\n    .optional(),\n  filters: z.union([comparisonFilterSchema, compoundFilterSchema]).optional(),\n});\n\nexport const fileSearchOutputSchema = z.object({\n  queries: z.array(z.string()),\n  results: z\n    .array(\n      z.object({\n        attributes: z.record(z.string(), z.unknown()),\n        fileId: z.string(),\n        filename: z.string(),\n        score: z.number(),\n        text: z.string(),\n      }),\n    )\n    .nullable(),\n});\n\nexport const fileSearch = createProviderDefinedToolFactoryWithOutputSchema<\n  {},\n  {\n    /**\n     * The search query to execute.\n     */\n    queries: string[];\n\n    /**\n     * The results of the file search tool call.\n     */\n    results:\n      | null\n      | {\n          /**\n           * Set of 16 key-value pairs that can be attached to an object.\n           * This can be useful for storing additional information about the object\n           * in a structured format, and querying for objects via API or the dashboard.\n           * Keys are strings with a maximum length of 64 characters.\n           * Values are strings with a maximum length of 512 characters, booleans, or numbers.\n           */\n          attributes: Record<string, unknown>;\n\n          /**\n           * The unique ID of the file.\n           */\n          fileId: string;\n\n          /**\n           * The name of the file.\n           */\n          filename: string;\n\n          /**\n           * The relevance score of the file - a value between 0 and 1.\n           */\n          score: number;\n\n          /**\n           * The text that was retrieved from the file.\n           */\n          text: string;\n        }[];\n  },\n  {\n    /**\n     * List of vector store IDs to search through.\n     */\n    vectorStoreIds: string[];\n\n    /**\n     * Maximum number of search results to return. Defaults to 10.\n     */\n    maxNumResults?: number;\n\n    /**\n     * Ranking options for the search.\n     */\n    ranking?: {\n      /**\n       * The ranker to use for the file search.\n       */\n      ranker?: string;\n\n      /**\n       * The score threshold for the file search, a number between 0 and 1.\n       * Numbers closer to 1 will attempt to return only the most relevant results,\n       * but may return fewer results.\n       */\n      scoreThreshold?: number;\n    };\n\n    /**\n     * A filter to apply.\n     */\n    filters?:\n      | OpenAIResponsesFileSearchToolComparisonFilter\n      | OpenAIResponsesFileSearchToolCompoundFilter;\n  }\n>({\n  id: 'openai.file_search',\n  name: 'file_search',\n  inputSchema: z.object({}),\n  outputSchema: fileSearchOutputSchema,\n});\n", "import { createProviderDefinedToolFactoryWithOutputSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const imageGenerationArgsSchema = z\n  .object({\n    background: z.enum(['auto', 'opaque', 'transparent']).optional(),\n    inputFidelity: z.enum(['low', 'high']).optional(),\n    inputImageMask: z\n      .object({\n        fileId: z.string().optional(),\n        imageUrl: z.string().optional(),\n      })\n      .optional(),\n    model: z.string().optional(),\n    moderation: z.enum(['auto']).optional(),\n    outputCompression: z.number().int().min(0).max(100).optional(),\n    outputFormat: z.enum(['png', 'jpeg', 'webp']).optional(),\n    quality: z.enum(['auto', 'low', 'medium', 'high']).optional(),\n    size: z.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional(),\n  })\n  .strict();\n\nexport const imageGenerationOutputSchema = z.object({\n  result: z.string(),\n});\n\ntype ImageGenerationArgs = {\n  /**\n   * Background type for the generated image. Default is 'auto'.\n   */\n  background?: 'auto' | 'opaque' | 'transparent';\n\n  /**\n   * Input fidelity for the generated image. Default is 'low'.\n   */\n  inputFidelity?: 'low' | 'high';\n\n  /**\n   * Optional mask for inpainting.\n   * Contains image_url (string, optional) and file_id (string, optional).\n   */\n  inputImageMask?: {\n    /**\n     * File ID for the mask image.\n     */\n    fileId?: string;\n\n    /**\n     * Base64-encoded mask image.\n     */\n    imageUrl?: string;\n  };\n\n  /**\n   * The image generation model to use. Default: gpt-image-1.\n   */\n  model?: string;\n\n  /**\n   * Moderation level for the generated image. Default: auto.\n   */\n  moderation?: 'auto';\n\n  /**\n   * Compression level for the output image. Default: 100.\n   */\n  outputCompression?: number;\n\n  /**\n   * The output format of the generated image. One of png, webp, or jpeg.\n   * Default: png\n   */\n  outputFormat?: 'png' | 'jpeg' | 'webp';\n\n  /**\n   * The quality of the generated image.\n   * One of low, medium, high, or auto. Default: auto.\n   */\n  quality?: 'auto' | 'low' | 'medium' | 'high';\n\n  /**\n   * The size of the generated image.\n   * One of 1024x1024, 1024x1536, 1536x1024, or auto.\n   * Default: auto.\n   */\n  size?: 'auto' | '1024x1024' | '1024x1536' | '1536x1024';\n};\n\nconst imageGenerationToolFactory =\n  createProviderDefinedToolFactoryWithOutputSchema<\n    {},\n    {\n      /**\n       * The generated image encoded in base64.\n       */\n      result: string;\n    },\n    ImageGenerationArgs\n  >({\n    id: 'openai.image_generation',\n    name: 'image_generation',\n    inputSchema: z.object({}),\n    outputSchema: imageGenerationOutputSchema,\n  });\n\nexport const imageGeneration = (\n  args: ImageGenerationArgs = {}, // default\n) => {\n  return imageGenerationToolFactory(args);\n};\n", "import { createProviderDefinedToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const webSearchArgsSchema = z.object({\n  filters: z\n    .object({\n      allowedDomains: z.array(z.string()).optional(),\n    })\n    .optional(),\n\n  searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n\n  userLocation: z\n    .object({\n      type: z.literal('approximate'),\n      country: z.string().optional(),\n      city: z.string().optional(),\n      region: z.string().optional(),\n      timezone: z.string().optional(),\n    })\n    .optional(),\n});\n\nexport const webSearchToolFactory = createProviderDefinedToolFactory<\n  {\n    // Web search doesn't take input parameters - it's controlled by the prompt\n  },\n  {\n    /**\n     * Filters for the search.\n     */\n    filters?: {\n      /**\n       * Allowed domains for the search.\n       * If not provided, all domains are allowed.\n       * Subdomains of the provided domains are allowed as well.\n       */\n      allowedDomains?: string[];\n    };\n\n    /**\n     * Search context size to use for the web search.\n     * - high: Most comprehensive context, highest cost, slower response\n     * - medium: Balanced context, cost, and latency (default)\n     * - low: Least context, lowest cost, fastest response\n     */\n    searchContextSize?: 'low' | 'medium' | 'high';\n\n    /**\n     * User location information to provide geographically relevant search results.\n     */\n    userLocation?: {\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: 'approximate';\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country?: string;\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city?: string;\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region?: string;\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone?: string;\n    };\n  }\n>({\n  id: 'openai.web_search',\n  name: 'web_search',\n  inputSchema: z.object({\n    action: z\n      .discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().nullish(),\n        }),\n        z.object({\n          type: z.literal('open_page'),\n          url: z.string(),\n        }),\n        z.object({\n          type: z.literal('find'),\n          url: z.string(),\n          pattern: z.string(),\n        }),\n      ])\n      .nullish(),\n  }),\n});\n\nexport const webSearch = (\n  args: Parameters<typeof webSearchToolFactory>[0] = {}, // default\n) => {\n  return webSearchToolFactory(args);\n};\n", "import { createProviderDefinedToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// Args validation schema\nexport const webSearchPreviewArgsSchema = z.object({\n  /**\n   * Search context size to use for the web search.\n   * - high: Most comprehensive context, highest cost, slower response\n   * - medium: Balanced context, cost, and latency (default)\n   * - low: Least context, lowest cost, fastest response\n   */\n  searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n\n  /**\n   * User location information to provide geographically relevant search results.\n   */\n  userLocation: z\n    .object({\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: z.literal('approximate'),\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country: z.string().optional(),\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city: z.string().optional(),\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region: z.string().optional(),\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone: z.string().optional(),\n    })\n    .optional(),\n});\n\nexport const webSearchPreview = createProviderDefinedToolFactory<\n  {\n    // Web search doesn't take input parameters - it's controlled by the prompt\n  },\n  {\n    /**\n     * Search context size to use for the web search.\n     * - high: Most comprehensive context, highest cost, slower response\n     * - medium: Balanced context, cost, and latency (default)\n     * - low: Least context, lowest cost, fastest response\n     */\n    searchContextSize?: 'low' | 'medium' | 'high';\n\n    /**\n     * User location information to provide geographically relevant search results.\n     */\n    userLocation?: {\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: 'approximate';\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country?: string;\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city?: string;\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region?: string;\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone?: string;\n    };\n  }\n>({\n  id: 'openai.web_search_preview',\n  name: 'web_search_preview',\n  inputSchema: z.object({\n    action: z\n      .discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().nullish(),\n        }),\n        z.object({\n          type: z.literal('open_page'),\n          url: z.string(),\n        }),\n        z.object({\n          type: z.literal('find'),\n          url: z.string(),\n          pattern: z.string(),\n        }),\n      ])\n      .nullish(),\n  }),\n});\n", "import { codeInterpreter } from './tool/code-interpreter';\nimport { fileSearch } from './tool/file-search';\nimport { imageGeneration } from './tool/image-generation';\nimport { webSearch } from './tool/web-search';\nimport { webSearchPreview } from './tool/web-search-preview';\n\nexport const openaiTools = {\n  /**\n   * The Code Interpreter tool allows models to write and run Python code in a\n   * sandboxed environment to solve complex problems in domains like data analysis,\n   * coding, and math.\n   *\n   * @param container - The container to use for the code interpreter.\n   *\n   * Must have name `code_interpreter`.\n   */\n  codeInterpreter,\n\n  /**\n   * File search is a tool available in the Responses API. It enables models to\n   * retrieve information in a knowledge base of previously uploaded files through\n   * semantic and keyword search.\n   *\n   * Must have name `file_search`.\n   *\n   * @param vectorStoreIds - The vector store IDs to use for the file search.\n   * @param maxNumResults - The maximum number of results to return.\n   * @param ranking - The ranking options to use for the file search.\n   * @param filters - The filters to use for the file search.\n   */\n  fileSearch,\n\n  /**\n   * The image generation tool allows you to generate images using a text prompt,\n   * and optionally image inputs. It leverages the GPT Image model,\n   * and automatically optimizes text inputs for improved performance.\n   *\n   * Must have name `image_generation`.\n   *\n   * @param size - Image dimensions (e.g., 1024x1024, 1024x1536)\n   * @param quality - Rendering quality (e.g. low, medium, high)\n   * @param format - File output format\n   * @param compression - Compression level (0-100%) for JPEG and WebP formats\n   * @param background - Transparent or opaque\n   */\n  imageGeneration,\n\n  /**\n   * Web search allows models to access up-to-date information from the internet\n   * and provide answers with sourced citations.\n   *\n   * Must have name `web_search_preview`.\n   *\n   * @param searchContextSize - The search context size to use for the web search.\n   * @param userLocation - The user location to use for the web search.\n   *\n   * @deprecated Use `webSearch` instead.\n   */\n  webSearchPreview,\n\n  /**\n   * Web search allows models to access up-to-date information from the internet\n   * and provide answers with sourced citations.\n   *\n   * Must have name `web_search`.\n   *\n   * @param filters - The filters to use for the web search.\n   * @param searchContextSize - The search context size to use for the web search.\n   * @param userLocation - The user location to use for the web search.\n   */\n  webSearch,\n};\n", "import {\n  APICallError,\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2ProviderDefinedTool,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  codeInterpreterInputSchema,\n  codeInterpreterOutputSchema,\n} from '../tool/code-interpreter';\nimport { fileSearchOutputSchema } from '../tool/file-search';\nimport { imageGenerationOutputSchema } from '../tool/image-generation';\nimport { convertToOpenAIResponsesInput } from './convert-to-openai-responses-input';\nimport { mapOpenAIResponseFinishReason } from './map-openai-responses-finish-reason';\nimport {\n  OpenAIResponsesIncludeOptions,\n  OpenAIResponsesIncludeValue,\n} from './openai-responses-api-types';\nimport { prepareResponsesTools } from './openai-responses-prepare-tools';\nimport { OpenAIResponsesModelId } from './openai-responses-settings';\n\nconst webSearchCallItem = z.object({\n  type: z.literal('web_search_call'),\n  id: z.string(),\n  status: z.string(),\n  action: z\n    .discriminatedUnion('type', [\n      z.object({\n        type: z.literal('search'),\n        query: z.string().nullish(),\n      }),\n      z.object({\n        type: z.literal('open_page'),\n        url: z.string(),\n      }),\n      z.object({\n        type: z.literal('find'),\n        url: z.string(),\n        pattern: z.string(),\n      }),\n    ])\n    .nullish(),\n});\n\nconst fileSearchCallItem = z.object({\n  type: z.literal('file_search_call'),\n  id: z.string(),\n  queries: z.array(z.string()),\n  results: z\n    .array(\n      z.object({\n        attributes: z.record(z.string(), z.unknown()),\n        file_id: z.string(),\n        filename: z.string(),\n        score: z.number(),\n        text: z.string(),\n      }),\n    )\n    .nullish(),\n});\n\nconst codeInterpreterCallItem = z.object({\n  type: z.literal('code_interpreter_call'),\n  id: z.string(),\n  code: z.string().nullable(),\n  container_id: z.string(),\n  outputs: z\n    .array(\n      z.discriminatedUnion('type', [\n        z.object({ type: z.literal('logs'), logs: z.string() }),\n        z.object({ type: z.literal('image'), url: z.string() }),\n      ]),\n    )\n    .nullable(),\n});\n\nconst imageGenerationCallItem = z.object({\n  type: z.literal('image_generation_call'),\n  id: z.string(),\n  result: z.string(),\n});\n\n/**\n * `top_logprobs` request body argument can be set to an integer between\n * 0 and 20 specifying the number of most likely tokens to return at each\n * token position, each with an associated log probability.\n *\n * @see https://platform.openai.com/docs/api-reference/responses/create#responses_create-top_logprobs\n */\nconst TOP_LOGPROBS_MAX = 20;\n\nconst LOGPROBS_SCHEMA = z.array(\n  z.object({\n    token: z.string(),\n    logprob: z.number(),\n    top_logprobs: z.array(\n      z.object({\n        token: z.string(),\n        logprob: z.number(),\n      }),\n    ),\n  }),\n);\n\nexport class OpenAIResponsesLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIResponsesModelId;\n\n  private readonly config: OpenAIConfig;\n\n  constructor(modelId: OpenAIResponsesModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    'image/*': [/^https?:\\/\\/.*$/],\n    'application/pdf': [/^https?:\\/\\/.*$/],\n  };\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    maxOutputTokens,\n    temperature,\n    stopSequences,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    seed,\n    prompt,\n    providerOptions,\n    tools,\n    toolChoice,\n    responseFormat,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n    const modelConfig = getResponsesModelConfig(this.modelId);\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    if (presencePenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'presencePenalty',\n      });\n    }\n\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'frequencyPenalty',\n      });\n    }\n\n    if (stopSequences != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'stopSequences' });\n    }\n\n    const openaiOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiResponsesProviderOptionsSchema,\n    });\n\n    const { input, warnings: inputWarnings } =\n      await convertToOpenAIResponsesInput({\n        prompt,\n        systemMessageMode: modelConfig.systemMessageMode,\n        fileIdPrefixes: this.config.fileIdPrefixes,\n        store: openaiOptions?.store ?? true,\n      });\n\n    warnings.push(...inputWarnings);\n\n    const strictJsonSchema = openaiOptions?.strictJsonSchema ?? false;\n\n    let include: OpenAIResponsesIncludeOptions = openaiOptions?.include;\n\n    function addInclude(key: OpenAIResponsesIncludeValue) {\n      include = include != null ? [...include, key] : [key];\n    }\n\n    function hasOpenAITool(id: string) {\n      return (\n        tools?.find(\n          tool => tool.type === 'provider-defined' && tool.id === id,\n        ) != null\n      );\n    }\n\n    // when logprobs are requested, automatically include them:\n    const topLogprobs =\n      typeof openaiOptions?.logprobs === 'number'\n        ? openaiOptions?.logprobs\n        : openaiOptions?.logprobs === true\n          ? TOP_LOGPROBS_MAX\n          : undefined;\n\n    if (topLogprobs) {\n      addInclude('message.output_text.logprobs');\n    }\n\n    // when a web search tool is present, automatically include the sources:\n    const webSearchToolName = (\n      tools?.find(\n        tool =>\n          tool.type === 'provider-defined' &&\n          (tool.id === 'openai.web_search' ||\n            tool.id === 'openai.web_search_preview'),\n      ) as LanguageModelV2ProviderDefinedTool | undefined\n    )?.name;\n\n    if (webSearchToolName) {\n      addInclude('web_search_call.action.sources');\n    }\n\n    // when a code interpreter tool is present, automatically include the outputs:\n    if (hasOpenAITool('openai.code_interpreter')) {\n      addInclude('code_interpreter_call.outputs');\n    }\n\n    const baseArgs = {\n      model: this.modelId,\n      input,\n      temperature,\n      top_p: topP,\n      max_output_tokens: maxOutputTokens,\n\n      ...((responseFormat?.type === 'json' || openaiOptions?.textVerbosity) && {\n        text: {\n          ...(responseFormat?.type === 'json' && {\n            format:\n              responseFormat.schema != null\n                ? {\n                    type: 'json_schema',\n                    strict: strictJsonSchema,\n                    name: responseFormat.name ?? 'response',\n                    description: responseFormat.description,\n                    schema: responseFormat.schema,\n                  }\n                : { type: 'json_object' },\n          }),\n          ...(openaiOptions?.textVerbosity && {\n            verbosity: openaiOptions.textVerbosity,\n          }),\n        },\n      }),\n\n      // provider options:\n      max_tool_calls: openaiOptions?.maxToolCalls,\n      metadata: openaiOptions?.metadata,\n      parallel_tool_calls: openaiOptions?.parallelToolCalls,\n      previous_response_id: openaiOptions?.previousResponseId,\n      store: openaiOptions?.store,\n      user: openaiOptions?.user,\n      instructions: openaiOptions?.instructions,\n      service_tier: openaiOptions?.serviceTier,\n      include,\n      prompt_cache_key: openaiOptions?.promptCacheKey,\n      safety_identifier: openaiOptions?.safetyIdentifier,\n      top_logprobs: topLogprobs,\n\n      // model-specific settings:\n      ...(modelConfig.isReasoningModel &&\n        (openaiOptions?.reasoningEffort != null ||\n          openaiOptions?.reasoningSummary != null) && {\n          reasoning: {\n            ...(openaiOptions?.reasoningEffort != null && {\n              effort: openaiOptions.reasoningEffort,\n            }),\n            ...(openaiOptions?.reasoningSummary != null && {\n              summary: openaiOptions.reasoningSummary,\n            }),\n          },\n        }),\n      ...(modelConfig.requiredAutoTruncation && {\n        truncation: 'auto',\n      }),\n    };\n\n    if (modelConfig.isReasoningModel) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n    } else {\n      if (openaiOptions?.reasoningEffort != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningEffort',\n          details: 'reasoningEffort is not supported for non-reasoning models',\n        });\n      }\n\n      if (openaiOptions?.reasoningSummary != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningSummary',\n          details: 'reasoningSummary is not supported for non-reasoning models',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions?.serviceTier === 'flex' &&\n      !modelConfig.supportsFlexProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions?.serviceTier === 'priority' &&\n      !modelConfig.supportsPriorityProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareResponsesTools({\n      tools,\n      toolChoice,\n      strictJsonSchema,\n    });\n\n    return {\n      webSearchToolName,\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n    } = await this.getArgs(options);\n    const url = this.config.url({\n      path: '/responses',\n      modelId: this.modelId,\n    });\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        z.object({\n          id: z.string(),\n          created_at: z.number(),\n          error: z\n            .object({\n              code: z.string(),\n              message: z.string(),\n            })\n            .nullish(),\n          model: z.string(),\n          output: z.array(\n            z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('message'),\n                role: z.literal('assistant'),\n                id: z.string(),\n                content: z.array(\n                  z.object({\n                    type: z.literal('output_text'),\n                    text: z.string(),\n                    logprobs: LOGPROBS_SCHEMA.nullish(),\n                    annotations: z.array(\n                      z.discriminatedUnion('type', [\n                        z.object({\n                          type: z.literal('url_citation'),\n                          start_index: z.number(),\n                          end_index: z.number(),\n                          url: z.string(),\n                          title: z.string(),\n                        }),\n                        z.object({\n                          type: z.literal('file_citation'),\n                          file_id: z.string(),\n                          filename: z.string().nullish(),\n                          index: z.number().nullish(),\n                          start_index: z.number().nullish(),\n                          end_index: z.number().nullish(),\n                          quote: z.string().nullish(),\n                        }),\n                        z.object({\n                          type: z.literal('container_file_citation'),\n                        }),\n                      ]),\n                    ),\n                  }),\n                ),\n              }),\n              webSearchCallItem,\n              fileSearchCallItem,\n              codeInterpreterCallItem,\n              imageGenerationCallItem,\n              z.object({\n                type: z.literal('function_call'),\n                call_id: z.string(),\n                name: z.string(),\n                arguments: z.string(),\n                id: z.string(),\n              }),\n              z.object({\n                type: z.literal('computer_call'),\n                id: z.string(),\n                status: z.string().optional(),\n              }),\n              z.object({\n                type: z.literal('reasoning'),\n                id: z.string(),\n                encrypted_content: z.string().nullish(),\n                summary: z.array(\n                  z.object({\n                    type: z.literal('summary_text'),\n                    text: z.string(),\n                  }),\n                ),\n              }),\n            ]),\n          ),\n          service_tier: z.string().nullish(),\n          incomplete_details: z.object({ reason: z.string() }).nullish(),\n          usage: usageSchema,\n        }),\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    if (response.error) {\n      throw new APICallError({\n        message: response.error.message,\n        url,\n        requestBodyValues: body,\n        statusCode: 400,\n        responseHeaders,\n        responseBody: rawResponse as string,\n        isRetryable: false,\n      });\n    }\n\n    const content: Array<LanguageModelV2Content> = [];\n    const logprobs: Array<z.infer<typeof LOGPROBS_SCHEMA>> = [];\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    // map response content to content array\n    for (const part of response.output) {\n      switch (part.type) {\n        case 'reasoning': {\n          // when there are no summary parts, we need to add an empty reasoning part:\n          if (part.summary.length === 0) {\n            part.summary.push({ type: 'summary_text', text: '' });\n          }\n\n          for (const summary of part.summary) {\n            content.push({\n              type: 'reasoning' as const,\n              text: summary.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                  reasoningEncryptedContent: part.encrypted_content ?? null,\n                },\n              },\n            });\n          }\n          break;\n        }\n\n        case 'image_generation_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'image_generation',\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'image_generation',\n            result: {\n              result: part.result,\n            } satisfies z.infer<typeof imageGenerationOutputSchema>,\n            providerExecuted: true,\n          });\n\n          break;\n        }\n\n        case 'message': {\n          for (const contentPart of part.content) {\n            if (\n              options.providerOptions?.openai?.logprobs &&\n              contentPart.logprobs\n            ) {\n              logprobs.push(contentPart.logprobs);\n            }\n\n            content.push({\n              type: 'text',\n              text: contentPart.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                },\n              },\n            });\n\n            for (const annotation of contentPart.annotations) {\n              if (annotation.type === 'url_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: this.config.generateId?.() ?? generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              } else if (annotation.type === 'file_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title: annotation.quote ?? annotation.filename ?? 'Document',\n                  filename: annotation.filename ?? annotation.file_id,\n                });\n              }\n            }\n          }\n\n          break;\n        }\n\n        case 'function_call': {\n          hasFunctionCall = true;\n\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: part.name,\n            input: part.arguments,\n            providerMetadata: {\n              openai: {\n                itemId: part.id,\n              },\n            },\n          });\n          break;\n        }\n\n        case 'web_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: webSearchToolName ?? 'web_search',\n            input: JSON.stringify({ action: part.action }),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: webSearchToolName ?? 'web_search',\n            result: { status: part.status },\n            providerExecuted: true,\n          });\n\n          break;\n        }\n\n        case 'computer_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            input: '',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            result: {\n              type: 'computer_use_tool_result',\n              status: part.status || 'completed',\n            },\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'file_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            input: '{}',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            result: {\n              queries: part.queries,\n              results:\n                part.results?.map(result => ({\n                  attributes: result.attributes,\n                  fileId: result.file_id,\n                  filename: result.filename,\n                  score: result.score,\n                  text: result.text,\n                })) ?? null,\n            } satisfies z.infer<typeof fileSearchOutputSchema>,\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'code_interpreter_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'code_interpreter',\n            input: JSON.stringify({\n              code: part.code,\n              containerId: part.container_id,\n            } satisfies z.infer<typeof codeInterpreterInputSchema>),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'code_interpreter',\n            result: {\n              outputs: part.outputs,\n            } satisfies z.infer<typeof codeInterpreterOutputSchema>,\n            providerExecuted: true,\n          });\n          break;\n        }\n      }\n    }\n\n    const providerMetadata: SharedV2ProviderMetadata = {\n      openai: { responseId: response.id },\n    };\n\n    if (logprobs.length > 0) {\n      providerMetadata.openai.logprobs = logprobs;\n    }\n\n    if (typeof response.service_tier === 'string') {\n      providerMetadata.openai.serviceTier = response.service_tier;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIResponseFinishReason({\n        finishReason: response.incomplete_details?.reason,\n        hasFunctionCall,\n      }),\n      usage: {\n        inputTokens: response.usage.input_tokens,\n        outputTokens: response.usage.output_tokens,\n        totalTokens: response.usage.input_tokens + response.usage.output_tokens,\n        reasoningTokens:\n          response.usage.output_tokens_details?.reasoning_tokens ?? undefined,\n        cachedInputTokens:\n          response.usage.input_tokens_details?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        id: response.id,\n        timestamp: new Date(response.created_at * 1000),\n        modelId: response.model,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const {\n      args: body,\n      warnings,\n      webSearchToolName,\n    } = await this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/responses',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...body,\n        stream: true,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiResponsesChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const self = this;\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    const logprobs: Array<z.infer<typeof LOGPROBS_SCHEMA>> = [];\n    let responseId: string | null = null;\n    const ongoingToolCalls: Record<\n      number,\n      { toolName: string; toolCallId: string } | undefined\n    > = {};\n\n    // flag that checks if there have been client-side tool calls (not executed by openai)\n    let hasFunctionCall = false;\n\n    const activeReasoning: Record<\n      string,\n      {\n        encryptedContent?: string | null;\n        summaryParts: number[];\n      }\n    > = {};\n\n    let serviceTier: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiResponsesChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            if (isResponseOutputItemAddedChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: value.item.name,\n                  toolCallId: value.item.call_id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.call_id,\n                  toolName: value.item.name,\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: webSearchToolName ?? 'web_search',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: webSearchToolName ?? 'web_search',\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'computer_use',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'computer_use',\n                });\n              } else if (value.item.type === 'file_search_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'image_generation',\n                  input: '{}',\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-start',\n                  id: value.item.id,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (isResponseOutputItemAddedReasoningChunk(value)) {\n                activeReasoning[value.item.id] = {\n                  encryptedContent: value.item.encrypted_content,\n                  summaryParts: [0],\n                };\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item.id}:0`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                      reasoningEncryptedContent:\n                        value.item.encrypted_content ?? null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseOutputItemDoneChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasFunctionCall = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.call_id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: value.item.name,\n                  input: value.item.arguments,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search',\n                  input: JSON.stringify({ action: value.item.action }),\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search',\n                  result: { status: value.item.status },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  input: '',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  result: {\n                    type: 'computer_use_tool_result',\n                    status: value.item.status || 'completed',\n                  },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'file_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  result: {\n                    queries: value.item.queries,\n                    results:\n                      value.item.results?.map(result => ({\n                        attributes: result.attributes,\n                        fileId: result.file_id,\n                        filename: result.filename,\n                        score: result.score,\n                        text: result.text,\n                      })) ?? null,\n                  } satisfies z.infer<typeof fileSearchOutputSchema>,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'code_interpreter_call') {\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'code_interpreter',\n                  input: JSON.stringify({\n                    code: value.item.code,\n                    containerId: value.item.container_id,\n                  } satisfies z.infer<typeof codeInterpreterInputSchema>),\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'code_interpreter',\n                  result: {\n                    outputs: value.item.outputs,\n                  } satisfies z.infer<typeof codeInterpreterOutputSchema>,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'image_generation_call') {\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'image_generation',\n                  result: {\n                    result: value.item.result,\n                  } satisfies z.infer<typeof imageGenerationOutputSchema>,\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-end',\n                  id: value.item.id,\n                });\n              } else if (isResponseOutputItemDoneReasoningChunk(value)) {\n                const activeReasoningPart = activeReasoning[value.item.id];\n\n                for (const summaryIndex of activeReasoningPart.summaryParts) {\n                  controller.enqueue({\n                    type: 'reasoning-end',\n                    id: `${value.item.id}:${summaryIndex}`,\n                    providerMetadata: {\n                      openai: {\n                        itemId: value.item.id,\n                        reasoningEncryptedContent:\n                          value.item.encrypted_content ?? null,\n                      },\n                    },\n                  });\n                }\n\n                delete activeReasoning[value.item.id];\n              }\n            } else if (isResponseFunctionCallArgumentsDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: value.delta,\n                });\n              }\n            } else if (isResponseCreatedChunk(value)) {\n              responseId = value.response.id;\n              controller.enqueue({\n                type: 'response-metadata',\n                id: value.response.id,\n                timestamp: new Date(value.response.created_at * 1000),\n                modelId: value.response.model,\n              });\n            } else if (isTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: value.item_id,\n                delta: value.delta,\n              });\n\n              if (options.providerOptions?.openai?.logprobs && value.logprobs) {\n                logprobs.push(value.logprobs);\n              }\n            } else if (isResponseReasoningSummaryPartAddedChunk(value)) {\n              // the first reasoning start is pushed in isResponseOutputItemAddedReasoningChunk.\n              if (value.summary_index > 0) {\n                activeReasoning[value.item_id]?.summaryParts.push(\n                  value.summary_index,\n                );\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item_id,\n                      reasoningEncryptedContent:\n                        activeReasoning[value.item_id]?.encryptedContent ??\n                        null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseReasoningSummaryTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'reasoning-delta',\n                id: `${value.item_id}:${value.summary_index}`,\n                delta: value.delta,\n                providerMetadata: {\n                  openai: {\n                    itemId: value.item_id,\n                  },\n                },\n              });\n            } else if (isResponseFinishedChunk(value)) {\n              finishReason = mapOpenAIResponseFinishReason({\n                finishReason: value.response.incomplete_details?.reason,\n                hasFunctionCall,\n              });\n              usage.inputTokens = value.response.usage.input_tokens;\n              usage.outputTokens = value.response.usage.output_tokens;\n              usage.totalTokens =\n                value.response.usage.input_tokens +\n                value.response.usage.output_tokens;\n              usage.reasoningTokens =\n                value.response.usage.output_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.response.usage.input_tokens_details?.cached_tokens ??\n                undefined;\n              if (typeof value.response.service_tier === 'string') {\n                serviceTier = value.response.service_tier;\n              }\n            } else if (isResponseAnnotationAddedChunk(value)) {\n              if (value.annotation.type === 'url_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: self.config.generateId?.() ?? generateId(),\n                  url: value.annotation.url,\n                  title: value.annotation.title,\n                });\n              } else if (value.annotation.type === 'file_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    value.annotation.quote ??\n                    value.annotation.filename ??\n                    'Document',\n                  filename:\n                    value.annotation.filename ?? value.annotation.file_id,\n                });\n              }\n            } else if (isErrorChunk(value)) {\n              controller.enqueue({ type: 'error', error: value });\n            }\n          },\n\n          flush(controller) {\n            const providerMetadata: SharedV2ProviderMetadata = {\n              openai: {\n                responseId,\n              },\n            };\n\n            if (logprobs.length > 0) {\n              providerMetadata.openai.logprobs = logprobs;\n            }\n\n            if (serviceTier !== undefined) {\n              providerMetadata.openai.serviceTier = serviceTier;\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst usageSchema = z.object({\n  input_tokens: z.number(),\n  input_tokens_details: z\n    .object({ cached_tokens: z.number().nullish() })\n    .nullish(),\n  output_tokens: z.number(),\n  output_tokens_details: z\n    .object({ reasoning_tokens: z.number().nullish() })\n    .nullish(),\n});\n\nconst textDeltaChunkSchema = z.object({\n  type: z.literal('response.output_text.delta'),\n  item_id: z.string(),\n  delta: z.string(),\n  logprobs: LOGPROBS_SCHEMA.nullish(),\n});\n\nconst errorChunkSchema = z.object({\n  type: z.literal('error'),\n  code: z.string(),\n  message: z.string(),\n  param: z.string().nullish(),\n  sequence_number: z.number(),\n});\n\nconst responseFinishedChunkSchema = z.object({\n  type: z.enum(['response.completed', 'response.incomplete']),\n  response: z.object({\n    incomplete_details: z.object({ reason: z.string() }).nullish(),\n    usage: usageSchema,\n    service_tier: z.string().nullish(),\n  }),\n});\n\nconst responseCreatedChunkSchema = z.object({\n  type: z.literal('response.created'),\n  response: z.object({\n    id: z.string(),\n    created_at: z.number(),\n    model: z.string(),\n    service_tier: z.string().nullish(),\n  }),\n});\n\nconst responseOutputItemAddedSchema = z.object({\n  type: z.literal('response.output_item.added'),\n  output_index: z.number(),\n  item: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('message'),\n      id: z.string(),\n    }),\n    z.object({\n      type: z.literal('reasoning'),\n      id: z.string(),\n      encrypted_content: z.string().nullish(),\n    }),\n    z.object({\n      type: z.literal('function_call'),\n      id: z.string(),\n      call_id: z.string(),\n      name: z.string(),\n      arguments: z.string(),\n    }),\n    z.object({\n      type: z.literal('web_search_call'),\n      id: z.string(),\n      status: z.string(),\n      action: z\n        .object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        })\n        .nullish(),\n    }),\n    z.object({\n      type: z.literal('computer_call'),\n      id: z.string(),\n      status: z.string(),\n    }),\n    z.object({\n      type: z.literal('file_search_call'),\n      id: z.string(),\n    }),\n    z.object({\n      type: z.literal('image_generation_call'),\n      id: z.string(),\n    }),\n  ]),\n});\n\nconst responseOutputItemDoneSchema = z.object({\n  type: z.literal('response.output_item.done'),\n  output_index: z.number(),\n  item: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('message'),\n      id: z.string(),\n    }),\n    z.object({\n      type: z.literal('reasoning'),\n      id: z.string(),\n      encrypted_content: z.string().nullish(),\n    }),\n    z.object({\n      type: z.literal('function_call'),\n      id: z.string(),\n      call_id: z.string(),\n      name: z.string(),\n      arguments: z.string(),\n      status: z.literal('completed'),\n    }),\n    codeInterpreterCallItem,\n    imageGenerationCallItem,\n    webSearchCallItem,\n    fileSearchCallItem,\n    z.object({\n      type: z.literal('computer_call'),\n      id: z.string(),\n      status: z.literal('completed'),\n    }),\n  ]),\n});\n\nconst responseFunctionCallArgumentsDeltaSchema = z.object({\n  type: z.literal('response.function_call_arguments.delta'),\n  item_id: z.string(),\n  output_index: z.number(),\n  delta: z.string(),\n});\n\nconst responseAnnotationAddedSchema = z.object({\n  type: z.literal('response.output_text.annotation.added'),\n  annotation: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('url_citation'),\n      url: z.string(),\n      title: z.string(),\n    }),\n    z.object({\n      type: z.literal('file_citation'),\n      file_id: z.string(),\n      filename: z.string().nullish(),\n      index: z.number().nullish(),\n      start_index: z.number().nullish(),\n      end_index: z.number().nullish(),\n      quote: z.string().nullish(),\n    }),\n  ]),\n});\n\nconst responseReasoningSummaryPartAddedSchema = z.object({\n  type: z.literal('response.reasoning_summary_part.added'),\n  item_id: z.string(),\n  summary_index: z.number(),\n});\n\nconst responseReasoningSummaryTextDeltaSchema = z.object({\n  type: z.literal('response.reasoning_summary_text.delta'),\n  item_id: z.string(),\n  summary_index: z.number(),\n  delta: z.string(),\n});\n\nconst openaiResponsesChunkSchema = z.union([\n  textDeltaChunkSchema,\n  responseFinishedChunkSchema,\n  responseCreatedChunkSchema,\n  responseOutputItemAddedSchema,\n  responseOutputItemDoneSchema,\n  responseFunctionCallArgumentsDeltaSchema,\n  responseAnnotationAddedSchema,\n  responseReasoningSummaryPartAddedSchema,\n  responseReasoningSummaryTextDeltaSchema,\n  errorChunkSchema,\n  z.object({ type: z.string() }).loose(), // fallback for unknown chunks\n]);\n\ntype ExtractByType<\n  T,\n  K extends T extends { type: infer U } ? U : never,\n> = T extends { type: K } ? T : never;\n\nfunction isTextDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof textDeltaChunkSchema> {\n  return chunk.type === 'response.output_text.delta';\n}\n\nfunction isResponseOutputItemDoneChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemDoneSchema> {\n  return chunk.type === 'response.output_item.done';\n}\n\nfunction isResponseOutputItemDoneReasoningChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemDoneSchema> & {\n  item: ExtractByType<\n    z.infer<typeof responseOutputItemDoneSchema>['item'],\n    'reasoning'\n  >;\n} {\n  return (\n    isResponseOutputItemDoneChunk(chunk) && chunk.item.type === 'reasoning'\n  );\n}\n\nfunction isResponseFinishedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseFinishedChunkSchema> {\n  return (\n    chunk.type === 'response.completed' || chunk.type === 'response.incomplete'\n  );\n}\n\nfunction isResponseCreatedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseCreatedChunkSchema> {\n  return chunk.type === 'response.created';\n}\n\nfunction isResponseFunctionCallArgumentsDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseFunctionCallArgumentsDeltaSchema> {\n  return chunk.type === 'response.function_call_arguments.delta';\n}\n\nfunction isResponseOutputItemAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemAddedSchema> {\n  return chunk.type === 'response.output_item.added';\n}\n\nfunction isResponseOutputItemAddedReasoningChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemAddedSchema> & {\n  item: ExtractByType<\n    z.infer<typeof responseOutputItemAddedSchema>['item'],\n    'reasoning'\n  >;\n} {\n  return (\n    isResponseOutputItemAddedChunk(chunk) && chunk.item.type === 'reasoning'\n  );\n}\n\nfunction isResponseAnnotationAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseAnnotationAddedSchema> {\n  return chunk.type === 'response.output_text.annotation.added';\n}\n\nfunction isResponseReasoningSummaryPartAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseReasoningSummaryPartAddedSchema> {\n  return chunk.type === 'response.reasoning_summary_part.added';\n}\n\nfunction isResponseReasoningSummaryTextDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseReasoningSummaryTextDeltaSchema> {\n  return chunk.type === 'response.reasoning_summary_text.delta';\n}\n\nfunction isErrorChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof errorChunkSchema> {\n  return chunk.type === 'error';\n}\n\ntype ResponsesModelConfig = {\n  isReasoningModel: boolean;\n  systemMessageMode: 'remove' | 'system' | 'developer';\n  requiredAutoTruncation: boolean;\n  supportsFlexProcessing: boolean;\n  supportsPriorityProcessing: boolean;\n};\n\nfunction getResponsesModelConfig(modelId: string): ResponsesModelConfig {\n  const supportsFlexProcessing =\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'));\n  const supportsPriorityProcessing =\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini');\n  const defaults = {\n    requiredAutoTruncation: false,\n    systemMessageMode: 'system' as const,\n    supportsFlexProcessing,\n    supportsPriorityProcessing,\n  };\n\n  // gpt-5-chat models are non-reasoning\n  if (modelId.startsWith('gpt-5-chat')) {\n    return {\n      ...defaults,\n      isReasoningModel: false,\n    };\n  }\n\n  // o series reasoning models:\n  if (\n    modelId.startsWith('o') ||\n    modelId.startsWith('gpt-5') ||\n    modelId.startsWith('codex-') ||\n    modelId.startsWith('computer-use')\n  ) {\n    if (modelId.startsWith('o1-mini') || modelId.startsWith('o1-preview')) {\n      return {\n        ...defaults,\n        isReasoningModel: true,\n        systemMessageMode: 'remove',\n      };\n    }\n\n    return {\n      ...defaults,\n      isReasoningModel: true,\n      systemMessageMode: 'developer',\n    };\n  }\n\n  // gpt models:\n  return {\n    ...defaults,\n    isReasoningModel: false,\n  };\n}\n\n// TODO AI SDK 6: use optional here instead of nullish\nconst openaiResponsesProviderOptionsSchema = z.object({\n  include: z\n    .array(\n      z.enum([\n        'reasoning.encrypted_content',\n        'file_search_call.results',\n        'message.output_text.logprobs',\n      ]),\n    )\n    .nullish(),\n  instructions: z.string().nullish(),\n\n  /**\n   * Return the log probabilities of the tokens.\n   *\n   * Setting to true will return the log probabilities of the tokens that\n   * were generated.\n   *\n   * Setting to a number will return the log probabilities of the top n\n   * tokens that were generated.\n   *\n   * @see https://platform.openai.com/docs/api-reference/responses/create\n   * @see https://cookbook.openai.com/examples/using_logprobs\n   */\n  logprobs: z\n    .union([z.boolean(), z.number().min(1).max(TOP_LOGPROBS_MAX)])\n    .optional(),\n\n  /**\n   * The maximum number of total calls to built-in tools that can be processed in a response.\n   * This maximum number applies across all built-in tool calls, not per individual tool.\n   * Any further attempts to call a tool by the model will be ignored.\n   */\n  maxToolCalls: z.number().nullish(),\n\n  metadata: z.any().nullish(),\n  parallelToolCalls: z.boolean().nullish(),\n  previousResponseId: z.string().nullish(),\n  promptCacheKey: z.string().nullish(),\n  reasoningEffort: z.string().nullish(),\n  reasoningSummary: z.string().nullish(),\n  safetyIdentifier: z.string().nullish(),\n  serviceTier: z.enum(['auto', 'flex', 'priority']).nullish(),\n  store: z.boolean().nullish(),\n  strictJsonSchema: z.boolean().nullish(),\n  textVerbosity: z.enum(['low', 'medium', 'high']).nullish(),\n  user: z.string().nullish(),\n});\n\nexport type OpenAIResponsesProviderOptions = z.infer<\n  typeof openaiResponsesProviderOptionsSchema\n>;\n", "import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  LanguageModelV2ToolCallPart,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertToBase64, parseProviderOptions } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  OpenAIResponsesInput,\n  OpenAIResponsesReasoning,\n} from './openai-responses-api-types';\n\n/**\n * Check if a string is a file ID based on the given prefixes\n * Returns false if prefixes is undefined (disables file ID detection)\n */\nfunction isFileId(data: string, prefixes?: readonly string[]): boolean {\n  if (!prefixes) return false;\n  return prefixes.some(prefix => data.startsWith(prefix));\n}\n\nexport async function convertToOpenAIResponsesInput({\n  prompt,\n  systemMessageMode,\n  fileIdPrefixes,\n  store,\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode: 'system' | 'developer' | 'remove';\n  fileIdPrefixes?: readonly string[];\n  store: boolean;\n}): Promise<{\n  input: OpenAIResponsesInput;\n  warnings: Array<LanguageModelV2CallWarning>;\n}> {\n  const input: OpenAIResponsesInput = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            input.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            input.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        input.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'input_text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'input_image',\n                    ...(part.data instanceof URL\n                      ? { image_url: part.data.toString() }\n                      : typeof part.data === 'string' &&\n                          isFileId(part.data, fileIdPrefixes)\n                        ? { file_id: part.data }\n                        : {\n                            image_url: `data:${mediaType};base64,${convertToBase64(part.data)}`,\n                          }),\n                    detail: part.providerOptions?.openai?.imageDetail,\n                  };\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    return {\n                      type: 'input_file',\n                      file_url: part.data.toString(),\n                    };\n                  }\n                  return {\n                    type: 'input_file',\n                    ...(typeof part.data === 'string' &&\n                    isFileId(part.data, fileIdPrefixes)\n                      ? { file_id: part.data }\n                      : {\n                          filename: part.filename ?? `part-${index}.pdf`,\n                          file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                        }),\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        const reasoningMessages: Record<string, OpenAIResponsesReasoning> = {};\n        const toolCallParts: Record<string, LanguageModelV2ToolCallPart> = {};\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              input.push({\n                role: 'assistant',\n                content: [{ type: 'output_text', text: part.text }],\n                id:\n                  (part.providerOptions?.openai?.itemId as string) ?? undefined,\n              });\n              break;\n            }\n            case 'tool-call': {\n              toolCallParts[part.toolCallId] = part;\n\n              if (part.providerExecuted) {\n                break;\n              }\n\n              input.push({\n                type: 'function_call',\n                call_id: part.toolCallId,\n                name: part.toolName,\n                arguments: JSON.stringify(part.input),\n                id:\n                  (part.providerOptions?.openai?.itemId as string) ?? undefined,\n              });\n              break;\n            }\n\n            // assistant tool result parts are from provider-executed tools:\n            case 'tool-result': {\n              if (store) {\n                // use item references to refer to tool results from built-in tools\n                input.push({ type: 'item_reference', id: part.toolCallId });\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Results for OpenAI tool ${part.toolName} are not sent to the API when store is false`,\n                });\n              }\n\n              break;\n            }\n\n            case 'reasoning': {\n              const providerOptions = await parseProviderOptions({\n                provider: 'openai',\n                providerOptions: part.providerOptions,\n                schema: openaiResponsesReasoningProviderOptionsSchema,\n              });\n\n              const reasoningId = providerOptions?.itemId;\n\n              if (reasoningId != null) {\n                const existingReasoningMessage = reasoningMessages[reasoningId];\n\n                const summaryParts: Array<{\n                  type: 'summary_text';\n                  text: string;\n                }> = [];\n\n                if (part.text.length > 0) {\n                  summaryParts.push({ type: 'summary_text', text: part.text });\n                } else if (existingReasoningMessage !== undefined) {\n                  warnings.push({\n                    type: 'other',\n                    message: `Cannot append empty reasoning part to existing reasoning sequence. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                  });\n                }\n\n                if (existingReasoningMessage === undefined) {\n                  reasoningMessages[reasoningId] = {\n                    type: 'reasoning',\n                    id: reasoningId,\n                    encrypted_content:\n                      providerOptions?.reasoningEncryptedContent,\n                    summary: summaryParts,\n                  };\n                  input.push(reasoningMessages[reasoningId]);\n                } else {\n                  existingReasoningMessage.summary.push(...summaryParts);\n                }\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Non-OpenAI reasoning parts are not supported. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                });\n              }\n              break;\n            }\n          }\n        }\n\n        break;\n      }\n\n      case 'tool': {\n        for (const part of content) {\n          const output = part.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          input.push({\n            type: 'function_call_output',\n            call_id: part.toolCallId,\n            output: contentValue,\n          });\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { input, warnings };\n}\n\nconst openaiResponsesReasoningProviderOptionsSchema = z.object({\n  itemId: z.string().nullish(),\n  reasoningEncryptedContent: z.string().nullish(),\n});\n\nexport type OpenAIResponsesReasoningProviderOptions = z.infer<\n  typeof openaiResponsesReasoningProviderOptionsSchema\n>;\n", "import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIResponseFinishReason({\n  finishReason,\n  hasFunctionCall,\n}: {\n  finishReason: string | null | undefined;\n  // flag that checks if there have been client-side tool calls (not executed by openai)\n  hasFunctionCall: boolean;\n}): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case undefined:\n    case null:\n      return hasFunctionCall ? 'tool-calls' : 'stop';\n    case 'max_output_tokens':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    default:\n      return hasFunctionCall ? 'tool-calls' : 'unknown';\n  }\n}\n", "import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { codeInterpreterArgsSchema } from '../tool/code-interpreter';\nimport { fileSearchArgsSchema } from '../tool/file-search';\nimport { webSearchArgsSchema } from '../tool/web-search';\nimport { webSearchPreviewArgsSchema } from '../tool/web-search-preview';\nimport { imageGenerationArgsSchema } from '../tool/image-generation';\nimport { OpenAIResponsesTool } from './openai-responses-api-types';\n\nexport function prepareResponsesTools({\n  tools,\n  toolChoice,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  strictJsonSchema: boolean;\n}): {\n  tools?: Array<OpenAIResponsesTool>;\n  toolChoice?:\n    | 'auto'\n    | 'none'\n    | 'required'\n    | { type: 'file_search' }\n    | { type: 'web_search_preview' }\n    | { type: 'web_search' }\n    | { type: 'function'; name: string }\n    | { type: 'code_interpreter' }\n    | { type: 'image_generation' };\n  toolWarnings: LanguageModelV2CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: Array<OpenAIResponsesTool> = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n          strict: strictJsonSchema,\n        });\n        break;\n      case 'provider-defined': {\n        switch (tool.id) {\n          case 'openai.file_search': {\n            const args = fileSearchArgsSchema.parse(tool.args);\n\n            openaiTools.push({\n              type: 'file_search',\n              vector_store_ids: args.vectorStoreIds,\n              max_num_results: args.maxNumResults,\n              ranking_options: args.ranking\n                ? {\n                    ranker: args.ranking.ranker,\n                    score_threshold: args.ranking.scoreThreshold,\n                  }\n                : undefined,\n              filters: args.filters,\n            });\n\n            break;\n          }\n          case 'openai.web_search_preview': {\n            const args = webSearchPreviewArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'web_search_preview',\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.web_search': {\n            const args = webSearchArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'web_search',\n              filters:\n                args.filters != null\n                  ? { allowed_domains: args.filters.allowedDomains }\n                  : undefined,\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.code_interpreter': {\n            const args = codeInterpreterArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'code_interpreter',\n              container:\n                args.container == null\n                  ? { type: 'auto', file_ids: undefined }\n                  : typeof args.container === 'string'\n                    ? args.container\n                    : { type: 'auto', file_ids: args.container.fileIds },\n            });\n            break;\n          }\n          case 'openai.image_generation': {\n            const args = imageGenerationArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'image_generation',\n              background: args.background,\n              input_fidelity: args.inputFidelity,\n              input_image_mask: args.inputImageMask\n                ? {\n                    file_id: args.inputImageMask.fileId,\n                    image_url: args.inputImageMask.imageUrl,\n                  }\n                : undefined,\n              model: args.model,\n              size: args.size,\n              quality: args.quality,\n              moderation: args.moderation,\n              output_format: args.outputFormat,\n              output_compression: args.outputCompression,\n            });\n            break;\n          }\n        }\n        break;\n      }\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice:\n          toolChoice.toolName === 'code_interpreter' ||\n          toolChoice.toolName === 'file_search' ||\n          toolChoice.toolName === 'image_generation' ||\n          toolChoice.toolName === 'web_search_preview' ||\n          toolChoice.toolName === 'web_search'\n            ? { type: toolChoice.toolName }\n            : { type: 'function', name: toolChoice.toolName },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n", "import { SpeechModelV2, SpeechModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createBinaryResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { OpenAISpeechAPITypes } from './openai-speech-api-types';\nimport { OpenAISpeechModelId } from './openai-speech-options';\n\n// https://platform.openai.com/docs/api-reference/audio/createSpeech\nconst OpenAIProviderOptionsSchema = z.object({\n  instructions: z.string().nullish(),\n  speed: z.number().min(0.25).max(4.0).default(1.0).nullish(),\n});\n\nexport type OpenAISpeechCallOptions = z.infer<\n  typeof OpenAIProviderOptionsSchema\n>;\n\ninterface OpenAISpeechModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAISpeechModel implements SpeechModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAISpeechModelId,\n    private readonly config: OpenAISpeechModelConfig,\n  ) {}\n\n  private async getArgs({\n    text,\n    voice = 'alloy',\n    outputFormat = 'mp3',\n    speed,\n    instructions,\n    language,\n    providerOptions,\n  }: Parameters<SpeechModelV2['doGenerate']>[0]) {\n    const warnings: SpeechModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: OpenAIProviderOptionsSchema,\n    });\n\n    // Create request body\n    const requestBody: Record<string, unknown> = {\n      model: this.modelId,\n      input: text,\n      voice,\n      response_format: 'mp3',\n      speed,\n      instructions,\n    };\n\n    if (outputFormat) {\n      if (['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'].includes(outputFormat)) {\n        requestBody.response_format = outputFormat;\n      } else {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'outputFormat',\n          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`,\n        });\n      }\n    }\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const speechModelOptions: OpenAISpeechAPITypes = {};\n\n      for (const key in speechModelOptions) {\n        const value = speechModelOptions[key as keyof OpenAISpeechAPITypes];\n        if (value !== undefined) {\n          requestBody[key] = value;\n        }\n      }\n    }\n\n    if (language) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'language',\n        details: `OpenAI speech models do not support language selection. Language parameter \"${language}\" was ignored.`,\n      });\n    }\n\n    return {\n      requestBody,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<SpeechModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<SpeechModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { requestBody, warnings } = await this.getArgs(options);\n\n    const {\n      value: audio,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/audio/speech',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: requestBody,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createBinaryResponseHandler(),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      audio,\n      warnings,\n      request: {\n        body: JSON.stringify(requestBody),\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n", "import {\n  TranscriptionModelV2,\n  TranscriptionModelV2CallOptions,\n  TranscriptionModelV2CallWarning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  convertBase64ToUint8Array,\n  createJsonResponseHandler,\n  mediaTypeToExtension,\n  parseProviderOptions,\n  postFormDataToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAITranscriptionModelId,\n  openAITranscriptionProviderOptions,\n  OpenAITranscriptionProviderOptions,\n} from './openai-transcription-options';\n\nexport type OpenAITranscriptionCallOptions = Omit<\n  TranscriptionModelV2CallOptions,\n  'providerOptions'\n> & {\n  providerOptions?: {\n    openai?: OpenAITranscriptionProviderOptions;\n  };\n};\n\ninterface OpenAITranscriptionModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\n// https://platform.openai.com/docs/guides/speech-to-text#supported-languages\nconst languageMap = {\n  afrikaans: 'af',\n  arabic: 'ar',\n  armenian: 'hy',\n  azerbaijani: 'az',\n  belarusian: 'be',\n  bosnian: 'bs',\n  bulgarian: 'bg',\n  catalan: 'ca',\n  chinese: 'zh',\n  croatian: 'hr',\n  czech: 'cs',\n  danish: 'da',\n  dutch: 'nl',\n  english: 'en',\n  estonian: 'et',\n  finnish: 'fi',\n  french: 'fr',\n  galician: 'gl',\n  german: 'de',\n  greek: 'el',\n  hebrew: 'he',\n  hindi: 'hi',\n  hungarian: 'hu',\n  icelandic: 'is',\n  indonesian: 'id',\n  italian: 'it',\n  japanese: 'ja',\n  kannada: 'kn',\n  kazakh: 'kk',\n  korean: 'ko',\n  latvian: 'lv',\n  lithuanian: 'lt',\n  macedonian: 'mk',\n  malay: 'ms',\n  marathi: 'mr',\n  maori: 'mi',\n  nepali: 'ne',\n  norwegian: 'no',\n  persian: 'fa',\n  polish: 'pl',\n  portuguese: 'pt',\n  romanian: 'ro',\n  russian: 'ru',\n  serbian: 'sr',\n  slovak: 'sk',\n  slovenian: 'sl',\n  spanish: 'es',\n  swahili: 'sw',\n  swedish: 'sv',\n  tagalog: 'tl',\n  tamil: 'ta',\n  thai: 'th',\n  turkish: 'tr',\n  ukrainian: 'uk',\n  urdu: 'ur',\n  vietnamese: 'vi',\n  welsh: 'cy',\n};\n\nexport class OpenAITranscriptionModel implements TranscriptionModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAITranscriptionModelId,\n    private readonly config: OpenAITranscriptionModelConfig,\n  ) {}\n\n  private async getArgs({\n    audio,\n    mediaType,\n    providerOptions,\n  }: OpenAITranscriptionCallOptions) {\n    const warnings: TranscriptionModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openAITranscriptionProviderOptions,\n    });\n\n    // Create form data with base fields\n    const formData = new FormData();\n    const blob =\n      audio instanceof Uint8Array\n        ? new Blob([audio])\n        : new Blob([convertBase64ToUint8Array(audio)]);\n\n    formData.append('model', this.modelId);\n    const fileExtension = mediaTypeToExtension(mediaType);\n    formData.append(\n      'file',\n      new File([blob], 'audio', { type: mediaType }),\n      `audio.${fileExtension}`,\n    );\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const transcriptionModelOptions = {\n        include: openAIOptions.include,\n        language: openAIOptions.language,\n        prompt: openAIOptions.prompt,\n        // https://platform.openai.com/docs/api-reference/audio/createTranscription#audio_createtranscription-response_format\n        // prefer verbose_json to get segments for models that support it\n        response_format: [\n          'gpt-4o-transcribe',\n          'gpt-4o-mini-transcribe',\n        ].includes(this.modelId)\n          ? 'json'\n          : 'verbose_json',\n        temperature: openAIOptions.temperature,\n        timestamp_granularities: openAIOptions.timestampGranularities,\n      };\n\n      for (const [key, value] of Object.entries(transcriptionModelOptions)) {\n        if (value != null) {\n          if (Array.isArray(value)) {\n            for (const item of value) {\n              formData.append(`${key}[]`, String(item));\n            }\n          } else {\n            formData.append(key, String(value));\n          }\n        }\n      }\n    }\n\n    return {\n      formData,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: OpenAITranscriptionCallOptions,\n  ): Promise<Awaited<ReturnType<TranscriptionModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { formData, warnings } = await this.getArgs(options);\n\n    const {\n      value: response,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postFormDataToApi({\n      url: this.config.url({\n        path: '/audio/transcriptions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      formData,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTranscriptionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const language =\n      response.language != null && response.language in languageMap\n        ? languageMap[response.language as keyof typeof languageMap]\n        : undefined;\n\n    return {\n      text: response.text,\n      segments:\n        response.segments?.map(segment => ({\n          text: segment.text,\n          startSecond: segment.start,\n          endSecond: segment.end,\n        })) ??\n        response.words?.map(word => ({\n          text: word.word,\n          startSecond: word.start,\n          endSecond: word.end,\n        })) ??\n        [],\n      language,\n      durationInSeconds: response.duration ?? undefined,\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n\nconst openaiTranscriptionResponseSchema = z.object({\n  text: z.string(),\n  language: z.string().nullish(),\n  duration: z.number().nullish(),\n  words: z\n    .array(\n      z.object({\n        word: z.string(),\n        start: z.number(),\n        end: z.number(),\n      }),\n    )\n    .nullish(),\n  segments: z\n    .array(\n      z.object({\n        id: z.number(),\n        seek: z.number(),\n        start: z.number(),\n        end: z.number(),\n        text: z.string(),\n        tokens: z.array(z.number()),\n        temperature: z.number(),\n        avg_logprob: z.number(),\n        compression_ratio: z.number(),\n        no_speech_prob: z.number(),\n      }),\n    )\n    .nullish(),\n});\n", "import { z } from 'zod/v4';\n\nexport type OpenAITranscriptionModelId =\n  | 'whisper-1'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createTranscription\nexport const openAITranscriptionProviderOptions = z.object({\n  /**\n   * Additional information to include in the transcription response.\n   */\n\n  include: z.array(z.string()).optional(),\n\n  /**\n   * The language of the input audio in ISO-639-1 format.\n   */\n  language: z.string().optional(),\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio segment.\n   */\n  prompt: z.string().optional(),\n\n  /**\n   * The sampling temperature, between 0 and 1.\n   * @default 0\n   */\n  temperature: z.number().min(0).max(1).default(0).optional(),\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * @default ['segment']\n   */\n  timestampGranularities: z\n    .array(z.enum(['word', 'segment']))\n    .default(['segment'])\n    .optional(),\n});\n\nexport type OpenAITranscriptionProviderOptions = z.infer<\n  typeof openAITranscriptionProviderOptions\n>;\n", "// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;AEGO,IAAM,wBAAwB,iBAAE,OAAO;EAC5C,OAAO,iBAAE,OAAO;IACd,SAAS,iBAAE,OAAO;;;;IAKlB,MAAM,iBAAE,OAAO,EAAE,QAAQ;IACzB,OAAO,iBAAE,IAAI,EAAE,QAAQ;IACvB,MAAM,iBAAE,MAAM,CAAC,iBAAE,OAAO,GAAG,iBAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;EAClD,CAAC;AACH,CAAC;AAIM,IAAM,8BAA8B,+BAA+B;EACxE,aAAa;EACb,gBAAgB,CAAA,SAAQ,KAAK,MAAM;AACrC,CAAC;ACbM,SAAS,4BAA4B;EAC1C;EACA,oBAAoB;AACtB,GAME;AACA,QAAM,WAA6B,CAAC;AACpC,QAAM,WAA8C,CAAC;AAErD,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;UACzB,KAAK,UAAU;AACb,qBAAS,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACzC;UACF;UACA,KAAK,aAAa;AAChB,qBAAS,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AAC5C;UACF;UACA,KAAK,UAAU;AACb,qBAAS,KAAK;cACZ,MAAM;cACN,SAAS;YACX,CAAC;AACD;UACF;UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;cACR,oCAAoC,gBAAgB;YACtD;UACF;QACF;AACA;MACF;MAEA,KAAK,QAAQ;AACX,YAAI,QAAQ,WAAW,KAAK,QAAQ,CAAC,EAAE,SAAS,QAAQ;AACtD,mBAAS,KAAK,EAAE,MAAM,QAAQ,SAAS,QAAQ,CAAC,EAAE,KAAK,CAAC;AACxD;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AA1DhD,gBAAA,IAAA,IAAA;AA2DY,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,QAAQ,MAAM,KAAK,KAAK;cACzC;cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;oBACL,MAAM;oBACN,WAAW;sBACT,KACE,KAAK,gBAAgB,MACjB,KAAK,KAAK,SAAS,IACnB,QAAQ,SAAS,WAAW,gBAAgB,KAAK,IAAI,CAAC;;sBAG5D,SAAQ,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GAA8B;oBACxC;kBACF;gBACF,WAAW,KAAK,UAAU,WAAW,QAAQ,GAAG;AAC9C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8BAA8B;sBACtC,eAAe;oBACjB,CAAC;kBACH;AAEA,0BAAQ,KAAK,WAAW;oBACtB,KAAK,aAAa;AAChB,6BAAO;wBACL,MAAM;wBACN,aAAa;0BACX,MAAM,gBAAgB,KAAK,IAAI;0BAC/B,QAAQ;wBACV;sBACF;oBACF;oBACA,KAAK;oBACL,KAAK,cAAc;AACjB,6BAAO;wBACL,MAAM;wBACN,aAAa;0BACX,MAAM,gBAAgB,KAAK,IAAI;0BAC/B,QAAQ;wBACV;sBACF;oBACF;oBAEA,SAAS;AACP,4BAAM,IAAI,8BAA8B;wBACtC,eAAe,uCAAuC,KAAK,SAAS;sBACtE,CAAC;oBACH;kBACF;gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,0BAAM,IAAI,8BAA8B;sBACtC,eAAe;oBACjB,CAAC;kBACH;AAEA,yBAAO;oBACL,MAAM;oBACN,MACE,OAAO,KAAK,SAAS,YACrB,KAAK,KAAK,WAAW,OAAO,IACxB,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAU,KAAA,KAAK,aAAL,OAAA,KAAiB,QAAQ,KAAK;sBACxC,WAAW,+BAA+B,gBAAgB,KAAK,IAAI,CAAC;oBACtE;kBACR;gBACF,OAAO;AACL,wBAAM,IAAI,8BAA8B;oBACtC,eAAe,wBAAwB,KAAK,SAAS;kBACvD,CAAC;gBACH;cACF;YACF;UACF,CAAC;QACH,CAAC;AAED;MACF;MAEA,KAAK,aAAa;AAChB,YAAI,OAAO;AACX,cAAM,YAID,CAAC;AAEN,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,sBAAQ,KAAK;AACb;YACF;YACA,KAAK,aAAa;AAChB,wBAAU,KAAK;gBACb,IAAI,KAAK;gBACT,MAAM;gBACN,UAAU;kBACR,MAAM,KAAK;kBACX,WAAW,KAAK,UAAU,KAAK,KAAK;gBACtC;cACF,CAAC;AACD;YACF;UACF;QACF;AAEA,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,YAAY,UAAU,SAAS,IAAI,YAAY;QACjD,CAAC;AAED;MACF;MAEA,KAAK,QAAQ;AACX,mBAAW,gBAAgB,SAAS;AAClC,gBAAM,SAAS,aAAa;AAE5B,cAAI;AACJ,kBAAQ,OAAO,MAAM;YACnB,KAAK;YACL,KAAK;AACH,6BAAe,OAAO;AACtB;YACF,KAAK;YACL,KAAK;YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;UACJ;AAEA,mBAAS,KAAK;YACZ,MAAM;YACN,cAAc,aAAa;YAC3B,SAAS;UACX,CAAC;QACH;AACA;MACF;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAEA,SAAO,EAAE,UAAU,SAAS;AAC9B;AC1NO,SAAS,oBAAoB;EAClC;EACA;EACA;AACF,GAIG;AACD,SAAO;IACL,IAAI,MAAA,OAAA,KAAM;IACV,SAAS,SAAA,OAAA,QAAS;IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;EAC1D;AACF;ACZO,SAAS,sBACd,cAC6B;AAC7B,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;ACuBO,IAAM,iCAAiCA,iBAAE,OAAO;;;;;;;EAOrD,WAAWA,iBAAE,OAAOA,iBAAE,OAAO,OAAe,GAAGA,iBAAE,OAAO,CAAC,EAAE,SAAS;;;;;;;;;;EAWpE,UAAUA,iBAAE,MAAM,CAACA,iBAAE,QAAQ,GAAGA,iBAAE,OAAO,CAAC,CAAC,EAAE,SAAS;;;;EAKtD,mBAAmBA,iBAAE,QAAQ,EAAE,SAAS;;;;;EAMxC,MAAMA,iBAAE,OAAO,EAAE,SAAS;;;;EAK1B,iBAAiBA,iBAAE,KAAK,CAAC,WAAW,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;;;;EAKvE,qBAAqBA,iBAAE,OAAO,EAAE,SAAS;;;;EAKzC,OAAOA,iBAAE,QAAQ,EAAE,SAAS;;;;EAK5B,UAAUA,iBAAE,OAAOA,iBAAE,OAAO,EAAE,IAAI,EAAE,GAAGA,iBAAE,OAAO,EAAE,IAAI,GAAG,CAAC,EAAE,SAAS;;;;EAKrE,YAAYA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,IAAI,CAAC,EAAE,SAAS;;;;;;EAOnD,mBAAmBA,iBAAE,QAAQ,EAAE,SAAS;;;;;;;;;EAUxC,aAAaA,iBAAE,KAAK,CAAC,QAAQ,QAAQ,UAAU,CAAC,EAAE,SAAS;;;;;;EAO3D,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;;;;;EAMvC,eAAeA,iBAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;;;;;EAM1D,gBAAgBA,iBAAE,OAAO,EAAE,SAAS;;;;;;;;EASpC,kBAAkBA,iBAAE,OAAO,EAAE,SAAS;AACxC,CAAC;ACnIM,SAAS,iBAAiB;EAC/B;EACA;EACA;EACA;AACF,GASE;AAEA,WAAQ,SAAA,OAAA,SAAA,MAAO,UAAS,QAAQ;AAEhC,QAAM,eAA6C,CAAC;AAEpD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;EACjE;AAEA,QAAMC,eAAwC,CAAC;AAE/C,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;MACjB,KAAK;AACHA,qBAAY,KAAK;UACf,MAAM;UACN,UAAU;YACR,MAAM,KAAK;YACX,aAAa,KAAK;YAClB,YAAY,KAAK;YACjB,QAAQ,oBAAoB,mBAAmB;UACjD;QACF,CAAC;AACD;MACF;AACE,qBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AACpD;IACJ;EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAOA,cAAa,YAAY,QAAW,aAAa;EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO,EAAE,OAAOA,cAAa,YAAY,MAAM,aAAa;IAC9D,KAAK;AACH,aAAO;QACL,OAAOA;QACP,YAAY;UACV,MAAM;UACN,UAAU;YACR,MAAM,WAAW;UACnB;QACF;QACA;MACF;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAIC,8BAA8B;QACtC,eAAe,qBAAqB,gBAAgB;MACtD,CAAC;IACH;EACF;AACF;ANzCO,IAAM,0BAAN,MAAyD;EAW9D,YAAY,SAA4B,QAA0B;AAVlE,SAAS,uBAAuB;AAIhC,SAAS,gBAAgB;MACvB,WAAW,CAAC,iBAAiB;IAC/B;AAKE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAA+B;AA7EjC,QAAA,IAAA,IAAA,IAAA;AA8EI,UAAM,WAAyC,CAAC;AAGhD,UAAM,iBACH,KAAA,MAAM,qBAAqB;MAC1B,UAAU;MACV;MACA,QAAQ;IACV,CAAC,MAJA,OAAA,KAIM,CAAC;AAEV,UAAM,qBAAoB,KAAA,cAAc,sBAAd,OAAA,KAAmC;AAE7D,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,SACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,UACzB,eAAe,UAAU,QACzB,CAAC,mBACD;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;IACH;AAEA,UAAM,EAAE,UAAU,UAAU,gBAAgB,IAAI;MAC9C;QACE;QACA,mBAAmB,qBAAqB,KAAK,OAAO;MACtD;IACF;AAEA,aAAS,KAAK,GAAG,eAAe;AAEhC,UAAM,oBAAmB,KAAA,cAAc,qBAAd,OAAA,KAAkC;AAE3D,UAAM,WAAW;;MAEf,OAAO,KAAK;;MAGZ,YAAY,cAAc;MAC1B,UACE,cAAc,aAAa,QAC3B,OAAO,cAAc,aAAa,WAC9B,OACA;MACN,cACE,OAAO,cAAc,aAAa,WAC9B,cAAc,WACd,OAAO,cAAc,aAAa,YAChC,cAAc,WACZ,IACA,SACF;MACR,MAAM,cAAc;MACpB,qBAAqB,cAAc;;MAGnC,YAAY;MACZ;MACA,OAAO;MACP,mBAAmB;MACnB,kBAAkB;MAClB,kBACE,kBAAA,OAAA,SAAA,eAAgB,UAAS,SACrB,qBAAqB,eAAe,UAAU,OAC5C;QACE,MAAM;QACN,aAAa;UACX,QAAQ,eAAe;UACvB,QAAQ;UACR,OAAM,KAAA,eAAe,SAAf,OAAA,KAAuB;UAC7B,aAAa,eAAe;QAC9B;MACF,IACA,EAAE,MAAM,cAAc,IACxB;MACN,MAAM;MACN;MACA,WAAW,cAAc;;;MAIzB,uBAAuB,cAAc;MACrC,OAAO,cAAc;MACrB,UAAU,cAAc;MACxB,YAAY,cAAc;MAC1B,kBAAkB,cAAc;MAChC,cAAc,cAAc;MAC5B,kBAAkB,cAAc;MAChC,mBAAmB,cAAc;;MAGjC;IACF;AAEA,QAAI,iBAAiB,KAAK,OAAO,GAAG;AAGlC,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,SAAS,MAAM;AAC1B,iBAAS,QAAQ;AACjB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,qBAAqB,MAAM;AACtC,iBAAS,oBAAoB;AAC7B,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,oBAAoB,MAAM;AACrC,iBAAS,mBAAmB;AAC5B,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,cAAc,MAAM;AAC/B,iBAAS,aAAa;AACtB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,YAAY,MAAM;AAC7B,iBAAS,WAAW;AACpB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;QACX,CAAC;MACH;AACA,UAAI,SAAS,gBAAgB,MAAM;AACjC,iBAAS,eAAe;AACxB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;QACX,CAAC;MACH;AAGA,UAAI,SAAS,cAAc,MAAM;AAC/B,YAAI,SAAS,yBAAyB,MAAM;AAC1C,mBAAS,wBAAwB,SAAS;QAC5C;AACA,iBAAS,aAAa;MACxB;IACF,WACE,KAAK,QAAQ,WAAW,uBAAuB,KAC/C,KAAK,QAAQ,WAAW,4BAA4B,GACpD;AACA,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SACE;QACJ,CAAC;MACH;IACF;AAGA,QACE,cAAc,gBAAgB,UAC9B,CAAC,uBAAuB,KAAK,OAAO,GACpC;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AACD,eAAS,eAAe;IAC1B;AAGA,QACE,cAAc,gBAAgB,cAC9B,CAAC,2BAA2B,KAAK,OAAO,GACxC;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AACD,eAAS,eAAe;IAC1B;AAEA,UAAM;MACJ,OAAOD;MACP,YAAY;MACZ;IACF,IAAI,iBAAiB;MACnB;MACA;MACA;MACA;IACF,CAAC;AAED,WAAO;MACL,MAAM;QACJ,GAAG;QACH,OAAOA;QACP,aAAa;MACf;MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;IACzC;EACF;EAEA,MAAM,WACJ,SAC6D;AAxTjE,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAyTI,UAAM,EAAE,MAAM,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE3D,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAM,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AACjC,UAAM,UAAyC,CAAC;AAGhD,UAAM,OAAO,OAAO,QAAQ;AAC5B,QAAI,QAAQ,QAAQ,KAAK,SAAS,GAAG;AACnC,cAAQ,KAAK,EAAE,MAAM,QAAQ,KAAK,CAAC;IACrC;AAGA,eAAW,aAAY,KAAA,OAAO,QAAQ,eAAf,OAAA,KAA6B,CAAC,GAAG;AACtD,cAAQ,KAAK;QACX,MAAM;QACN,aAAY,KAAA,SAAS,OAAT,OAAA,KAAe,WAAW;QACtC,UAAU,SAAS,SAAS;QAC5B,OAAO,SAAS,SAAS;MAC3B,CAAC;IACH;AAGA,eAAW,eAAc,KAAA,OAAO,QAAQ,gBAAf,OAAA,KAA8B,CAAC,GAAG;AACzD,cAAQ,KAAK;QACX,MAAM;QACN,YAAY;QACZ,IAAI,WAAW;QACf,KAAK,WAAW;QAChB,OAAO,WAAW;MACpB,CAAC;IACH;AAGA,UAAM,0BAAyB,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;AAC/C,UAAM,sBAAqB,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;AAC3C,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,SAAI,0BAAA,OAAA,SAAA,uBAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,0BAAA,OAAA,SAAA,uBAAwB;IAC5B;AACA,SAAI,0BAAA,OAAA,SAAA,uBAAwB,+BAA8B,MAAM;AAC9D,uBAAiB,OAAO,2BACtB,0BAAA,OAAA,SAAA,uBAAwB;IAC5B;AACA,UAAI,KAAA,OAAO,aAAP,OAAA,SAAA,GAAiB,YAAW,MAAM;AACpC,uBAAiB,OAAO,WAAW,OAAO,SAAS;IACrD;AAEA,WAAO;MACL;MACA,cAAc,sBAAsB,OAAO,aAAa;MACxD,OAAO;QACL,cAAa,MAAA,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB,kBAAhB,OAAA,KAAiC;QAC9C,eAAc,MAAA,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB,sBAAhB,OAAA,KAAqC;QACnD,cAAa,MAAA,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB,iBAAhB,OAAA,KAAgC;QAC7C,kBAAiB,KAAA,0BAAA,OAAA,SAAA,uBAAwB,qBAAxB,OAAA,KAA4C;QAC7D,oBAAmB,KAAA,sBAAA,OAAA,SAAA,mBAAoB,kBAApB,OAAA,KAAqC;MAC1D;MACA,SAAS,EAAE,KAAK;MAChB,UAAU;QACR,GAAG,oBAAoB,QAAQ;QAC/B,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;MACX,GAAG;MACH,QAAQ;MACR,gBAAgB;QACd,eAAe;MACjB;IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2B;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,YAQD,CAAC;AAEN,QAAI,eAA4C;AAChD,UAAM,QAA8B;MAClC,aAAa;MACb,cAAc;MACd,aAAa;IACf;AACA,QAAI,eAAe;AACnB,QAAI,eAAe;AAEnB,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AA5cvC,gBAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AA6cY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;gBACjB,MAAM;gBACN,GAAG,oBAAoB,KAAK;cAC9B,CAAC;YACH;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,oBAAM,eAAc,KAAA,MAAM,MAAM,kBAAZ,OAAA,KAA6B;AACjD,oBAAM,gBAAe,KAAA,MAAM,MAAM,sBAAZ,OAAA,KAAiC;AACtD,oBAAM,eAAc,KAAA,MAAM,MAAM,iBAAZ,OAAA,KAA4B;AAChD,oBAAM,mBACJ,MAAA,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GAAuC,qBAAvC,OAAA,KACA;AACF,oBAAM,qBACJ,MAAA,KAAA,MAAM,MAAM,0BAAZ,OAAA,SAAA,GAAmC,kBAAnC,OAAA,KAAoD;AAEtD,oBACE,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GAAuC;cAC3C;AACA,oBACE,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GACI,+BAA8B,MAClC;AACA,iCAAiB,OAAO,4BACtB,KAAA,MAAM,MAAM,8BAAZ,OAAA,SAAA,GAAuC;cAC3C;YACF;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,UAAA,OAAA,SAAA,OAAQ,kBAAiB,MAAM;AACjC,6BAAe,sBAAsB,OAAO,aAAa;YAC3D;AAEA,kBAAI,KAAA,UAAA,OAAA,SAAA,OAAQ,aAAR,OAAA,SAAA,GAAkB,YAAW,MAAM;AACrC,+BAAiB,OAAO,WAAW,OAAO,SAAS;YACrD;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,UAAS,MAAM;AACzB;YACF;AAEA,kBAAM,QAAQ,OAAO;AAErB,gBAAI,MAAM,WAAW,MAAM;AACzB,kBAAI,CAAC,cAAc;AACjB,2BAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;AAClD,+BAAe;cACjB;AAEA,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;gBACJ,OAAO,MAAM;cACf,CAAC;YACH;AAEA,gBAAI,MAAM,cAAc,MAAM;AAC5B,yBAAW,iBAAiB,MAAM,YAAY;AAC5C,sBAAM,QAAQ,cAAc;AAG5B,oBAAI,UAAU,KAAK,KAAK,MAAM;AAC5B,sBAAI,cAAc,SAAS,YAAY;AACrC,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,sBAAI,cAAc,MAAM,MAAM;AAC5B,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,wBAAI,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,SAAQ,MAAM;AACxC,0BAAM,IAAI,yBAAyB;sBACjC,MAAM;sBACN,SAAS;oBACX,CAAC;kBACH;AAEA,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,cAAc;oBAClB,UAAU,cAAc,SAAS;kBACnC,CAAC;AAED,4BAAU,KAAK,IAAI;oBACjB,IAAI,cAAc;oBAClB,MAAM;oBACN,UAAU;sBACR,MAAM,cAAc,SAAS;sBAC7B,YAAW,KAAA,cAAc,SAAS,cAAvB,OAAA,KAAoC;oBACjD;oBACA,aAAa;kBACf;AAEA,wBAAME,YAAW,UAAU,KAAK;AAEhC,wBACE,KAAAA,UAAS,aAAT,OAAA,SAAA,GAAmB,SAAQ,UAC3B,KAAAA,UAAS,aAAT,OAAA,SAAA,GAAmB,cAAa,MAChC;AAEA,wBAAIA,UAAS,SAAS,UAAU,SAAS,GAAG;AAC1C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAIA,UAAS;wBACb,OAAOA,UAAS,SAAS;sBAC3B,CAAC;oBACH;AAIA,wBAAI,eAAeA,UAAS,SAAS,SAAS,GAAG;AAC/C,iCAAW,QAAQ;wBACjB,MAAM;wBACN,IAAIA,UAAS;sBACf,CAAC;AAED,iCAAW,QAAQ;wBACjB,MAAM;wBACN,aAAY,KAAAA,UAAS,OAAT,OAAA,KAAe,WAAW;wBACtC,UAAUA,UAAS,SAAS;wBAC5B,OAAOA,UAAS,SAAS;sBAC3B,CAAC;AACDA,gCAAS,cAAc;oBACzB;kBACF;AAEA;gBACF;AAGA,sBAAM,WAAW,UAAU,KAAK;AAEhC,oBAAI,SAAS,aAAa;AACxB;gBACF;AAEA,sBAAI,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,cAAa,MAAM;AAC7C,2BAAS,SAAU,cACjB,MAAA,KAAA,cAAc,aAAd,OAAA,SAAA,GAAwB,cAAxB,OAAA,KAAqC;gBACzC;AAGA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,QAAO,KAAA,cAAc,SAAS,cAAvB,OAAA,KAAoC;gBAC7C,CAAC;AAGD,sBACE,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,SAAQ,UAC3B,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,cAAa,QAChC,eAAe,SAAS,SAAS,SAAS,GAC1C;AACA,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,SAAS;kBACf,CAAC;AAED,6BAAW,QAAQ;oBACjB,MAAM;oBACN,aAAY,KAAA,SAAS,OAAT,OAAA,KAAe,WAAW;oBACtC,UAAU,SAAS,SAAS;oBAC5B,OAAO,SAAS,SAAS;kBAC3B,CAAC;AACD,2BAAS,cAAc;gBACzB;cACF;YACF;AAGA,gBAAI,MAAM,eAAe,MAAM;AAC7B,yBAAW,cAAc,MAAM,aAAa;AAC1C,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,IAAI,WAAW;kBACf,KAAK,WAAW;kBAChB,OAAO,WAAW;gBACpB,CAAC;cACH;YACF;UACF;UAEA,MAAM,YAAY;AAChB,gBAAI,cAAc;AAChB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;YAClD;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA;cACA,GAAI,oBAAoB,OAAO,EAAE,iBAAiB,IAAI,CAAC;YACzD,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AAEA,IAAM,yBAAyBH,iBAC5B,OAAO;EACN,eAAeA,iBAAE,OAAO,EAAE,QAAQ;EAClC,mBAAmBA,iBAAE,OAAO,EAAE,QAAQ;EACtC,cAAcA,iBAAE,OAAO,EAAE,QAAQ;EACjC,uBAAuBA,iBACpB,OAAO;IACN,eAAeA,iBAAE,OAAO,EAAE,QAAQ;EACpC,CAAC,EACA,QAAQ;EACX,2BAA2BA,iBACxB,OAAO;IACN,kBAAkBA,iBAAE,OAAO,EAAE,QAAQ;IACrC,4BAA4BA,iBAAE,OAAO,EAAE,QAAQ;IAC/C,4BAA4BA,iBAAE,OAAO,EAAE,QAAQ;EACjD,CAAC,EACA,QAAQ;AACb,CAAC,EACA,QAAQ;AAIX,IAAM,2BAA2BA,iBAAE,OAAO;EACxC,IAAIA,iBAAE,OAAO,EAAE,QAAQ;EACvB,SAASA,iBAAE,OAAO,EAAE,QAAQ;EAC5B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;EAC1B,SAASA,iBAAE;IACTA,iBAAE,OAAO;MACP,SAASA,iBAAE,OAAO;QAChB,MAAMA,iBAAE,QAAQ,WAAW,EAAE,QAAQ;QACrC,SAASA,iBAAE,OAAO,EAAE,QAAQ;QAC5B,YAAYA,iBACT;UACCA,iBAAE,OAAO;YACP,IAAIA,iBAAE,OAAO,EAAE,QAAQ;YACvB,MAAMA,iBAAE,QAAQ,UAAU;YAC1B,UAAUA,iBAAE,OAAO;cACjB,MAAMA,iBAAE,OAAO;cACf,WAAWA,iBAAE,OAAO;YACtB,CAAC;UACH,CAAC;QACH,EACC,QAAQ;QACX,aAAaA,iBACV;UACCA,iBAAE,OAAO;YACP,MAAMA,iBAAE,QAAQ,cAAc;YAC9B,aAAaA,iBAAE,OAAO;YACtB,WAAWA,iBAAE,OAAO;YACpB,KAAKA,iBAAE,OAAO;YACd,OAAOA,iBAAE,OAAO;UAClB,CAAC;QACH,EACC,QAAQ;MACb,CAAC;MACD,OAAOA,iBAAE,OAAO;MAChB,UAAUA,iBACP,OAAO;QACN,SAASA,iBACN;UACCA,iBAAE,OAAO;YACP,OAAOA,iBAAE,OAAO;YAChB,SAASA,iBAAE,OAAO;YAClB,cAAcA,iBAAE;cACdA,iBAAE,OAAO;gBACP,OAAOA,iBAAE,OAAO;gBAChB,SAASA,iBAAE,OAAO;cACpB,CAAC;YACH;UACF,CAAC;QACH,EACC,QAAQ;MACb,CAAC,EACA,QAAQ;MACX,eAAeA,iBAAE,OAAO,EAAE,QAAQ;IACpC,CAAC;EACH;EACA,OAAO;AACT,CAAC;AAID,IAAM,wBAAwBA,iBAAE,MAAM;EACpCA,iBAAE,OAAO;IACP,IAAIA,iBAAE,OAAO,EAAE,QAAQ;IACvB,SAASA,iBAAE,OAAO,EAAE,QAAQ;IAC5B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;IAC1B,SAASA,iBAAE;MACTA,iBAAE,OAAO;QACP,OAAOA,iBACJ,OAAO;UACN,MAAMA,iBAAE,KAAK,CAAC,WAAW,CAAC,EAAE,QAAQ;UACpC,SAASA,iBAAE,OAAO,EAAE,QAAQ;UAC5B,YAAYA,iBACT;YACCA,iBAAE,OAAO;cACP,OAAOA,iBAAE,OAAO;cAChB,IAAIA,iBAAE,OAAO,EAAE,QAAQ;cACvB,MAAMA,iBAAE,QAAQ,UAAU,EAAE,QAAQ;cACpC,UAAUA,iBAAE,OAAO;gBACjB,MAAMA,iBAAE,OAAO,EAAE,QAAQ;gBACzB,WAAWA,iBAAE,OAAO,EAAE,QAAQ;cAChC,CAAC;YACH,CAAC;UACH,EACC,QAAQ;UACX,aAAaA,iBACV;YACCA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,cAAc;cAC9B,aAAaA,iBAAE,OAAO;cACtB,WAAWA,iBAAE,OAAO;cACpB,KAAKA,iBAAE,OAAO;cACd,OAAOA,iBAAE,OAAO;YAClB,CAAC;UACH,EACC,QAAQ;QACb,CAAC,EACA,QAAQ;QACX,UAAUA,iBACP,OAAO;UACN,SAASA,iBACN;YACCA,iBAAE,OAAO;cACP,OAAOA,iBAAE,OAAO;cAChB,SAASA,iBAAE,OAAO;cAClB,cAAcA,iBAAE;gBACdA,iBAAE,OAAO;kBACP,OAAOA,iBAAE,OAAO;kBAChB,SAASA,iBAAE,OAAO;gBACpB,CAAC;cACH;YACF,CAAC;UACH,EACC,QAAQ;QACb,CAAC,EACA,QAAQ;QACX,eAAeA,iBAAE,OAAO,EAAE,QAAQ;QAClC,OAAOA,iBAAE,OAAO;MAClB,CAAC;IACH;IACA,OAAO;EACT,CAAC;EACD;AACF,CAAC;AAED,SAAS,iBAAiB,SAAiB;AACzC,UACG,QAAQ,WAAW,GAAG,KAAK,QAAQ,WAAW,OAAO,MACtD,CAAC,QAAQ,WAAW,YAAY;AAEpC;AAEA,SAAS,uBAAuB,SAAiB;AAC/C,SACE,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC3B,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAEpE;AAEA,SAAS,2BAA2B,SAAiB;AACnD,SACE,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,YAAY,KAC9B,QAAQ,WAAW,OAAO,KACzB,CAAC,QAAQ,WAAW,YAAY,KAChC,CAAC,QAAQ,WAAW,YAAY,KAClC,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS;AAEhC;AAEA,SAAS,qBAAqB,SAAiB;AAx2B/C,MAAA,IAAA;AAy2BE,MAAI,CAAC,iBAAiB,OAAO,GAAG;AAC9B,WAAO;EACT;AAEA,UACE,MAAA,KAAA,gBAAgB,OAAuC,MAAvD,OAAA,SAAA,GACI,sBADJ,OAAA,KACyB;AAE7B;AAEA,IAAM,kBAAkB;EACtB,WAAW;IACT,mBAAmB;EACrB;EACA,sBAAsB;IACpB,mBAAmB;EACrB;EACA,cAAc;IACZ,mBAAmB;EACrB;EACA,yBAAyB;IACvB,mBAAmB;EACrB;EACA,IAAI;IACF,mBAAmB;EACrB;EACA,iBAAiB;IACf,mBAAmB;EACrB;EACA,WAAW;IACT,mBAAmB;EACrB;EACA,sBAAsB;IACpB,mBAAmB;EACrB;EACA,WAAW;IACT,mBAAmB;EACrB;EACA,sBAAsB;IACpB,mBAAmB;EACrB;AACF;AQ54BO,SAAS,gCAAgC;EAC9C;EACA,OAAO;EACP,YAAY;AACd,GAOE;AAEA,MAAI,OAAO;AAGX,MAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC/B,YAAQ,GAAG,OAAO,CAAC,EAAE,OAAO;;;AAC5B,aAAS,OAAO,MAAM,CAAC;EACzB;AAEA,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,cAAM,IAAI,mBAAmB;UAC3B,SAAS;UACT;QACF,CAAC;MACH;MAEA,KAAK,QAAQ;AACX,cAAM,cAAc,QACjB,IAAI,CAAA,SAAQ;AACX,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;YACd;UACF;QACF,CAAC,EACA,OAAO,OAAO,EACd,KAAK,EAAE;AAEV,gBAAQ,GAAG,IAAI;EAAM,WAAW;;;AAChC;MACF;MAEA,KAAK,aAAa;AAChB,cAAM,mBAAmB,QACtB,IAAI,CAAA,SAAQ;AACX,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;YACd;YACA,KAAK,aAAa;AAChB,oBAAM,IAAIE,8BAA8B;gBACtC,eAAe;cACjB,CAAC;YACH;UACF;QACF,CAAC,EACA,KAAK,EAAE;AAEV,gBAAQ,GAAG,SAAS;EAAM,gBAAgB;;;AAC1C;MACF;MAEA,KAAK,QAAQ;AACX,cAAM,IAAIA,8BAA8B;UACtC,eAAe;QACjB,CAAC;MACH;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAGA,UAAQ,GAAG,SAAS;;AAEpB,SAAO;IACL,QAAQ;IACR,eAAe,CAAC;EAAK,IAAI,GAAG;EAC9B;AACF;AC5FO,SAASE,qBAAoB;EAClC;EACA;EACA;AACF,GAIG;AACD,SAAO;IACL,IAAI,MAAA,OAAA,KAAM;IACV,SAAS,SAAA,OAAA,QAAS;IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;EAC1D;AACF;ACZO,SAASC,uBACd,cAC6B;AAC7B,UAAQ,cAAc;IACpB,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;ACbO,IAAM,kCAAkCL,iBAAE,OAAO;;;;EAItD,MAAMA,iBAAE,QAAQ,EAAE,SAAS;;;;;;;;;;;;;;;EAgB3B,WAAWA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,OAAO,CAAC,EAAE,SAAS;;;;EAKrD,QAAQA,iBAAE,OAAO,EAAE,SAAS;;;;;EAM5B,MAAMA,iBAAE,OAAO,EAAE,SAAS;;;;;;;;;;EAW1B,UAAUA,iBAAE,MAAM,CAACA,iBAAE,QAAQ,GAAGA,iBAAE,OAAO,CAAC,CAAC,EAAE,SAAS;AACxD,CAAC;AJXM,IAAM,gCAAN,MAA+D;EAWpE,YACE,SACA,QACA;AAbF,SAAS,uBAAuB;AAsBhC,SAAS,gBAA0C;;IAEnD;AAVE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAVA,IAAY,sBAA8B;AACxC,WAAO,KAAK,OAAO,SAAS,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK;EACjD;EAUA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAMA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA,eAAe;IACf;IACA;IACA;IACA;IACA;EACF,GAAiD;AAC/C,UAAM,WAAyC,CAAC;AAGhD,UAAM,gBAAgB;MACpB,GAAI,MAAMM,qBAAqB;QAC7B,UAAU;QACV;QACA,QAAQ;MACV,CAAC;MACD,GAAI,MAAMA,qBAAqB;QAC7B,UAAU,KAAK;QACf;QACA,QAAQ;MACV,CAAC;IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;IAChE;AAEA,QAAI,SAAA,OAAA,SAAA,MAAO,QAAQ;AACjB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,QAAQ,CAAC;IACjE;AAEA,QAAI,cAAc,MAAM;AACtB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,aAAa,CAAC;IACtE;AAEA,QAAI,kBAAkB,QAAQ,eAAe,SAAS,QAAQ;AAC5D,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS;MACX,CAAC;IACH;AAEA,UAAM,EAAE,QAAQ,kBAAkB,cAAc,IAC9C,gCAAgC,EAAE,OAAO,CAAC;AAE5C,UAAM,OAAO,CAAC,GAAI,iBAAA,OAAA,gBAAiB,CAAC,GAAI,GAAI,qBAAA,OAAA,oBAAqB,CAAC,CAAE;AAEpE,WAAO;MACL,MAAM;;QAEJ,OAAO,KAAK;;QAGZ,MAAM,cAAc;QACpB,YAAY,cAAc;QAC1B,WACE,iBAAA,OAAA,SAAA,cAAe,cAAa,OACxB,KACA,iBAAA,OAAA,SAAA,cAAe,cAAa,QAC1B,SACA,iBAAA,OAAA,SAAA,cAAe;QACvB,QAAQ,cAAc;QACtB,MAAM,cAAc;;QAGpB,YAAY;QACZ;QACA,OAAO;QACP,mBAAmB;QACnB,kBAAkB;QAClB;;QAGA,QAAQ;;QAGR,MAAM,KAAK,SAAS,IAAI,OAAO;MACjC;MACA;IACF;EACF;EAEA,MAAM,WACJ,SAC6D;AA7JjE,QAAA,IAAA,IAAA;AA8JI,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;MACN,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,SAAS,SAAS,QAAQ,CAAC;AAEjC,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAEhE,QAAI,OAAO,YAAY,MAAM;AAC3B,uBAAiB,OAAO,WAAW,OAAO;IAC5C;AAEA,WAAO;MACL,SAAS,CAAC,EAAE,MAAM,QAAQ,MAAM,OAAO,KAAK,CAAC;MAC7C,OAAO;QACL,cAAa,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;QAC7B,eAAc,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;QAC9B,cAAa,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB;MAC/B;MACA,cAAcJ,uBAAsB,OAAO,aAAa;MACxD,SAAS,EAAE,MAAM,KAAK;MACtB,UAAU;QACR,GAAGD,qBAAoB,QAAQ;QAC/B,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAErD,UAAM,OAAO;MACX,GAAG;MACH,QAAQ;MAER,gBAAgB;QACd,eAAe;MACjB;IACF;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMG,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BE;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,QAAI,eAA4C;AAChD,UAAM,mBAA6C,EAAE,QAAQ,CAAC,EAAE;AAChE,UAAM,QAA8B;MAClC,aAAa;MACb,cAAc;MACd,aAAa;IACf;AACA,QAAI,eAAe;AAEnB,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AAC3B,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;gBACjB,MAAM;gBACN,GAAGN,qBAAoB,KAAK;cAC9B,CAAC;AAED,yBAAW,QAAQ,EAAE,MAAM,cAAc,IAAI,IAAI,CAAC;YACpD;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,oBAAM,cAAc,MAAM,MAAM;AAChC,oBAAM,eAAe,MAAM,MAAM;AACjC,oBAAM,cAAc,MAAM,MAAM;YAClC;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,UAAA,OAAA,SAAA,OAAQ,kBAAiB,MAAM;AACjC,6BAAeC,uBAAsB,OAAO,aAAa;YAC3D;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,aAAY,MAAM;AAC5B,+BAAiB,OAAO,WAAW,OAAO;YAC5C;AAEA,iBAAI,UAAA,OAAA,SAAA,OAAQ,SAAQ,QAAQ,OAAO,KAAK,SAAS,GAAG;AAClD,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI;gBACJ,OAAO,OAAO;cAChB,CAAC;YACH;UACF;UAEA,MAAM,YAAY;AAChB,gBAAI,CAAC,cAAc;AACjB,yBAAW,QAAQ,EAAE,MAAM,YAAY,IAAI,IAAI,CAAC;YAClD;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA;cACA;YACF,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AAEA,IAAM,cAAcL,iBAAE,OAAO;EAC3B,eAAeA,iBAAE,OAAO;EACxB,mBAAmBA,iBAAE,OAAO;EAC5B,cAAcA,iBAAE,OAAO;AACzB,CAAC;AAID,IAAM,iCAAiCA,iBAAE,OAAO;EAC9C,IAAIA,iBAAE,OAAO,EAAE,QAAQ;EACvB,SAASA,iBAAE,OAAO,EAAE,QAAQ;EAC5B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;EAC1B,SAASA,iBAAE;IACTA,iBAAE,OAAO;MACP,MAAMA,iBAAE,OAAO;MACf,eAAeA,iBAAE,OAAO;MACxB,UAAUA,iBACP,OAAO;QACN,QAAQA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;QAC1B,gBAAgBA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;QAClC,cAAcA,iBAAE,MAAMA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;MAClE,CAAC,EACA,QAAQ;IACb,CAAC;EACH;EACA,OAAO,YAAY,QAAQ;AAC7B,CAAC;AAID,IAAM,8BAA8BA,iBAAE,MAAM;EAC1CA,iBAAE,OAAO;IACP,IAAIA,iBAAE,OAAO,EAAE,QAAQ;IACvB,SAASA,iBAAE,OAAO,EAAE,QAAQ;IAC5B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;IAC1B,SAASA,iBAAE;MACTA,iBAAE,OAAO;QACP,MAAMA,iBAAE,OAAO;QACf,eAAeA,iBAAE,OAAO,EAAE,QAAQ;QAClC,OAAOA,iBAAE,OAAO;QAChB,UAAUA,iBACP,OAAO;UACN,QAAQA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;UAC1B,gBAAgBA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;UAClC,cAAcA,iBAAE,MAAMA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;QAClE,CAAC,EACA,QAAQ;MACb,CAAC;IACH;IACA,OAAO,YAAY,QAAQ;EAC7B,CAAC;EACD;AACF,CAAC;AMvXM,IAAM,iCAAiCA,iBAAE,OAAO;;;;;EAKrD,YAAYA,iBAAE,OAAO,EAAE,SAAS;;;;;EAMhC,MAAMA,iBAAE,OAAO,EAAE,SAAS;AAC5B,CAAC;ADFM,IAAM,uBAAN,MAA+D;EAYpE,YAAY,SAAiC,QAAsB;AAXnE,SAAS,uBAAuB;AAEhC,SAAS,uBAAuB;AAChC,SAAS,wBAAwB;AAS/B,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAPA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAM,QAAQ;IACZ;IACA;IACA;IACA;EACF,GAEE;AA1CJ,QAAA;AA2CI,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,mCAAmC;QAC3C,UAAU,KAAK;QACf,SAAS,KAAK;QACd,sBAAsB,KAAK;QAC3B;MACF,CAAC;IACH;AAGA,UAAM,iBACH,KAAA,MAAMM,qBAAqB;MAC1B,UAAU;MACV;MACA,QAAQ;IACV,CAAC,MAJA,OAAA,KAIM,CAAC;AAEV,UAAM;MACJ;MACA,OAAO;MACP;IACF,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;MACtD,MAAM;QACJ,OAAO,KAAK;QACZ,OAAO;QACP,iBAAiB;QACjB,YAAY,cAAc;QAC1B,MAAM,cAAc;MACtB;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,YAAY,SAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,SAAS;MACpD,OAAO,SAAS,QACZ,EAAE,QAAQ,SAAS,MAAM,cAAc,IACvC;MACJ,UAAU,EAAE,SAAS,iBAAiB,MAAM,SAAS;IACvD;EACF;AACF;AAIA,IAAM,oCAAoCT,iBAAE,OAAO;EACjD,MAAMA,iBAAE,MAAMA,iBAAE,OAAO,EAAE,WAAWA,iBAAE,MAAMA,iBAAE,OAAO,CAAC,EAAE,CAAC,CAAC;EAC1D,OAAOA,iBAAE,OAAO,EAAE,eAAeA,iBAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AACzD,CAAC;AG7FM,IAAM,wBAA4D;EACvE,YAAY;EACZ,YAAY;EACZ,eAAe;AACjB;AAEO,IAAM,2BAA2B,oBAAI,IAAI,CAAC,aAAa,CAAC;ADQxD,IAAM,mBAAN,MAA+C;EAWpD,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AAZnB,SAAS,uBAAuB;EAa7B;EAXH,IAAI,mBAA2B;AAxBjC,QAAA;AAyBI,YAAO,KAAA,sBAAsB,KAAK,OAAO,MAAlC,OAAA,KAAuC;EAChD;EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAM,WAAW;IACf;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAEE;AAhDJ,QAAA,IAAA,IAAA,IAAA;AAiDI,UAAM,WAA2C,CAAC;AAElD,QAAI,eAAe,MAAM;AACvB,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;IACH;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;IAChE;AAEA,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,OAAO,UAAU,gBAAgB,IAAI,MAAMO,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;MACtD,MAAM;QACJ,OAAO,KAAK;QACZ;QACA;QACA;QACA,IAAI,KAAA,gBAAgB,WAAhB,OAAA,KAA0B,CAAC;QAC/B,GAAI,CAAC,yBAAyB,IAAI,KAAK,OAAO,IAC1C,EAAE,iBAAiB,WAAW,IAC9B,CAAC;MACP;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA;MACA,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL,QAAQ,SAAS,KAAK,IAAI,CAAA,SAAQ,KAAK,QAAQ;MAC/C;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;MACX;MACA,kBAAkB;QAChB,QAAQ;UACN,QAAQ,SAAS,KAAK;YAAI,CAAA,SACxB,KAAK,iBACD;cACE,eAAe,KAAK;YACtB,IACA;UACN;QACF;MACF;IACF;EACF;AACF;AAIA,IAAM,4BAA4BT,iBAAE,OAAO;EACzC,MAAMA,iBAAE;IACNA,iBAAE,OAAO,EAAE,UAAUA,iBAAE,OAAO,GAAG,gBAAgBA,iBAAE,OAAO,EAAE,SAAS,EAAE,CAAC;EAC1E;AACF,CAAC;AEnHM,IAAM,6BAA6BA,iBAAE,OAAO;EACjD,MAAMA,iBAAE,OAAO,EAAE,QAAQ;EACzB,aAAaA,iBAAE,OAAO;AACxB,CAAC;AAEM,IAAM,8BAA8BA,iBAAE,OAAO;EAClD,SAASA,iBACN;IACCA,iBAAE,mBAAmB,QAAQ;MAC3BA,iBAAE,OAAO,EAAE,MAAMA,iBAAE,QAAQ,MAAM,GAAG,MAAMA,iBAAE,OAAO,EAAE,CAAC;MACtDA,iBAAE,OAAO,EAAE,MAAMA,iBAAE,QAAQ,OAAO,GAAG,KAAKA,iBAAE,OAAO,EAAE,CAAC;IACxD,CAAC;EACH,EACC,QAAQ;AACb,CAAC;AAEM,IAAM,4BAA4BA,iBAAE,OAAO;EAChD,WAAWA,iBACR,MAAM;IACLA,iBAAE,OAAO;IACTA,iBAAE,OAAO;MACP,SAASA,iBAAE,MAAMA,iBAAE,OAAO,CAAC,EAAE,SAAS;IACxC,CAAC;EACH,CAAC,EACA,SAAS;AACd,CAAC;AAWM,IAAM,6BACX,iDAqCE;EACA,IAAI;EACJ,MAAM;EACN,aAAa;EACb,cAAc;AAChB,CAAC;AAEI,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;ACjFA,IAAM,yBAAyBA,iBAAE,OAAO;EACtC,KAAKA,iBAAE,OAAO;EACd,MAAMA,iBAAE,KAAK,CAAC,MAAM,MAAM,MAAM,OAAO,MAAM,KAAK,CAAC;EACnD,OAAOA,iBAAE,MAAM,CAACA,iBAAE,OAAO,GAAGA,iBAAE,OAAO,GAAGA,iBAAE,QAAQ,CAAC,CAAC;AACtD,CAAC;AAED,IAAM,uBAAuCA,iBAAE,OAAO;EACpD,MAAMA,iBAAE,KAAK,CAAC,OAAO,IAAI,CAAC;EAC1B,SAASA,iBAAE;IACTA,iBAAE,MAAM,CAAC,wBAAwBA,iBAAE,KAAK,MAAM,oBAAoB,CAAC,CAAC;EACtE;AACF,CAAC;AAEM,IAAM,uBAAuBA,iBAAE,OAAO;EAC3C,gBAAgBA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;EAClC,eAAeA,iBAAE,OAAO,EAAE,SAAS;EACnC,SAASA,iBACN,OAAO;IACN,QAAQA,iBAAE,OAAO,EAAE,SAAS;IAC5B,gBAAgBA,iBAAE,OAAO,EAAE,SAAS;EACtC,CAAC,EACA,SAAS;EACZ,SAASA,iBAAE,MAAM,CAAC,wBAAwB,oBAAoB,CAAC,EAAE,SAAS;AAC5E,CAAC;AAEM,IAAM,yBAAyBA,iBAAE,OAAO;EAC7C,SAASA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;EAC3B,SAASA,iBACN;IACCA,iBAAE,OAAO;MACP,YAAYA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,QAAQ,CAAC;MAC5C,QAAQA,iBAAE,OAAO;MACjB,UAAUA,iBAAE,OAAO;MACnB,OAAOA,iBAAE,OAAO;MAChB,MAAMA,iBAAE,OAAO;IACjB,CAAC;EACH,EACC,SAAS;AACd,CAAC;AAEM,IAAM,aAAaW,iDA+ExB;EACA,IAAI;EACJ,MAAM;EACN,aAAaX,iBAAE,OAAO,CAAC,CAAC;EACxB,cAAc;AAChB,CAAC;AChIM,IAAM,4BAA4BA,iBACtC,OAAO;EACN,YAAYA,iBAAE,KAAK,CAAC,QAAQ,UAAU,aAAa,CAAC,EAAE,SAAS;EAC/D,eAAeA,iBAAE,KAAK,CAAC,OAAO,MAAM,CAAC,EAAE,SAAS;EAChD,gBAAgBA,iBACb,OAAO;IACN,QAAQA,iBAAE,OAAO,EAAE,SAAS;IAC5B,UAAUA,iBAAE,OAAO,EAAE,SAAS;EAChC,CAAC,EACA,SAAS;EACZ,OAAOA,iBAAE,OAAO,EAAE,SAAS;EAC3B,YAAYA,iBAAE,KAAK,CAAC,MAAM,CAAC,EAAE,SAAS;EACtC,mBAAmBA,iBAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,GAAG,EAAE,SAAS;EAC7D,cAAcA,iBAAE,KAAK,CAAC,OAAO,QAAQ,MAAM,CAAC,EAAE,SAAS;EACvD,SAASA,iBAAE,KAAK,CAAC,QAAQ,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;EAC5D,MAAMA,iBAAE,KAAK,CAAC,aAAa,aAAa,aAAa,MAAM,CAAC,EAAE,SAAS;AACzE,CAAC,EACA,OAAO;AAEH,IAAM,8BAA8BA,iBAAE,OAAO;EAClD,QAAQA,iBAAE,OAAO;AACnB,CAAC;AAgED,IAAM,6BACJW,iDASE;EACA,IAAI;EACJ,MAAM;EACN,aAAaX,iBAAE,OAAO,CAAC,CAAC;EACxB,cAAc;AAChB,CAAC;AAEI,IAAM,kBAAkB,CAC7B,OAA4B,CAAC,MAC1B;AACH,SAAO,2BAA2B,IAAI;AACxC;AC1GO,IAAM,sBAAsBA,iBAAE,OAAO;EAC1C,SAASA,iBACN,OAAO;IACN,gBAAgBA,iBAAE,MAAMA,iBAAE,OAAO,CAAC,EAAE,SAAS;EAC/C,CAAC,EACA,SAAS;EAEZ,mBAAmBA,iBAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;EAE9D,cAAcA,iBACX,OAAO;IACN,MAAMA,iBAAE,QAAQ,aAAa;IAC7B,SAASA,iBAAE,OAAO,EAAE,SAAS;IAC7B,MAAMA,iBAAE,OAAO,EAAE,SAAS;IAC1B,QAAQA,iBAAE,OAAO,EAAE,SAAS;IAC5B,UAAUA,iBAAE,OAAO,EAAE,SAAS;EAChC,CAAC,EACA,SAAS;AACd,CAAC;AAEM,IAAM,uBAAuB,iCAmDlC;EACA,IAAI;EACJ,MAAM;EACN,aAAaA,iBAAE,OAAO;IACpB,QAAQA,iBACL,mBAAmB,QAAQ;MAC1BA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,QAAQ;QACxB,OAAOA,iBAAE,OAAO,EAAE,QAAQ;MAC5B,CAAC;MACDA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,WAAW;QAC3B,KAAKA,iBAAE,OAAO;MAChB,CAAC;MACDA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,MAAM;QACtB,KAAKA,iBAAE,OAAO;QACd,SAASA,iBAAE,OAAO;MACpB,CAAC;IACH,CAAC,EACA,QAAQ;EACb,CAAC;AACH,CAAC;AAEM,IAAM,YAAY,CACvB,OAAmD,CAAC,MACjD;AACH,SAAO,qBAAqB,IAAI;AAClC;AClGO,IAAM,6BAA6BA,iBAAE,OAAO;;;;;;;EAOjD,mBAAmBA,iBAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,SAAS;;;;EAK9D,cAAcA,iBACX,OAAO;;;;IAIN,MAAMA,iBAAE,QAAQ,aAAa;;;;IAI7B,SAASA,iBAAE,OAAO,EAAE,SAAS;;;;IAI7B,MAAMA,iBAAE,OAAO,EAAE,SAAS;;;;IAI1B,QAAQA,iBAAE,OAAO,EAAE,SAAS;;;;IAI5B,UAAUA,iBAAE,OAAO,EAAE,SAAS;EAChC,CAAC,EACA,SAAS;AACd,CAAC;AAEM,IAAM,mBAAmBY,iCAuC9B;EACA,IAAI;EACJ,MAAM;EACN,aAAaZ,iBAAE,OAAO;IACpB,QAAQA,iBACL,mBAAmB,QAAQ;MAC1BA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,QAAQ;QACxB,OAAOA,iBAAE,OAAO,EAAE,QAAQ;MAC5B,CAAC;MACDA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,WAAW;QAC3B,KAAKA,iBAAE,OAAO;MAChB,CAAC;MACDA,iBAAE,OAAO;QACP,MAAMA,iBAAE,QAAQ,MAAM;QACtB,KAAKA,iBAAE,OAAO;QACd,SAASA,iBAAE,OAAO;MACpB,CAAC;IACH,CAAC,EACA,QAAQ;EACb,CAAC;AACH,CAAC;ACjGM,IAAM,cAAc;;;;;;;;;;EAUzB;;;;;;;;;;;;;EAcA;;;;;;;;;;;;;;EAeA;;;;;;;;;;;;EAaA;;;;;;;;;;;EAYA;AACF;AEtDA,SAAS,SAAS,MAAc,UAAuC;AACrE,MAAI,CAAC,SAAU,QAAO;AACtB,SAAO,SAAS,KAAK,CAAA,WAAU,KAAK,WAAW,MAAM,CAAC;AACxD;AAEA,eAAsB,8BAA8B;EAClD;EACA;EACA;EACA;AACF,GAQG;AAnCH,MAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAoCE,QAAM,QAA8B,CAAC;AACrC,QAAM,WAA8C,CAAC;AAErD,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;MACZ,KAAK,UAAU;AACb,gBAAQ,mBAAmB;UACzB,KAAK,UAAU;AACb,kBAAM,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACtC;UACF;UACA,KAAK,aAAa;AAChB,kBAAM,KAAK,EAAE,MAAM,aAAa,QAAQ,CAAC;AACzC;UACF;UACA,KAAK,UAAU;AACb,qBAAS,KAAK;cACZ,MAAM;cACN,SAAS;YACX,CAAC;AACD;UACF;UACA,SAAS;AACP,kBAAM,mBAA0B;AAChC,kBAAM,IAAI;cACR,oCAAoC,gBAAgB;YACtD;UACF;QACF;AACA;MACF;MAEA,KAAK,QAAQ;AACX,cAAM,KAAK;UACT,MAAM;UACN,SAAS,QAAQ,IAAI,CAAC,MAAM,UAAU;AAvEhD,gBAAAa,KAAAC,KAAAC;AAwEY,oBAAQ,KAAK,MAAM;cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,cAAc,MAAM,KAAK,KAAK;cAC/C;cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,UAAU,WAAW,QAAQ,GAAG;AACvC,wBAAM,YACJ,KAAK,cAAc,YACf,eACA,KAAK;AAEX,yBAAO;oBACL,MAAM;oBACN,GAAI,KAAK,gBAAgB,MACrB,EAAE,WAAW,KAAK,KAAK,SAAS,EAAE,IAClC,OAAO,KAAK,SAAS,YACnB,SAAS,KAAK,MAAM,cAAc,IAClC,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAW,QAAQ,SAAS,WAAWC,gBAAgB,KAAK,IAAI,CAAC;oBACnE;oBACN,SAAQF,OAAAD,MAAA,KAAK,oBAAL,OAAA,SAAAA,IAAsB,WAAtB,OAAA,SAAAC,IAA8B;kBACxC;gBACF,WAAW,KAAK,cAAc,mBAAmB;AAC/C,sBAAI,KAAK,gBAAgB,KAAK;AAC5B,2BAAO;sBACL,MAAM;sBACN,UAAU,KAAK,KAAK,SAAS;oBAC/B;kBACF;AACA,yBAAO;oBACL,MAAM;oBACN,GAAI,OAAO,KAAK,SAAS,YACzB,SAAS,KAAK,MAAM,cAAc,IAC9B,EAAE,SAAS,KAAK,KAAK,IACrB;sBACE,WAAUC,MAAA,KAAK,aAAL,OAAAA,MAAiB,QAAQ,KAAK;sBACxC,WAAW,+BAA+BC,gBAAgB,KAAK,IAAI,CAAC;oBACtE;kBACN;gBACF,OAAO;AACL,wBAAM,IAAId,8BAA8B;oBACtC,eAAe,wBAAwB,KAAK,SAAS;kBACvD,CAAC;gBACH;cACF;YACF;UACF,CAAC;QACH,CAAC;AAED;MACF;MAEA,KAAK,aAAa;AAChB,cAAM,oBAA8D,CAAC;AACrE,cAAM,gBAA6D,CAAC;AAEpE,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;YACjB,KAAK,QAAQ;AACX,oBAAM,KAAK;gBACT,MAAM;gBACN,SAAS,CAAC,EAAE,MAAM,eAAe,MAAM,KAAK,KAAK,CAAC;gBAClD,KACG,MAAA,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GAA8B,WAA9B,OAAA,KAAmD;cACxD,CAAC;AACD;YACF;YACA,KAAK,aAAa;AAChB,4BAAc,KAAK,UAAU,IAAI;AAEjC,kBAAI,KAAK,kBAAkB;AACzB;cACF;AAEA,oBAAM,KAAK;gBACT,MAAM;gBACN,SAAS,KAAK;gBACd,MAAM,KAAK;gBACX,WAAW,KAAK,UAAU,KAAK,KAAK;gBACpC,KACG,MAAA,MAAA,KAAA,KAAK,oBAAL,OAAA,SAAA,GAAsB,WAAtB,OAAA,SAAA,GAA8B,WAA9B,OAAA,KAAmD;cACxD,CAAC;AACD;YACF;YAGA,KAAK,eAAe;AAClB,kBAAI,OAAO;AAET,sBAAM,KAAK,EAAE,MAAM,kBAAkB,IAAI,KAAK,WAAW,CAAC;cAC5D,OAAO;AACL,yBAAS,KAAK;kBACZ,MAAM;kBACN,SAAS,2BAA2B,KAAK,QAAQ;gBACnD,CAAC;cACH;AAEA;YACF;YAEA,KAAK,aAAa;AAChB,oBAAM,kBAAkB,MAAMI,qBAAqB;gBACjD,UAAU;gBACV,iBAAiB,KAAK;gBACtB,QAAQ;cACV,CAAC;AAED,oBAAM,cAAc,mBAAA,OAAA,SAAA,gBAAiB;AAErC,kBAAI,eAAe,MAAM;AACvB,sBAAM,2BAA2B,kBAAkB,WAAW;AAE9D,sBAAM,eAGD,CAAC;AAEN,oBAAI,KAAK,KAAK,SAAS,GAAG;AACxB,+BAAa,KAAK,EAAE,MAAM,gBAAgB,MAAM,KAAK,KAAK,CAAC;gBAC7D,WAAW,6BAA6B,QAAW;AACjD,2BAAS,KAAK;oBACZ,MAAM;oBACN,SAAS,+FAA+F,KAAK,UAAU,IAAI,CAAC;kBAC9H,CAAC;gBACH;AAEA,oBAAI,6BAA6B,QAAW;AAC1C,oCAAkB,WAAW,IAAI;oBAC/B,MAAM;oBACN,IAAI;oBACJ,mBACE,mBAAA,OAAA,SAAA,gBAAiB;oBACnB,SAAS;kBACX;AACA,wBAAM,KAAK,kBAAkB,WAAW,CAAC;gBAC3C,OAAO;AACL,2CAAyB,QAAQ,KAAK,GAAG,YAAY;gBACvD;cACF,OAAO;AACL,yBAAS,KAAK;kBACZ,MAAM;kBACN,SAAS,0EAA0E,KAAK,UAAU,IAAI,CAAC;gBACzG,CAAC;cACH;AACA;YACF;UACF;QACF;AAEA;MACF;MAEA,KAAK,QAAQ;AACX,mBAAW,QAAQ,SAAS;AAC1B,gBAAM,SAAS,KAAK;AAEpB,cAAI;AACJ,kBAAQ,OAAO,MAAM;YACnB,KAAK;YACL,KAAK;AACH,6BAAe,OAAO;AACtB;YACF,KAAK;YACL,KAAK;YACL,KAAK;AACH,6BAAe,KAAK,UAAU,OAAO,KAAK;AAC1C;UACJ;AAEA,gBAAM,KAAK;YACT,MAAM;YACN,SAAS,KAAK;YACd,QAAQ;UACV,CAAC;QACH;AAEA;MACF;MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;MACzD;IACF;EACF;AAEA,SAAO,EAAE,OAAO,SAAS;AAC3B;AAEA,IAAM,gDAAgDN,iBAAE,OAAO;EAC7D,QAAQA,iBAAE,OAAO,EAAE,QAAQ;EAC3B,2BAA2BA,iBAAE,OAAO,EAAE,QAAQ;AAChD,CAAC;ACvQM,SAAS,8BAA8B;EAC5C;EACA;AACF,GAIgC;AAC9B,UAAQ,cAAc;IACpB,KAAK;IACL,KAAK;AACH,aAAO,kBAAkB,eAAe;IAC1C,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT;AACE,aAAO,kBAAkB,eAAe;EAC5C;AACF;ACTO,SAAS,sBAAsB;EACpC;EACA;EACA;AACF,GAiBE;AAEA,WAAQ,SAAA,OAAA,SAAA,MAAO,UAAS,QAAQ;AAEhC,QAAM,eAA6C,CAAC;AAEpD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,YAAY,QAAW,aAAa;EACjE;AAEA,QAAMC,eAA0C,CAAC;AAEjD,aAAW,QAAQ,OAAO;AACxB,YAAQ,KAAK,MAAM;MACjB,KAAK;AACHA,qBAAY,KAAK;UACf,MAAM;UACN,MAAM,KAAK;UACX,aAAa,KAAK;UAClB,YAAY,KAAK;UACjB,QAAQ;QACV,CAAC;AACD;MACF,KAAK,oBAAoB;AACvB,gBAAQ,KAAK,IAAI;UACf,KAAK,sBAAsB;AACzB,kBAAM,OAAO,qBAAqB,MAAM,KAAK,IAAI;AAEjDA,yBAAY,KAAK;cACf,MAAM;cACN,kBAAkB,KAAK;cACvB,iBAAiB,KAAK;cACtB,iBAAiB,KAAK,UAClB;gBACE,QAAQ,KAAK,QAAQ;gBACrB,iBAAiB,KAAK,QAAQ;cAChC,IACA;cACJ,SAAS,KAAK;YAChB,CAAC;AAED;UACF;UACA,KAAK,6BAA6B;AAChC,kBAAM,OAAO,2BAA2B,MAAM,KAAK,IAAI;AACvDA,yBAAY,KAAK;cACf,MAAM;cACN,qBAAqB,KAAK;cAC1B,eAAe,KAAK;YACtB,CAAC;AACD;UACF;UACA,KAAK,qBAAqB;AACxB,kBAAM,OAAO,oBAAoB,MAAM,KAAK,IAAI;AAChDA,yBAAY,KAAK;cACf,MAAM;cACN,SACE,KAAK,WAAW,OACZ,EAAE,iBAAiB,KAAK,QAAQ,eAAe,IAC/C;cACN,qBAAqB,KAAK;cAC1B,eAAe,KAAK;YACtB,CAAC;AACD;UACF;UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,0BAA0B,MAAM,KAAK,IAAI;AACtDA,yBAAY,KAAK;cACf,MAAM;cACN,WACE,KAAK,aAAa,OACd,EAAE,MAAM,QAAQ,UAAU,OAAU,IACpC,OAAO,KAAK,cAAc,WACxB,KAAK,YACL,EAAE,MAAM,QAAQ,UAAU,KAAK,UAAU,QAAQ;YAC3D,CAAC;AACD;UACF;UACA,KAAK,2BAA2B;AAC9B,kBAAM,OAAO,0BAA0B,MAAM,KAAK,IAAI;AACtDA,yBAAY,KAAK;cACf,MAAM;cACN,YAAY,KAAK;cACjB,gBAAgB,KAAK;cACrB,kBAAkB,KAAK,iBACnB;gBACE,SAAS,KAAK,eAAe;gBAC7B,WAAW,KAAK,eAAe;cACjC,IACA;cACJ,OAAO,KAAK;cACZ,MAAM,KAAK;cACX,SAAS,KAAK;cACd,YAAY,KAAK;cACjB,eAAe,KAAK;cACpB,oBAAoB,KAAK;YAC3B,CAAC;AACD;UACF;QACF;AACA;MACF;MACA;AACE,qBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AACpD;IACJ;EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAOA,cAAa,YAAY,QAAW,aAAa;EACnE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;IACZ,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO,EAAE,OAAOA,cAAa,YAAY,MAAM,aAAa;IAC9D,KAAK;AACH,aAAO;QACL,OAAOA;QACP,YACE,WAAW,aAAa,sBACxB,WAAW,aAAa,iBACxB,WAAW,aAAa,sBACxB,WAAW,aAAa,wBACxB,WAAW,aAAa,eACpB,EAAE,MAAM,WAAW,SAAS,IAC5B,EAAE,MAAM,YAAY,MAAM,WAAW,SAAS;QACpD;MACF;IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAIC,8BAA8B;QACtC,eAAe,qBAAqB,gBAAgB;MACtD,CAAC;IACH;EACF;AACF;AHtIA,IAAM,oBAAoBF,iBAAE,OAAO;EACjC,MAAMA,iBAAE,QAAQ,iBAAiB;EACjC,IAAIA,iBAAE,OAAO;EACb,QAAQA,iBAAE,OAAO;EACjB,QAAQA,iBACL,mBAAmB,QAAQ;IAC1BA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,QAAQ;MACxB,OAAOA,iBAAE,OAAO,EAAE,QAAQ;IAC5B,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,WAAW;MAC3B,KAAKA,iBAAE,OAAO;IAChB,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,MAAM;MACtB,KAAKA,iBAAE,OAAO;MACd,SAASA,iBAAE,OAAO;IACpB,CAAC;EACH,CAAC,EACA,QAAQ;AACb,CAAC;AAED,IAAM,qBAAqBA,iBAAE,OAAO;EAClC,MAAMA,iBAAE,QAAQ,kBAAkB;EAClC,IAAIA,iBAAE,OAAO;EACb,SAASA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;EAC3B,SAASA,iBACN;IACCA,iBAAE,OAAO;MACP,YAAYA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,QAAQ,CAAC;MAC5C,SAASA,iBAAE,OAAO;MAClB,UAAUA,iBAAE,OAAO;MACnB,OAAOA,iBAAE,OAAO;MAChB,MAAMA,iBAAE,OAAO;IACjB,CAAC;EACH,EACC,QAAQ;AACb,CAAC;AAED,IAAM,0BAA0BA,iBAAE,OAAO;EACvC,MAAMA,iBAAE,QAAQ,uBAAuB;EACvC,IAAIA,iBAAE,OAAO;EACb,MAAMA,iBAAE,OAAO,EAAE,SAAS;EAC1B,cAAcA,iBAAE,OAAO;EACvB,SAASA,iBACN;IACCA,iBAAE,mBAAmB,QAAQ;MAC3BA,iBAAE,OAAO,EAAE,MAAMA,iBAAE,QAAQ,MAAM,GAAG,MAAMA,iBAAE,OAAO,EAAE,CAAC;MACtDA,iBAAE,OAAO,EAAE,MAAMA,iBAAE,QAAQ,OAAO,GAAG,KAAKA,iBAAE,OAAO,EAAE,CAAC;IACxD,CAAC;EACH,EACC,SAAS;AACd,CAAC;AAED,IAAM,0BAA0BA,iBAAE,OAAO;EACvC,MAAMA,iBAAE,QAAQ,uBAAuB;EACvC,IAAIA,iBAAE,OAAO;EACb,QAAQA,iBAAE,OAAO;AACnB,CAAC;AASD,IAAM,mBAAmB;AAEzB,IAAM,kBAAkBA,iBAAE;EACxBA,iBAAE,OAAO;IACP,OAAOA,iBAAE,OAAO;IAChB,SAASA,iBAAE,OAAO;IAClB,cAAcA,iBAAE;MACdA,iBAAE,OAAO;QACP,OAAOA,iBAAE,OAAO;QAChB,SAASA,iBAAE,OAAO;MACpB,CAAC;IACH;EACF,CAAC;AACH;AAEO,IAAM,+BAAN,MAA8D;EAOnE,YAAY,SAAiC,QAAsB;AANnE,SAAS,uBAAuB;AAWhC,SAAS,gBAA0C;MACjD,WAAW,CAAC,iBAAiB;MAC7B,mBAAmB,CAAC,iBAAiB;IACvC;AAPE,SAAK,UAAU;AACf,SAAK,SAAS;EAChB;EAOA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAc,QAAQ;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,GAAiD;AA5JnD,QAAA,IAAA,IAAA,IAAA;AA6JI,UAAM,WAAyC,CAAC;AAChD,UAAM,cAAc,wBAAwB,KAAK,OAAO;AAExD,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;IAChE;AAEA,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,OAAO,CAAC;IAChE;AAEA,QAAI,mBAAmB,MAAM;AAC3B,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QAAI,oBAAoB,MAAM;AAC5B,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;MACX,CAAC;IACH;AAEA,QAAI,iBAAiB,MAAM;AACzB,eAAS,KAAK,EAAE,MAAM,uBAAuB,SAAS,gBAAgB,CAAC;IACzE;AAEA,UAAM,gBAAgB,MAAMM,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAED,UAAM,EAAE,OAAO,UAAU,cAAc,IACrC,MAAM,8BAA8B;MAClC;MACA,mBAAmB,YAAY;MAC/B,gBAAgB,KAAK,OAAO;MAC5B,QAAO,KAAA,iBAAA,OAAA,SAAA,cAAe,UAAf,OAAA,KAAwB;IACjC,CAAC;AAEH,aAAS,KAAK,GAAG,aAAa;AAE9B,UAAM,oBAAmB,KAAA,iBAAA,OAAA,SAAA,cAAe,qBAAf,OAAA,KAAmC;AAE5D,QAAI,UAAyC,iBAAA,OAAA,SAAA,cAAe;AAE5D,aAAS,WAAW,KAAkC;AACpD,gBAAU,WAAW,OAAO,CAAC,GAAG,SAAS,GAAG,IAAI,CAAC,GAAG;IACtD;AAEA,aAAS,cAAc,IAAY;AACjC,cACE,SAAA,OAAA,SAAA,MAAO;QACL,CAAA,SAAQ,KAAK,SAAS,sBAAsB,KAAK,OAAO;MAAA,MACrD;IAET;AAGA,UAAM,cACJ,QAAO,iBAAA,OAAA,SAAA,cAAe,cAAa,WAC/B,iBAAA,OAAA,SAAA,cAAe,YACf,iBAAA,OAAA,SAAA,cAAe,cAAa,OAC1B,mBACA;AAER,QAAI,aAAa;AACf,iBAAW,8BAA8B;IAC3C;AAGA,UAAM,qBACJ,KAAA,SAAA,OAAA,SAAA,MAAO;MACL,CAAA,SACE,KAAK,SAAS,uBACb,KAAK,OAAO,uBACX,KAAK,OAAO;IAAA,MAJlB,OAAA,SAAA,GAMC;AAEH,QAAI,mBAAmB;AACrB,iBAAW,gCAAgC;IAC7C;AAGA,QAAI,cAAc,yBAAyB,GAAG;AAC5C,iBAAW,+BAA+B;IAC5C;AAEA,UAAM,WAAW;MACf,OAAO,KAAK;MACZ;MACA;MACA,OAAO;MACP,mBAAmB;MAEnB,KAAK,kBAAA,OAAA,SAAA,eAAgB,UAAS,WAAU,iBAAA,OAAA,SAAA,cAAe,mBAAkB;QACvE,MAAM;UACJ,IAAI,kBAAA,OAAA,SAAA,eAAgB,UAAS,UAAU;YACrC,QACE,eAAe,UAAU,OACrB;cACE,MAAM;cACN,QAAQ;cACR,OAAM,KAAA,eAAe,SAAf,OAAA,KAAuB;cAC7B,aAAa,eAAe;cAC5B,QAAQ,eAAe;YACzB,IACA,EAAE,MAAM,cAAc;UAC9B;UACA,IAAI,iBAAA,OAAA,SAAA,cAAe,kBAAiB;YAClC,WAAW,cAAc;UAC3B;QACF;MACF;;MAGA,gBAAgB,iBAAA,OAAA,SAAA,cAAe;MAC/B,UAAU,iBAAA,OAAA,SAAA,cAAe;MACzB,qBAAqB,iBAAA,OAAA,SAAA,cAAe;MACpC,sBAAsB,iBAAA,OAAA,SAAA,cAAe;MACrC,OAAO,iBAAA,OAAA,SAAA,cAAe;MACtB,MAAM,iBAAA,OAAA,SAAA,cAAe;MACrB,cAAc,iBAAA,OAAA,SAAA,cAAe;MAC7B,cAAc,iBAAA,OAAA,SAAA,cAAe;MAC7B;MACA,kBAAkB,iBAAA,OAAA,SAAA,cAAe;MACjC,mBAAmB,iBAAA,OAAA,SAAA,cAAe;MAClC,cAAc;;MAGd,GAAI,YAAY,sBACb,iBAAA,OAAA,SAAA,cAAe,oBAAmB,SACjC,iBAAA,OAAA,SAAA,cAAe,qBAAoB,SAAS;QAC5C,WAAW;UACT,IAAI,iBAAA,OAAA,SAAA,cAAe,oBAAmB,QAAQ;YAC5C,QAAQ,cAAc;UACxB;UACA,IAAI,iBAAA,OAAA,SAAA,cAAe,qBAAoB,QAAQ;YAC7C,SAAS,cAAc;UACzB;QACF;MACF;MACF,GAAI,YAAY,0BAA0B;QACxC,YAAY;MACd;IACF;AAEA,QAAI,YAAY,kBAAkB;AAGhC,UAAI,SAAS,eAAe,MAAM;AAChC,iBAAS,cAAc;AACvB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AAEA,UAAI,SAAS,SAAS,MAAM;AAC1B,iBAAS,QAAQ;AACjB,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;IACF,OAAO;AACL,WAAI,iBAAA,OAAA,SAAA,cAAe,oBAAmB,MAAM;AAC1C,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;AAEA,WAAI,iBAAA,OAAA,SAAA,cAAe,qBAAoB,MAAM;AAC3C,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS;QACX,CAAC;MACH;IACF;AAGA,SACE,iBAAA,OAAA,SAAA,cAAe,iBAAgB,UAC/B,CAAC,YAAY,wBACb;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AAED,aAAQ,SAAiB;IAC3B;AAGA,SACE,iBAAA,OAAA,SAAA,cAAe,iBAAgB,cAC/B,CAAC,YAAY,4BACb;AACA,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SACE;MACJ,CAAC;AAED,aAAQ,SAAiB;IAC3B;AAEA,UAAM;MACJ,OAAOL;MACP,YAAY;MACZ;IACF,IAAI,sBAAsB;MACxB;MACA;MACA;IACF,CAAC;AAED,WAAO;MACL;MACA,MAAM;QACJ,GAAG;QACH,OAAOA;QACP,aAAa;MACf;MACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;IACzC;EACF;EAEA,MAAM,WACJ,SAC6D;AA/YjE,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAgZI,UAAM;MACJ,MAAM;MACN;MACA;IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAC9B,UAAM,MAAM,KAAK,OAAO,IAAI;MAC1B,MAAM;MACN,SAAS,KAAK;IAChB,CAAC;AAED,UAAM;MACJ;MACA,OAAO;MACP,UAAU;IACZ,IAAI,MAAMM,cAAc;MACtB;MACA,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BC;QACzBT,iBAAE,OAAO;UACP,IAAIA,iBAAE,OAAO;UACb,YAAYA,iBAAE,OAAO;UACrB,OAAOA,iBACJ,OAAO;YACN,MAAMA,iBAAE,OAAO;YACf,SAASA,iBAAE,OAAO;UACpB,CAAC,EACA,QAAQ;UACX,OAAOA,iBAAE,OAAO;UAChB,QAAQA,iBAAE;YACRA,iBAAE,mBAAmB,QAAQ;cAC3BA,iBAAE,OAAO;gBACP,MAAMA,iBAAE,QAAQ,SAAS;gBACzB,MAAMA,iBAAE,QAAQ,WAAW;gBAC3B,IAAIA,iBAAE,OAAO;gBACb,SAASA,iBAAE;kBACTA,iBAAE,OAAO;oBACP,MAAMA,iBAAE,QAAQ,aAAa;oBAC7B,MAAMA,iBAAE,OAAO;oBACf,UAAU,gBAAgB,QAAQ;oBAClC,aAAaA,iBAAE;sBACbA,iBAAE,mBAAmB,QAAQ;wBAC3BA,iBAAE,OAAO;0BACP,MAAMA,iBAAE,QAAQ,cAAc;0BAC9B,aAAaA,iBAAE,OAAO;0BACtB,WAAWA,iBAAE,OAAO;0BACpB,KAAKA,iBAAE,OAAO;0BACd,OAAOA,iBAAE,OAAO;wBAClB,CAAC;wBACDA,iBAAE,OAAO;0BACP,MAAMA,iBAAE,QAAQ,eAAe;0BAC/B,SAASA,iBAAE,OAAO;0BAClB,UAAUA,iBAAE,OAAO,EAAE,QAAQ;0BAC7B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;0BAC1B,aAAaA,iBAAE,OAAO,EAAE,QAAQ;0BAChC,WAAWA,iBAAE,OAAO,EAAE,QAAQ;0BAC9B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;wBAC5B,CAAC;wBACDA,iBAAE,OAAO;0BACP,MAAMA,iBAAE,QAAQ,yBAAyB;wBAC3C,CAAC;sBACH,CAAC;oBACH;kBACF,CAAC;gBACH;cACF,CAAC;cACD;cACA;cACA;cACA;cACAA,iBAAE,OAAO;gBACP,MAAMA,iBAAE,QAAQ,eAAe;gBAC/B,SAASA,iBAAE,OAAO;gBAClB,MAAMA,iBAAE,OAAO;gBACf,WAAWA,iBAAE,OAAO;gBACpB,IAAIA,iBAAE,OAAO;cACf,CAAC;cACDA,iBAAE,OAAO;gBACP,MAAMA,iBAAE,QAAQ,eAAe;gBAC/B,IAAIA,iBAAE,OAAO;gBACb,QAAQA,iBAAE,OAAO,EAAE,SAAS;cAC9B,CAAC;cACDA,iBAAE,OAAO;gBACP,MAAMA,iBAAE,QAAQ,WAAW;gBAC3B,IAAIA,iBAAE,OAAO;gBACb,mBAAmBA,iBAAE,OAAO,EAAE,QAAQ;gBACtC,SAASA,iBAAE;kBACTA,iBAAE,OAAO;oBACP,MAAMA,iBAAE,QAAQ,cAAc;oBAC9B,MAAMA,iBAAE,OAAO;kBACjB,CAAC;gBACH;cACF,CAAC;YACH,CAAC;UACH;UACA,cAAcA,iBAAE,OAAO,EAAE,QAAQ;UACjC,oBAAoBA,iBAAE,OAAO,EAAE,QAAQA,iBAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;UAC7D,OAAOiB;QACT,CAAC;MACH;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,QAAI,SAAS,OAAO;AAClB,YAAM,IAAI,aAAa;QACrB,SAAS,SAAS,MAAM;QACxB;QACA,mBAAmB;QACnB,YAAY;QACZ;QACA,cAAc;QACd,aAAa;MACf,CAAC;IACH;AAEA,UAAM,UAAyC,CAAC;AAChD,UAAM,WAAmD,CAAC;AAG1D,QAAI,kBAAkB;AAGtB,eAAW,QAAQ,SAAS,QAAQ;AAClC,cAAQ,KAAK,MAAM;QACjB,KAAK,aAAa;AAEhB,cAAI,KAAK,QAAQ,WAAW,GAAG;AAC7B,iBAAK,QAAQ,KAAK,EAAE,MAAM,gBAAgB,MAAM,GAAG,CAAC;UACtD;AAEA,qBAAW,WAAW,KAAK,SAAS;AAClC,oBAAQ,KAAK;cACX,MAAM;cACN,MAAM,QAAQ;cACd,kBAAkB;gBAChB,QAAQ;kBACN,QAAQ,KAAK;kBACb,4BAA2B,KAAA,KAAK,sBAAL,OAAA,KAA0B;gBACvD;cACF;YACF,CAAC;UACH;AACA;QACF;QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,QAAQ;cACN,QAAQ,KAAK;YACf;YACA,kBAAkB;UACpB,CAAC;AAED;QACF;QAEA,KAAK,WAAW;AACd,qBAAW,eAAe,KAAK,SAAS;AACtC,kBACE,MAAA,KAAA,QAAQ,oBAAR,OAAA,SAAA,GAAyB,WAAzB,OAAA,SAAA,GAAiC,aACjC,YAAY,UACZ;AACA,uBAAS,KAAK,YAAY,QAAQ;YACpC;AAEA,oBAAQ,KAAK;cACX,MAAM;cACN,MAAM,YAAY;cAClB,kBAAkB;gBAChB,QAAQ;kBACN,QAAQ,KAAK;gBACf;cACF;YACF,CAAC;AAED,uBAAW,cAAc,YAAY,aAAa;AAChD,kBAAI,WAAW,SAAS,gBAAgB;AACtC,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BC,WAAW;kBAC7C,KAAK,WAAW;kBAChB,OAAO,WAAW;gBACpB,CAAC;cACH,WAAW,WAAW,SAAS,iBAAiB;AAC9C,wBAAQ,KAAK;kBACX,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QAAO,MAAA,KAAA,WAAW,UAAX,OAAA,KAAoB,WAAW,aAA/B,OAAA,KAA2C;kBAClD,WAAU,KAAA,WAAW,aAAX,OAAA,KAAuB,WAAW;gBAC9C,CAAC;cACH;YACF;UACF;AAEA;QACF;QAEA,KAAK,iBAAiB;AACpB,4BAAkB;AAElB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,KAAK;YACf,OAAO,KAAK;YACZ,kBAAkB;cAChB,QAAQ;gBACN,QAAQ,KAAK;cACf;YACF;UACF,CAAC;AACD;QACF;QAEA,KAAK,mBAAmB;AACtB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,qBAAA,OAAA,oBAAqB;YAC/B,OAAO,KAAK,UAAU,EAAE,QAAQ,KAAK,OAAO,CAAC;YAC7C,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU,qBAAA,OAAA,oBAAqB;YAC/B,QAAQ,EAAE,QAAQ,KAAK,OAAO;YAC9B,kBAAkB;UACpB,CAAC;AAED;QACF;QAEA,KAAK,iBAAiB;AACpB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,QAAQ;cACN,MAAM;cACN,QAAQ,KAAK,UAAU;YACzB;YACA,kBAAkB;UACpB,CAAC;AACD;QACF;QAEA,KAAK,oBAAoB;AACvB,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,OAAO;YACP,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,QAAQ;cACN,SAAS,KAAK;cACd,UACE,MAAA,KAAA,KAAK,YAAL,OAAA,SAAA,GAAc,IAAI,CAAA,YAAW;gBAC3B,YAAY,OAAO;gBACnB,QAAQ,OAAO;gBACf,UAAU,OAAO;gBACjB,OAAO,OAAO;gBACd,MAAM,OAAO;cACf,EAAA,MANA,OAAA,KAMO;YACX;YACA,kBAAkB;UACpB,CAAC;AACD;QACF;QAEA,KAAK,yBAAyB;AAC5B,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,OAAO,KAAK,UAAU;cACpB,MAAM,KAAK;cACX,aAAa,KAAK;YACpB,CAAsD;YACtD,kBAAkB;UACpB,CAAC;AAED,kBAAQ,KAAK;YACX,MAAM;YACN,YAAY,KAAK;YACjB,UAAU;YACV,QAAQ;cACN,SAAS,KAAK;YAChB;YACA,kBAAkB;UACpB,CAAC;AACD;QACF;MACF;IACF;AAEA,UAAM,mBAA6C;MACjD,QAAQ,EAAE,YAAY,SAAS,GAAG;IACpC;AAEA,QAAI,SAAS,SAAS,GAAG;AACvB,uBAAiB,OAAO,WAAW;IACrC;AAEA,QAAI,OAAO,SAAS,iBAAiB,UAAU;AAC7C,uBAAiB,OAAO,cAAc,SAAS;IACjD;AAEA,WAAO;MACL;MACA,cAAc,8BAA8B;QAC1C,eAAc,KAAA,SAAS,uBAAT,OAAA,SAAA,GAA6B;QAC3C;MACF,CAAC;MACD,OAAO;QACL,aAAa,SAAS,MAAM;QAC5B,cAAc,SAAS,MAAM;QAC7B,aAAa,SAAS,MAAM,eAAe,SAAS,MAAM;QAC1D,kBACE,MAAA,KAAA,SAAS,MAAM,0BAAf,OAAA,SAAA,GAAsC,qBAAtC,OAAA,KAA0D;QAC5D,oBACE,MAAA,KAAA,SAAS,MAAM,yBAAf,OAAA,SAAA,GAAqC,kBAArC,OAAA,KAAsD;MAC1D;MACA,SAAS,EAAE,KAAK;MAChB,UAAU;QACR,IAAI,SAAS;QACb,WAAW,IAAI,KAAK,SAAS,aAAa,GAAI;QAC9C,SAAS,SAAS;QAClB,SAAS;QACT,MAAM;MACR;MACA;MACA;IACF;EACF;EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM;MACJ,MAAM;MACN;MACA;IACF,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE9B,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMX,cAAc;MAC/D,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;QACJ,GAAG;QACH,QAAQ;MACV;MACA,uBAAuB;MACvB,2BAA2BE;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,OAAO;AAEb,QAAI,eAA4C;AAChD,UAAM,QAA8B;MAClC,aAAa;MACb,cAAc;MACd,aAAa;IACf;AACA,UAAM,WAAmD,CAAC;AAC1D,QAAI,aAA4B;AAChC,UAAM,mBAGF,CAAC;AAGL,QAAI,kBAAkB;AAEtB,UAAM,kBAMF,CAAC;AAEL,QAAI;AAEJ,WAAO;MACL,QAAQ,SAAS;QACf,IAAI,gBAGF;UACA,MAAM,YAAY;AAChB,uBAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;UACvD;UAEA,UAAU,OAAO,YAAY;AAh0BvC,gBAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAi0BY,gBAAI,QAAQ,kBAAkB;AAC5B,yBAAW,QAAQ,EAAE,MAAM,OAAO,UAAU,MAAM,SAAS,CAAC;YAC9D;AAGA,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;YACF;AAEA,kBAAM,QAAQ,MAAM;AAEpB,gBAAI,+BAA+B,KAAK,GAAG;AACzC,kBAAI,MAAM,KAAK,SAAS,iBAAiB;AACvC,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,MAAM,KAAK;kBACrB,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU,MAAM,KAAK;gBACvB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU,qBAAA,OAAA,oBAAqB;kBAC/B,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU,qBAAA,OAAA,oBAAqB;gBACjC,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;kBACrC,UAAU;kBACV,YAAY,MAAM,KAAK;gBACzB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,UAAU;gBACZ,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,OAAO;kBACP,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,OAAO;kBACP,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,WAAW;AACxC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;kBACf,kBAAkB;oBAChB,QAAQ;sBACN,QAAQ,MAAM,KAAK;oBACrB;kBACF;gBACF,CAAC;cACH,WAAW,wCAAwC,KAAK,GAAG;AACzD,gCAAgB,MAAM,KAAK,EAAE,IAAI;kBAC/B,kBAAkB,MAAM,KAAK;kBAC7B,cAAc,CAAC,CAAC;gBAClB;AAEA,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,GAAG,MAAM,KAAK,EAAE;kBACpB,kBAAkB;oBAChB,QAAQ;sBACN,QAAQ,MAAM,KAAK;sBACnB,4BACE,KAAA,MAAM,KAAK,sBAAX,OAAA,KAAgC;oBACpC;kBACF;gBACF,CAAC;cACH;YACF,WAAW,8BAA8B,KAAK,GAAG;AAC/C,kBAAI,MAAM,KAAK,SAAS,iBAAiB;AACvC,iCAAiB,MAAM,YAAY,IAAI;AACvC,kCAAkB;AAElB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU,MAAM,KAAK;kBACrB,OAAO,MAAM,KAAK;kBAClB,kBAAkB;oBAChB,QAAQ;sBACN,QAAQ,MAAM,KAAK;oBACrB;kBACF;gBACF,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,mBAAmB;AAChD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,OAAO,KAAK,UAAU,EAAE,QAAQ,MAAM,KAAK,OAAO,CAAC;kBACnD,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,QAAQ,EAAE,QAAQ,MAAM,KAAK,OAAO;kBACpC,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,iBAAiB;AAC9C,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,OAAO;kBACP,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,QAAQ;oBACN,MAAM;oBACN,QAAQ,MAAM,KAAK,UAAU;kBAC/B;kBACA,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,oBAAoB;AACjD,iCAAiB,MAAM,YAAY,IAAI;AAEvC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,QAAQ;oBACN,SAAS,MAAM,KAAK;oBACpB,UACE,MAAA,KAAA,MAAM,KAAK,YAAX,OAAA,SAAA,GAAoB,IAAI,CAAA,YAAW;sBACjC,YAAY,OAAO;sBACnB,QAAQ,OAAO;sBACf,UAAU,OAAO;sBACjB,OAAO,OAAO;sBACd,MAAM,OAAO;oBACf,EAAA,MANA,OAAA,KAMO;kBACX;kBACA,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,OAAO,KAAK,UAAU;oBACpB,MAAM,MAAM,KAAK;oBACjB,aAAa,MAAM,KAAK;kBAC1B,CAAsD;kBACtD,kBAAkB;gBACpB,CAAC;AAED,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,QAAQ;oBACN,SAAS,MAAM,KAAK;kBACtB;kBACA,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,yBAAyB;AACtD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY,MAAM,KAAK;kBACvB,UAAU;kBACV,QAAQ;oBACN,QAAQ,MAAM,KAAK;kBACrB;kBACA,kBAAkB;gBACpB,CAAC;cACH,WAAW,MAAM,KAAK,SAAS,WAAW;AACxC,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,MAAM,KAAK;gBACjB,CAAC;cACH,WAAW,uCAAuC,KAAK,GAAG;AACxD,sBAAM,sBAAsB,gBAAgB,MAAM,KAAK,EAAE;AAEzD,2BAAW,gBAAgB,oBAAoB,cAAc;AAC3D,6BAAW,QAAQ;oBACjB,MAAM;oBACN,IAAI,GAAG,MAAM,KAAK,EAAE,IAAI,YAAY;oBACpC,kBAAkB;sBAChB,QAAQ;wBACN,QAAQ,MAAM,KAAK;wBACnB,4BACE,KAAA,MAAM,KAAK,sBAAX,OAAA,KAAgC;sBACpC;oBACF;kBACF,CAAC;gBACH;AAEA,uBAAO,gBAAgB,MAAM,KAAK,EAAE;cACtC;YACF,WAAW,0CAA0C,KAAK,GAAG;AAC3D,oBAAM,WAAW,iBAAiB,MAAM,YAAY;AAEpD,kBAAI,YAAY,MAAM;AACpB,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,SAAS;kBACb,OAAO,MAAM;gBACf,CAAC;cACH;YACF,WAAW,uBAAuB,KAAK,GAAG;AACxC,2BAAa,MAAM,SAAS;AAC5B,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,MAAM,SAAS;gBACnB,WAAW,IAAI,KAAK,MAAM,SAAS,aAAa,GAAI;gBACpD,SAAS,MAAM,SAAS;cAC1B,CAAC;YACH,WAAW,iBAAiB,KAAK,GAAG;AAClC,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,MAAM;gBACV,OAAO,MAAM;cACf,CAAC;AAED,oBAAI,MAAA,KAAA,QAAQ,oBAAR,OAAA,SAAA,GAAyB,WAAzB,OAAA,SAAA,GAAiC,aAAY,MAAM,UAAU;AAC/D,yBAAS,KAAK,MAAM,QAAQ;cAC9B;YACF,WAAW,yCAAyC,KAAK,GAAG;AAE1D,kBAAI,MAAM,gBAAgB,GAAG;AAC3B,iBAAA,KAAA,gBAAgB,MAAM,OAAO,MAA7B,OAAA,SAAA,GAAgC,aAAa;kBAC3C,MAAM;gBAAA;AAGR,2BAAW,QAAQ;kBACjB,MAAM;kBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;kBAC3C,kBAAkB;oBAChB,QAAQ;sBACN,QAAQ,MAAM;sBACd,4BACE,MAAA,KAAA,gBAAgB,MAAM,OAAO,MAA7B,OAAA,SAAA,GAAgC,qBAAhC,OAAA,KACA;oBACJ;kBACF;gBACF,CAAC;cACH;YACF,WAAW,yCAAyC,KAAK,GAAG;AAC1D,yBAAW,QAAQ;gBACjB,MAAM;gBACN,IAAI,GAAG,MAAM,OAAO,IAAI,MAAM,aAAa;gBAC3C,OAAO,MAAM;gBACb,kBAAkB;kBAChB,QAAQ;oBACN,QAAQ,MAAM;kBAChB;gBACF;cACF,CAAC;YACH,WAAW,wBAAwB,KAAK,GAAG;AACzC,6BAAe,8BAA8B;gBAC3C,eAAc,KAAA,MAAM,SAAS,uBAAf,OAAA,SAAA,GAAmC;gBACjD;cACF,CAAC;AACD,oBAAM,cAAc,MAAM,SAAS,MAAM;AACzC,oBAAM,eAAe,MAAM,SAAS,MAAM;AAC1C,oBAAM,cACJ,MAAM,SAAS,MAAM,eACrB,MAAM,SAAS,MAAM;AACvB,oBAAM,mBACJ,MAAA,KAAA,MAAM,SAAS,MAAM,0BAArB,OAAA,SAAA,GAA4C,qBAA5C,OAAA,KACA;AACF,oBAAM,qBACJ,MAAA,KAAA,MAAM,SAAS,MAAM,yBAArB,OAAA,SAAA,GAA2C,kBAA3C,OAAA,KACA;AACF,kBAAI,OAAO,MAAM,SAAS,iBAAiB,UAAU;AACnD,8BAAc,MAAM,SAAS;cAC/B;YACF,WAAW,+BAA+B,KAAK,GAAG;AAChD,kBAAI,MAAM,WAAW,SAAS,gBAAgB;AAC5C,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BQ,WAAW;kBAC7C,KAAK,MAAM,WAAW;kBACtB,OAAO,MAAM,WAAW;gBAC1B,CAAC;cACH,WAAW,MAAM,WAAW,SAAS,iBAAiB;AACpD,2BAAW,QAAQ;kBACjB,MAAM;kBACN,YAAY;kBACZ,KAAI,MAAA,MAAA,KAAA,KAAK,QAAO,eAAZ,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA8BA,WAAW;kBAC7C,WAAW;kBACX,QACE,MAAA,KAAA,MAAM,WAAW,UAAjB,OAAA,KACA,MAAM,WAAW,aADjB,OAAA,KAEA;kBACF,WACE,KAAA,MAAM,WAAW,aAAjB,OAAA,KAA6B,MAAM,WAAW;gBAClD,CAAC;cACH;YACF,WAAW,aAAa,KAAK,GAAG;AAC9B,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,CAAC;YACpD;UACF;UAEA,MAAM,YAAY;AAChB,kBAAM,mBAA6C;cACjD,QAAQ;gBACN;cACF;YACF;AAEA,gBAAI,SAAS,SAAS,GAAG;AACvB,+BAAiB,OAAO,WAAW;YACrC;AAEA,gBAAI,gBAAgB,QAAW;AAC7B,+BAAiB,OAAO,cAAc;YACxC;AAEA,uBAAW,QAAQ;cACjB,MAAM;cACN;cACA;cACA;YACF,CAAC;UACH;QACF,CAAC;MACH;MACA,SAAS,EAAE,KAAK;MAChB,UAAU,EAAE,SAAS,gBAAgB;IACvC;EACF;AACF;AAEA,IAAMD,eAAcjB,iBAAE,OAAO;EAC3B,cAAcA,iBAAE,OAAO;EACvB,sBAAsBA,iBACnB,OAAO,EAAE,eAAeA,iBAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EAC9C,QAAQ;EACX,eAAeA,iBAAE,OAAO;EACxB,uBAAuBA,iBACpB,OAAO,EAAE,kBAAkBA,iBAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,EACjD,QAAQ;AACb,CAAC;AAED,IAAM,uBAAuBA,iBAAE,OAAO;EACpC,MAAMA,iBAAE,QAAQ,4BAA4B;EAC5C,SAASA,iBAAE,OAAO;EAClB,OAAOA,iBAAE,OAAO;EAChB,UAAU,gBAAgB,QAAQ;AACpC,CAAC;AAED,IAAM,mBAAmBA,iBAAE,OAAO;EAChC,MAAMA,iBAAE,QAAQ,OAAO;EACvB,MAAMA,iBAAE,OAAO;EACf,SAASA,iBAAE,OAAO;EAClB,OAAOA,iBAAE,OAAO,EAAE,QAAQ;EAC1B,iBAAiBA,iBAAE,OAAO;AAC5B,CAAC;AAED,IAAM,8BAA8BA,iBAAE,OAAO;EAC3C,MAAMA,iBAAE,KAAK,CAAC,sBAAsB,qBAAqB,CAAC;EAC1D,UAAUA,iBAAE,OAAO;IACjB,oBAAoBA,iBAAE,OAAO,EAAE,QAAQA,iBAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;IAC7D,OAAOiB;IACP,cAAcjB,iBAAE,OAAO,EAAE,QAAQ;EACnC,CAAC;AACH,CAAC;AAED,IAAM,6BAA6BA,iBAAE,OAAO;EAC1C,MAAMA,iBAAE,QAAQ,kBAAkB;EAClC,UAAUA,iBAAE,OAAO;IACjB,IAAIA,iBAAE,OAAO;IACb,YAAYA,iBAAE,OAAO;IACrB,OAAOA,iBAAE,OAAO;IAChB,cAAcA,iBAAE,OAAO,EAAE,QAAQ;EACnC,CAAC;AACH,CAAC;AAED,IAAM,gCAAgCA,iBAAE,OAAO;EAC7C,MAAMA,iBAAE,QAAQ,4BAA4B;EAC5C,cAAcA,iBAAE,OAAO;EACvB,MAAMA,iBAAE,mBAAmB,QAAQ;IACjCA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,SAAS;MACzB,IAAIA,iBAAE,OAAO;IACf,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,WAAW;MAC3B,IAAIA,iBAAE,OAAO;MACb,mBAAmBA,iBAAE,OAAO,EAAE,QAAQ;IACxC,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,eAAe;MAC/B,IAAIA,iBAAE,OAAO;MACb,SAASA,iBAAE,OAAO;MAClB,MAAMA,iBAAE,OAAO;MACf,WAAWA,iBAAE,OAAO;IACtB,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,iBAAiB;MACjC,IAAIA,iBAAE,OAAO;MACb,QAAQA,iBAAE,OAAO;MACjB,QAAQA,iBACL,OAAO;QACN,MAAMA,iBAAE,QAAQ,QAAQ;QACxB,OAAOA,iBAAE,OAAO,EAAE,SAAS;MAC7B,CAAC,EACA,QAAQ;IACb,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,eAAe;MAC/B,IAAIA,iBAAE,OAAO;MACb,QAAQA,iBAAE,OAAO;IACnB,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,kBAAkB;MAClC,IAAIA,iBAAE,OAAO;IACf,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,uBAAuB;MACvC,IAAIA,iBAAE,OAAO;IACf,CAAC;EACH,CAAC;AACH,CAAC;AAED,IAAM,+BAA+BA,iBAAE,OAAO;EAC5C,MAAMA,iBAAE,QAAQ,2BAA2B;EAC3C,cAAcA,iBAAE,OAAO;EACvB,MAAMA,iBAAE,mBAAmB,QAAQ;IACjCA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,SAAS;MACzB,IAAIA,iBAAE,OAAO;IACf,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,WAAW;MAC3B,IAAIA,iBAAE,OAAO;MACb,mBAAmBA,iBAAE,OAAO,EAAE,QAAQ;IACxC,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,eAAe;MAC/B,IAAIA,iBAAE,OAAO;MACb,SAASA,iBAAE,OAAO;MAClB,MAAMA,iBAAE,OAAO;MACf,WAAWA,iBAAE,OAAO;MACpB,QAAQA,iBAAE,QAAQ,WAAW;IAC/B,CAAC;IACD;IACA;IACA;IACA;IACAA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,eAAe;MAC/B,IAAIA,iBAAE,OAAO;MACb,QAAQA,iBAAE,QAAQ,WAAW;IAC/B,CAAC;EACH,CAAC;AACH,CAAC;AAED,IAAM,2CAA2CA,iBAAE,OAAO;EACxD,MAAMA,iBAAE,QAAQ,wCAAwC;EACxD,SAASA,iBAAE,OAAO;EAClB,cAAcA,iBAAE,OAAO;EACvB,OAAOA,iBAAE,OAAO;AAClB,CAAC;AAED,IAAM,gCAAgCA,iBAAE,OAAO;EAC7C,MAAMA,iBAAE,QAAQ,uCAAuC;EACvD,YAAYA,iBAAE,mBAAmB,QAAQ;IACvCA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,cAAc;MAC9B,KAAKA,iBAAE,OAAO;MACd,OAAOA,iBAAE,OAAO;IAClB,CAAC;IACDA,iBAAE,OAAO;MACP,MAAMA,iBAAE,QAAQ,eAAe;MAC/B,SAASA,iBAAE,OAAO;MAClB,UAAUA,iBAAE,OAAO,EAAE,QAAQ;MAC7B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;MAC1B,aAAaA,iBAAE,OAAO,EAAE,QAAQ;MAChC,WAAWA,iBAAE,OAAO,EAAE,QAAQ;MAC9B,OAAOA,iBAAE,OAAO,EAAE,QAAQ;IAC5B,CAAC;EACH,CAAC;AACH,CAAC;AAED,IAAM,0CAA0CA,iBAAE,OAAO;EACvD,MAAMA,iBAAE,QAAQ,uCAAuC;EACvD,SAASA,iBAAE,OAAO;EAClB,eAAeA,iBAAE,OAAO;AAC1B,CAAC;AAED,IAAM,0CAA0CA,iBAAE,OAAO;EACvD,MAAMA,iBAAE,QAAQ,uCAAuC;EACvD,SAASA,iBAAE,OAAO;EAClB,eAAeA,iBAAE,OAAO;EACxB,OAAOA,iBAAE,OAAO;AAClB,CAAC;AAED,IAAM,6BAA6BA,iBAAE,MAAM;EACzC;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACAA,iBAAE,OAAO,EAAE,MAAMA,iBAAE,OAAO,EAAE,CAAC,EAAE,MAAM;;AACvC,CAAC;AAOD,SAAS,iBACP,OAC+C;AAC/C,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,8BACP,OACuD;AACvD,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,uCACP,OAMA;AACA,SACE,8BAA8B,KAAK,KAAK,MAAM,KAAK,SAAS;AAEhE;AAEA,SAAS,wBACP,OACsD;AACtD,SACE,MAAM,SAAS,wBAAwB,MAAM,SAAS;AAE1D;AAEA,SAAS,uBACP,OACqD;AACrD,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,0CACP,OACmE;AACnE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,+BACP,OACwD;AACxD,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,wCACP,OAMA;AACA,SACE,+BAA+B,KAAK,KAAK,MAAM,KAAK,SAAS;AAEjE;AAEA,SAAS,+BACP,OACwD;AACxD,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,yCACP,OACkE;AAClE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,yCACP,OACkE;AAClE,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,aACP,OAC2C;AAC3C,SAAO,MAAM,SAAS;AACxB;AAUA,SAAS,wBAAwB,SAAuC;AACtE,QAAMmB,0BACJ,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS,KAC3B,QAAQ,WAAW,OAAO,KAAK,CAAC,QAAQ,WAAW,YAAY;AAClE,QAAMC,8BACJ,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,YAAY,KAC9B,QAAQ,WAAW,OAAO,KACzB,CAAC,QAAQ,WAAW,YAAY,KAChC,CAAC,QAAQ,WAAW,YAAY,KAClC,QAAQ,WAAW,IAAI,KACvB,QAAQ,WAAW,SAAS;AAC9B,QAAM,WAAW;IACf,wBAAwB;IACxB,mBAAmB;IACnB,wBAAAD;IACA,4BAAAC;EACF;AAGA,MAAI,QAAQ,WAAW,YAAY,GAAG;AACpC,WAAO;MACL,GAAG;MACH,kBAAkB;IACpB;EACF;AAGA,MACE,QAAQ,WAAW,GAAG,KACtB,QAAQ,WAAW,OAAO,KAC1B,QAAQ,WAAW,QAAQ,KAC3B,QAAQ,WAAW,cAAc,GACjC;AACA,QAAI,QAAQ,WAAW,SAAS,KAAK,QAAQ,WAAW,YAAY,GAAG;AACrE,aAAO;QACL,GAAG;QACH,kBAAkB;QAClB,mBAAmB;MACrB;IACF;AAEA,WAAO;MACL,GAAG;MACH,kBAAkB;MAClB,mBAAmB;IACrB;EACF;AAGA,SAAO;IACL,GAAG;IACH,kBAAkB;EACpB;AACF;AAGA,IAAM,uCAAuCpB,iBAAE,OAAO;EACpD,SAASA,iBACN;IACCA,iBAAE,KAAK;MACL;MACA;MACA;IACF,CAAC;EACH,EACC,QAAQ;EACX,cAAcA,iBAAE,OAAO,EAAE,QAAQ;;;;;;;;;;;;;EAcjC,UAAUA,iBACP,MAAM,CAACA,iBAAE,QAAQ,GAAGA,iBAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,gBAAgB,CAAC,CAAC,EAC5D,SAAS;;;;;;EAOZ,cAAcA,iBAAE,OAAO,EAAE,QAAQ;EAEjC,UAAUA,iBAAE,IAAI,EAAE,QAAQ;EAC1B,mBAAmBA,iBAAE,QAAQ,EAAE,QAAQ;EACvC,oBAAoBA,iBAAE,OAAO,EAAE,QAAQ;EACvC,gBAAgBA,iBAAE,OAAO,EAAE,QAAQ;EACnC,iBAAiBA,iBAAE,OAAO,EAAE,QAAQ;EACpC,kBAAkBA,iBAAE,OAAO,EAAE,QAAQ;EACrC,kBAAkBA,iBAAE,OAAO,EAAE,QAAQ;EACrC,aAAaA,iBAAE,KAAK,CAAC,QAAQ,QAAQ,UAAU,CAAC,EAAE,QAAQ;EAC1D,OAAOA,iBAAE,QAAQ,EAAE,QAAQ;EAC3B,kBAAkBA,iBAAE,QAAQ,EAAE,QAAQ;EACtC,eAAeA,iBAAE,KAAK,CAAC,OAAO,UAAU,MAAM,CAAC,EAAE,QAAQ;EACzD,MAAMA,iBAAE,OAAO,EAAE,QAAQ;AAC3B,CAAC;AIxiDD,IAAM,8BAA8BA,iBAAE,OAAO;EAC3C,cAAcA,iBAAE,OAAO,EAAE,QAAQ;EACjC,OAAOA,iBAAE,OAAO,EAAE,IAAI,IAAI,EAAE,IAAI,CAAG,EAAE,QAAQ,CAAG,EAAE,QAAQ;AAC5D,CAAC;AAYM,IAAM,oBAAN,MAAiD;EAOtD,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AARnB,SAAS,uBAAuB;EAS7B;EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAc,QAAQ;IACpB;IACA,QAAQ;IACR,eAAe;IACf;IACA;IACA;IACA;EACF,GAA+C;AAC7C,UAAM,WAAuC,CAAC;AAG9C,UAAM,gBAAgB,MAAMM,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAGD,UAAM,cAAuC;MAC3C,OAAO,KAAK;MACZ,OAAO;MACP;MACA,iBAAiB;MACjB;MACA;IACF;AAEA,QAAI,cAAc;AAChB,UAAI,CAAC,OAAO,QAAQ,OAAO,QAAQ,OAAO,KAAK,EAAE,SAAS,YAAY,GAAG;AACvE,oBAAY,kBAAkB;MAChC,OAAO;AACL,iBAAS,KAAK;UACZ,MAAM;UACN,SAAS;UACT,SAAS,8BAA8B,YAAY;QACrD,CAAC;MACH;IACF;AAGA,QAAI,eAAe;AACjB,YAAM,qBAA2C,CAAC;AAElD,iBAAW,OAAO,oBAAoB;AACpC,cAAM,QAAQ,mBAAmB,GAAiC;AAClE,YAAI,UAAU,QAAW;AACvB,sBAAY,GAAG,IAAI;QACrB;MACF;IACF;AAEA,QAAI,UAAU;AACZ,eAAS,KAAK;QACZ,MAAM;QACN,SAAS;QACT,SAAS,+EAA+E,QAAQ;MAClG,CAAC;IACH;AAEA,WAAO;MACL;MACA;IACF;EACF;EAEA,MAAM,WACJ,SAC2D;AA7G/D,QAAA,IAAA,IAAA;AA8GI,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,aAAa,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAE5D,UAAM;MACJ,OAAO;MACP;MACA,UAAU;IACZ,IAAI,MAAMC,cAAc;MACtB,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASC,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D,MAAM;MACN,uBAAuB;MACvB,2BAA2B,4BAA4B;MACvD,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,WAAO;MACL;MACA;MACA,SAAS;QACP,MAAM,KAAK,UAAU,WAAW;MAClC;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;QACT,MAAM;MACR;IACF;EACF;AACF;AEvIO,IAAM,qCAAqCR,iBAAE,OAAO;;;;EAKzD,SAASA,iBAAE,MAAMA,iBAAE,OAAO,CAAC,EAAE,SAAS;;;;EAKtC,UAAUA,iBAAE,OAAO,EAAE,SAAS;;;;EAK9B,QAAQA,iBAAE,OAAO,EAAE,SAAS;;;;;EAM5B,aAAaA,iBAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,QAAQ,CAAC,EAAE,SAAS;;;;;EAM1D,wBAAwBA,iBACrB,MAAMA,iBAAE,KAAK,CAAC,QAAQ,SAAS,CAAC,CAAC,EACjC,QAAQ,CAAC,SAAS,CAAC,EACnB,SAAS;AACd,CAAC;ADFD,IAAM,cAAc;EAClB,WAAW;EACX,QAAQ;EACR,UAAU;EACV,aAAa;EACb,YAAY;EACZ,SAAS;EACT,WAAW;EACX,SAAS;EACT,SAAS;EACT,UAAU;EACV,OAAO;EACP,QAAQ;EACR,OAAO;EACP,SAAS;EACT,UAAU;EACV,SAAS;EACT,QAAQ;EACR,UAAU;EACV,QAAQ;EACR,OAAO;EACP,QAAQ;EACR,OAAO;EACP,WAAW;EACX,WAAW;EACX,YAAY;EACZ,SAAS;EACT,UAAU;EACV,SAAS;EACT,QAAQ;EACR,QAAQ;EACR,SAAS;EACT,YAAY;EACZ,YAAY;EACZ,OAAO;EACP,SAAS;EACT,OAAO;EACP,QAAQ;EACR,WAAW;EACX,SAAS;EACT,QAAQ;EACR,YAAY;EACZ,UAAU;EACV,SAAS;EACT,SAAS;EACT,QAAQ;EACR,WAAW;EACX,SAAS;EACT,SAAS;EACT,SAAS;EACT,SAAS;EACT,OAAO;EACP,MAAM;EACN,SAAS;EACT,WAAW;EACX,MAAM;EACN,YAAY;EACZ,OAAO;AACT;AAEO,IAAM,2BAAN,MAA+D;EAOpE,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AARnB,SAAS,uBAAuB;EAS7B;EAPH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAOA,MAAc,QAAQ;IACpB;IACA;IACA;EACF,GAAmC;AACjC,UAAM,WAA8C,CAAC;AAGrD,UAAM,gBAAgB,MAAMM,qBAAqB;MAC/C,UAAU;MACV;MACA,QAAQ;IACV,CAAC;AAGD,UAAM,WAAW,IAAI,SAAS;AAC9B,UAAM,OACJ,iBAAiB,aACb,IAAI,KAAK,CAAC,KAAK,CAAC,IAChB,IAAI,KAAK,CAAC,0BAA0B,KAAK,CAAC,CAAC;AAEjD,aAAS,OAAO,SAAS,KAAK,OAAO;AACrC,UAAM,gBAAgB,qBAAqB,SAAS;AACpD,aAAS;MACP;MACA,IAAI,KAAK,CAAC,IAAI,GAAG,SAAS,EAAE,MAAM,UAAU,CAAC;MAC7C,SAAS,aAAa;IACxB;AAGA,QAAI,eAAe;AACjB,YAAM,4BAA4B;QAChC,SAAS,cAAc;QACvB,UAAU,cAAc;QACxB,QAAQ,cAAc;;;QAGtB,iBAAiB;UACf;UACA;QACF,EAAE,SAAS,KAAK,OAAO,IACnB,SACA;QACJ,aAAa,cAAc;QAC3B,yBAAyB,cAAc;MACzC;AAEA,iBAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,yBAAyB,GAAG;AACpE,YAAI,SAAS,MAAM;AACjB,cAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,uBAAW,QAAQ,OAAO;AACxB,uBAAS,OAAO,GAAG,GAAG,MAAM,OAAO,IAAI,CAAC;YAC1C;UACF,OAAO;AACL,qBAAS,OAAO,KAAK,OAAO,KAAK,CAAC;UACpC;QACF;MACF;IACF;AAEA,WAAO;MACL;MACA;IACF;EACF;EAEA,MAAM,WACJ,SACkE;AAlLtE,QAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAmLI,UAAM,eAAc,MAAA,MAAA,KAAA,KAAK,OAAO,cAAZ,OAAA,SAAA,GAAuB,gBAAvB,OAAA,SAAA,GAAA,KAAA,EAAA,MAAA,OAAA,KAA0C,oBAAI,KAAK;AACvE,UAAM,EAAE,UAAU,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AAEzD,UAAM;MACJ,OAAO;MACP;MACA,UAAU;IACZ,IAAI,MAAM,kBAAkB;MAC1B,KAAK,KAAK,OAAO,IAAI;QACnB,MAAM;QACN,SAAS,KAAK;MAChB,CAAC;MACD,SAASE,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;MAC9D;MACA,uBAAuB;MACvB,2BAA2BC;QACzB;MACF;MACA,aAAa,QAAQ;MACrB,OAAO,KAAK,OAAO;IACrB,CAAC;AAED,UAAM,WACJ,SAAS,YAAY,QAAQ,SAAS,YAAY,cAC9C,YAAY,SAAS,QAAoC,IACzD;AAEN,WAAO;MACL,MAAM,SAAS;MACf,WACE,MAAA,MAAA,KAAA,SAAS,aAAT,OAAA,SAAA,GAAmB,IAAI,CAAA,aAAY;QACjC,MAAM,QAAQ;QACd,aAAa,QAAQ;QACrB,WAAW,QAAQ;MACrB,EAAA,MAJA,OAAA,MAKA,KAAA,SAAS,UAAT,OAAA,SAAA,GAAgB,IAAI,CAAA,UAAS;QAC3B,MAAM,KAAK;QACX,aAAa,KAAK;QAClB,WAAW,KAAK;MAClB,EAAA,MATA,OAAA,KAUA,CAAC;MACH;MACA,oBAAmB,KAAA,SAAS,aAAT,OAAA,KAAqB;MACxC;MACA,UAAU;QACR,WAAW;QACX,SAAS,KAAK;QACd,SAAS;QACT,MAAM;MACR;IACF;EACF;AACF;AAEA,IAAM,oCAAoCT,iBAAE,OAAO;EACjD,MAAMA,iBAAE,OAAO;EACf,UAAUA,iBAAE,OAAO,EAAE,QAAQ;EAC7B,UAAUA,iBAAE,OAAO,EAAE,QAAQ;EAC7B,OAAOA,iBACJ;IACCA,iBAAE,OAAO;MACP,MAAMA,iBAAE,OAAO;MACf,OAAOA,iBAAE,OAAO;MAChB,KAAKA,iBAAE,OAAO;IAChB,CAAC;EACH,EACC,QAAQ;EACX,UAAUA,iBACP;IACCA,iBAAE,OAAO;MACP,IAAIA,iBAAE,OAAO;MACb,MAAMA,iBAAE,OAAO;MACf,OAAOA,iBAAE,OAAO;MAChB,KAAKA,iBAAE,OAAO;MACd,MAAMA,iBAAE,OAAO;MACf,QAAQA,iBAAE,MAAMA,iBAAE,OAAO,CAAC;MAC1B,aAAaA,iBAAE,OAAO;MACtB,aAAaA,iBAAE,OAAO;MACtB,mBAAmBA,iBAAE,OAAO;MAC5B,gBAAgBA,iBAAE,OAAO;IAC3B,CAAC;EACH,EACC,QAAQ;AACb,CAAC;AEpQM,IAAM,UACX,OACI,WACA;A9BmIC,SAAS,aACd,UAAkC,CAAC,GACnB;AA1IlB,MAAA,IAAA;AA2IE,QAAM,WACJ,KAAA,qBAAqB,QAAQ,OAAO,MAApC,OAAA,KAAyC;AAE3C,QAAM,gBAAe,KAAA,QAAQ,SAAR,OAAA,KAAgB;AAErC,QAAM,aAAa,MACjB;IACE;MACE,eAAe,UAAU,WAAW;QAClC,QAAQ,QAAQ;QAChB,yBAAyB;QACzB,aAAa;MACf,CAAC,CAAC;MACF,uBAAuB,QAAQ;MAC/B,kBAAkB,QAAQ;MAC1B,GAAG,QAAQ;IACb;IACA,iBAAiB,OAAO;EAC1B;AAEF,QAAM,kBAAkB,CAAC,YACvB,IAAI,wBAAwB,SAAS;IACnC,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,wBAAwB,CAAC,YAC7B,IAAI,8BAA8B,SAAS;IACzC,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,uBAAuB,CAAC,YAC5B,IAAI,qBAAqB,SAAS;IAChC,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,mBAAmB,CAAC,YACxB,IAAI,iBAAiB,SAAS;IAC5B,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,2BAA2B,CAAC,YAChC,IAAI,yBAAyB,SAAS;IACpC,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,oBAAoB,CAAC,YACzB,IAAI,kBAAkB,SAAS;IAC7B,UAAU,GAAG,YAAY;IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;IACpC,SAAS;IACT,OAAO,QAAQ;EACjB,CAAC;AAEH,QAAM,sBAAsB,CAAC,YAAoC;AAC/D,QAAI,YAAY;AACd,YAAM,IAAI;QACR;MACF;IACF;AAEA,WAAO,qBAAqB,OAAO;EACrC;AAEA,QAAM,uBAAuB,CAAC,YAAoC;AAChE,WAAO,IAAI,6BAA6B,SAAS;MAC/C,UAAU,GAAG,YAAY;MACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;MACpC,SAAS;MACT,OAAO,QAAQ;MACf,gBAAgB,CAAC,OAAO;IAC1B,CAAC;EACH;AAEA,QAAM,WAAW,SAAU,SAAiC;AAC1D,WAAO,oBAAoB,OAAO;EACpC;AAEA,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,aAAa;AACtB,WAAS,YAAY;AACrB,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAE9B,WAAS,QAAQ;AACjB,WAAS,aAAa;AAEtB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAE9B,WAAS,SAAS;AAClB,WAAS,cAAc;AAEvB,WAAS,QAAQ;AAEjB,SAAO;AACT;AAKO,IAAM,SAAS,aAAa;",
  "names": ["z", "openaiTools", "UnsupportedFunctionalityError", "toolCall", "getResponseMetadata", "mapOpenAIFinishReason", "parseProviderOptions", "postJsonToApi", "combineHeaders", "createJsonResponseHandler", "createEventSourceResponseHandler", "createProviderDefinedToolFactoryWithOutputSchema", "createProviderDefinedToolFactory", "_a", "_b", "_c", "convertToBase64", "usageSchema", "generateId", "supportsFlexProcessing", "supportsPriorityProcessing"]
}
